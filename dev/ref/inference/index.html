<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Inference Library · Gen</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Gen</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><a class="toctext" href="../../getting_started/">Getting Started</a></li><li><a class="toctext" href="../../tutorials/">Tutorials</a></li><li><a class="toctext" href="../../guide/">Guide</a></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../modeling/">Modeling Languages</a></li><li><a class="toctext" href="../combinators/">Generative Function Combinators</a></li><li><a class="toctext" href="../assignments/">Assignments</a></li><li><a class="toctext" href="../selections/">Selections</a></li><li class="current"><a class="toctext" href>Inference Library</a><ul class="internal"><li><a class="toctext" href="#Importance-Sampling-1">Importance Sampling</a></li><li><a class="toctext" href="#Markov-Chain-Monte-Carlo-1">Markov Chain Monte Carlo</a></li><li><a class="toctext" href="#Optimization-over-Random-Choices-1">Optimization over Random Choices</a></li><li><a class="toctext" href="#Particle-Filtering-1">Particle Filtering</a></li><li><a class="toctext" href="#Training-Generative-Functions-1">Training Generative Functions</a></li></ul></li><li><a class="toctext" href="../gfi/">Generative Function Interface</a></li><li><a class="toctext" href="../distributions/">Probability Distributions</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Reference</li><li><a href>Inference Library</a></li></ul><a class="edit-page" href="https://github.com/probcomp/Gen/blob/master/docs/src/ref/inference.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Inference Library</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Inference-Library-1" href="#Inference-Library-1">Inference Library</a></h1><h2><a class="nav-anchor" id="Importance-Sampling-1" href="#Importance-Sampling-1">Importance Sampling</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.importance_sampling" href="#Gen.importance_sampling"><code>Gen.importance_sampling</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(traces, log_norm_weights, lml_est) = importance_sampling(model::GenerativeFunction,
    model_args::Tuple, observations::Assignment, num_samples::Int)

(traces, log_norm_weights, lml_est) = importance_sampling(model::GenerativeFunction,
    model_args::Tuple, observations::Assignment,
    proposal::GenerativeFunction, proposal_args::Tuple,
    num_samples::Int)</code></pre><p>Run importance sampling, returning a vector of traces with associated log weights.</p><p>The log-weights are normalized. Also return the estimate of the marginal likelihood of the observations (<code>lml_est</code>). The observations are addresses that must be sampled by the model in the given model arguments. The first variant uses the internal proposal distribution of the model. The second variant uses a custom proposal distribution defined by the given generative function. All addresses of random choices sampled by the proposal should also be sampled by the model function.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/importance.jl#L1-L18">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.importance_resampling" href="#Gen.importance_resampling"><code>Gen.importance_resampling</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(trace, lml_est) = importance_resampling(model::GenerativeFunction,
    model_args::Tuple, observations::Assignment, num_samples::Int)

(traces, lml_est) = importance_resampling(model::GenerativeFunction,
    model_args::Tuple, observations::Assignment,
    proposal::GenerativeFunction, proposal_args::Tuple,
    num_samples::Int)</code></pre><p>Run sampling importance resampling, returning a single trace.</p><p>Unlike <code>importance_sampling</code>, the memory used constant in the number of samples.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/importance.jl#L51-L63">source</a></section><h2><a class="nav-anchor" id="Markov-Chain-Monte-Carlo-1" href="#Markov-Chain-Monte-Carlo-1">Markov Chain Monte Carlo</a></h2><p>The following inference library methods take a trace and return a new trace.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.default_mh" href="#Gen.default_mh"><code>Gen.default_mh</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(new_trace, accepted) = default_mh(trace, selection::AddressSet)</code></pre><p>Perform a Metropolis-Hastings update that proposes new values for the selected addresses from the internal proposal (often using ancestral sampling).</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/mh.jl#L1-L5">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.simple_mh" href="#Gen.simple_mh"><code>Gen.simple_mh</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(new_trace, accepted) = simple_mh(trace, proposal::GenerativeFunction, proposal_args::Tuple)</code></pre><p>Perform a Metropolis-Hastings update that proposes new values for some subset of random choices in the given trace using the given proposal generative function.</p><p>The proposal generative function should take as its first argument the current trace of the model, and remaining arguments <code>proposal_args</code>. All addresses sampled by the proposal must be in the existing model trace. The proposal may modify the control flow of the model, but values of new addresses in the model are sampled from the model&#39;s internal proposal distribution.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/mh.jl#L18-L26">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.custom_mh" href="#Gen.custom_mh"><code>Gen.custom_mh</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(new_trace, accepted) = custom_mh(trace, proposal::GenerativeFunction, proposal_args::Tuple)</code></pre><p>Perform a Metropolis-Hastings update that proposes new values for some subset of random choices in the given trace using the given proposal generative function.</p><p>The proposal generative function should take as its first argument the current trace of the model, and remaining arguments <code>proposal_args</code>. If the proposal modifies addresses that determine the control flow in the model, values must be provided by the proposal for any addresses that are newly sampled by the model.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/mh.jl#L45-L52">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.general_mh" href="#Gen.general_mh"><code>Gen.general_mh</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(new_trace, accepted) = general_mh(trace, proposal::GenerativeFunction, proposal_args::Tuple, involution::Function)</code></pre><p>Perform a generalized Metropolis-Hastings update based on an involution (bijection that is its own inverse) on a space of assignments.</p><p>The `involution&#39; Julia function has the following signature:</p><pre><code class="language-none">(new_trace, bwd_assmt::Assignment, weight) = involution(trace, fwd_assmt::Assignment, fwd_ret, proposal_args::Tuple)</code></pre><p>The generative function <code>proposal</code> is executed on arguments <code>(trace, proposal_args...)</code>, producing an assignment <code>fwd_assmt</code> and return value <code>fwd_ret</code>. For each value of model arguments (contained in <code>trace</code>) and <code>proposal_args</code>, the <code>involution</code> function applies an involution that maps the tuple <code>(get_assmt(trace), fwd_assmt)</code> to the tuple <code>(get_assmt(new_trace), bwd_assmt)</code>. Note that <code>fwd_ret</code> is a deterministic function of <code>fwd_assmt</code> and <code>proposal_args</code>. When only discrete random choices are used, the <code>weight</code> must be equal to <code>get_score(new_trace) - get_score(trace)</code>.</p><p><strong>Including Continuous Random Choices</strong> When continuous random choices are used, the <code>weight</code> must include an additive term that is the determinant of the the Jacobian of the bijection on the continuous random choices that is obtained by currying the involution on the discrete random choices.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/mh.jl#L73-L89">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.mala" href="#Gen.mala"><code>Gen.mala</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(new_trace, accepted) = mala(trace, selection::AddressSet, tau::Real)</code></pre><p>Apply a Metropolis-Adjusted Langevin Algorithm (MALA) update.</p><p><a href="https://en.wikipedia.org/wiki/Metropolis-adjusted_Langevin_algorithm">Reference URL</a></p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/mala.jl#L2-L8">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.hmc" href="#Gen.hmc"><code>Gen.hmc</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(new_trace, accepted) = hmc(trace, selection::AddressSet, mass=0.1, L=10, eps=0.1)</code></pre><p>Apply a Hamiltonian Monte Carlo (HMC) update.</p><p>Neal, Radford M. &quot;MCMC using Hamiltonian dynamics.&quot; Handbook of Markov Chain Monte Carlo 2.11 (2011): 2.</p><p><a href="http://www.mcmchandbook.net/HandbookChapter5.pdf">Reference URL</a></p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/hmc.jl#L13-L21">source</a></section><h2><a class="nav-anchor" id="Optimization-over-Random-Choices-1" href="#Optimization-over-Random-Choices-1">Optimization over Random Choices</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.map_optimize" href="#Gen.map_optimize"><code>Gen.map_optimize</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">new_trace = map_optimize(trace, selection::AddressSet, 
    max_step_size=0.1, tau=0.5, min_step_size=1e-16, verbose=false)</code></pre><p>Perform backtracking gradient ascent to optimize the log probability of the trace over selected continuous choices.</p><p>Selected random choices must have support on the entire real line.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/map_optimize.jl#L1-L8">source</a></section><h2><a class="nav-anchor" id="Particle-Filtering-1" href="#Particle-Filtering-1">Particle Filtering</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.particle_filter_default" href="#Gen.particle_filter_default"><code>Gen.particle_filter_default</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(traces, log_norm_weights, lml_est) = particle_filter_default(
    model::GenerativeFunction, model_args::Tuple, num_steps::Int,
    num_particles::Int, ess_threshold::Real,
    init_observations::Assignment, step_observations::Function;
    verbose=false)</code></pre><p>Run particle filtering using the internal proposal of the model.</p><p>The first argument to the model must be an integer, starting with 1, that defines the step. The remaining arguments are given by <code>model_args</code>. The model traces will be initialized with <code>step=1</code> using the constraints given by <code>init_observations</code>. Then, the <code>step</code> will be consecutively incremented by 1. The function <code>step_observations</code> takes the step and returns a tuple <code>(observations, argdiff)</code> where <code>observations</code> is an assignment containing the values for newly observed random choices for the step, and <code>argdiff</code> describes the argument change from the previous step to the current step.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/particle_filter.jl#L18-L32">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Gen.particle_filter_custom" href="#Gen.particle_filter_custom"><code>Gen.particle_filter_custom</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">(traces, log_norm_weights, lml_est) = particle_filter_custom(
    model::GenerativeFunction, model_args::Tuple, num_steps::Int,
    num_steps::Int, num_particles::Int, ess_threshold::Real,
    init_observations::Assignment, init_proposal_args::Tuple,
    step_observations::Function, step_proposal_args::Function,
    init_proposal::GenerativeFunction, step_proposal::GenerativeFunction;
    verbose::Bool=false)</code></pre><p>Run particle filtering using custom proposal(s) at each step.</p></div></div><a class="source-link" target="_blank" href="https://github.com/probcomp/Gen/blob/b658f4e09f3c870c1fc0afb96eb825433780f6d3/src/inference/particle_filter.jl#L90-L100">source</a></section><h2><a class="nav-anchor" id="Training-Generative-Functions-1" href="#Training-Generative-Functions-1">Training Generative Functions</a></h2><pre><code class="language-none">sgd_train_batch</code></pre><footer><hr/><a class="previous" href="../selections/"><span class="direction">Previous</span><span class="title">Selections</span></a><a class="next" href="../gfi/"><span class="direction">Next</span><span class="title">Generative Function Interface</span></a></footer></article></body></html>
