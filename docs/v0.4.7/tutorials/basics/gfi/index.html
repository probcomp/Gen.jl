<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Generative Function Interface · Gen.jl</title><meta name="title" content="Generative Function Interface · Gen.jl"/><meta property="og:title" content="Generative Function Interface · Gen.jl"/><meta property="twitter:title" content="Generative Function Interface · Gen.jl"/><meta name="description" content="Documentation for Gen.jl."/><meta property="og:description" content="Documentation for Gen.jl."/><meta property="twitter:description" content="Documentation for Gen.jl."/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><script src="../../../assets/header.js"></script><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">Gen.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Getting Started</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../getting_started/linear_regression/">Example 1: Linear Regression</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox" checked/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Basics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../modeling_in_gen/">Introduction to Modeling in Gen</a></li><li class="is-active"><a class="tocitem" href>Generative Function Interface</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Mathematical-concepts"><span>Mathematical concepts</span></a></li><li><a class="tocitem" href="#Traces"><span>Traces</span></a></li><li><a class="tocitem" href="#Updating-traces"><span>Updating traces</span></a></li><li><a class="tocitem" href="#differentiable_programming_tutorial"><span>Differentiable Programming</span></a></li></ul></li><li><a class="tocitem" href="../combinators/">Generative Combinators</a></li><li><a class="tocitem" href="../particle_filter/">Object Tracking with Particle Filters</a></li><li><a class="tocitem" href="../vi/">Variational Inference</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Advanced</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../trace_translators/">Trace Translators</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Model Optmizations</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../model_optimizations/scaling_with_sml/">Speeding Inference with the Static Modeling Language</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">How-to Guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../how_to/mcmc_kernels/">MCMC Kernels</a></li><li><a class="tocitem" href="../../../how_to/custom_distributions/">Custom Distributions</a></li><li><a class="tocitem" href="../../../how_to/custom_dsl/">Custom Modeling Languages</a></li><li><a class="tocitem" href="../../../how_to/custom_derivatives/">Custom Gradients</a></li><li><a class="tocitem" href="../../../how_to/custom_incremental_computation/">Incremental Computation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">API Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Modeling Library</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../api/model/gfi/">Generative Functions</a></li><li><a class="tocitem" href="../../../api/model/distributions/">Probability Distributions</a></li><li><a class="tocitem" href="../../../api/model/choice_maps/">Choice Maps</a></li><li><a class="tocitem" href="../../../api/model/modeling/">Built-in Modeling Languages</a></li><li><a class="tocitem" href="../../../api/model/combinators/">Combinators</a></li><li><a class="tocitem" href="../../../api/model/selections/">Selections</a></li><li><a class="tocitem" href="../../../api/model/parameter_optimization/">Optimizing Trainable Parameters</a></li><li><a class="tocitem" href="../../../api/model/trace_translators/">Trace Translators</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5-2" type="checkbox"/><label class="tocitem" for="menuitem-5-2"><span class="docs-label">Inference Library</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../api/inference/importance/">Importance Sampling</a></li><li><a class="tocitem" href="../../../api/inference/map/">MAP Optimization</a></li><li><a class="tocitem" href="../../../api/inference/mcmc/">Markov chain Monte Carlo</a></li><li><a class="tocitem" href="../../../api/inference/map/">MAP Optimization</a></li><li><a class="tocitem" href="../../../api/inference/pf/">Particle Filtering</a></li><li><a class="tocitem" href="../../../api/inference/vi/">Variational Inference</a></li><li><a class="tocitem" href="../../../api/inference/learning/">Learning Generative Functions</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Explanation and Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../explanations/language_implementation/">Modeling Language Implementation</a></li><li><a class="tocitem" href="../../../explanations/combinator_design/">Combinator Design and Implementation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li><a class="is-disabled">Basics</a></li><li class="is-active"><a href>Generative Function Interface</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Generative Function Interface</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/probcomp/Gen.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/probcomp/Gen.jl/blob/master/docs/src/tutorials/basics/gfi.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="gfi"><a class="docs-heading-anchor" href="#gfi">Generative Function Interface</a><a id="gfi-1"></a><a class="docs-heading-anchor-permalink" href="#gfi" title="Permalink"></a></h1><p>One of the core abstractions in Gen is the <strong>generative function</strong>. Generative functions are used to represent a variety of different types of probabilistic computations including generative models, inference models, custom proposal distributions, and variational approximations.</p><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>Generative functions are represented by the following abstact type:</p><p>There are various kinds of generative functions, which are represented by concrete subtypes of <a href="../../../api/model/gfi/#Gen.GenerativeFunction"><code>GenerativeFunction</code></a>. For example, the <a href="../../../api/model/modeling/#dynamic_modeling_language">Built-in Modeling Language</a> allows generative functions to be constructed using Julia function definition syntax:</p><pre><code class="language-julia hljs">@gen function foo(a, b=0)
    if @trace(bernoulli(0.5), :z)
        return a + b + 1
    else
        return a + b
    end
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any, Any], true, Union{Nothing, Some{Any}}[nothing, Some(0)], Main.var&quot;##foo#280&quot;, Bool[0, 0], false)</code></pre><p>Users can also extend Gen by implementing their own <a href="../../../how_to/custom_distributions/#custom_generative_functions">custom generative functions</a>, which can be new modeling languages, or just specialized optimized implementations of a fragment of a specific model.</p><p>Generative functions behave like Julia functions in some respects. For example, we can call a generative function <code>foo</code> on arguments and get an output value using regular Julia call syntax:</p><pre><code class="language-julia hljs">foo(2, 4)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">6</code></pre><p>However, generative functions are distinct from Julia functions because they support additional behaviors, described in the remainder of this section.</p><h2 id="Mathematical-concepts"><a class="docs-heading-anchor" href="#Mathematical-concepts">Mathematical concepts</a><a id="Mathematical-concepts-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-concepts" title="Permalink"></a></h2><p>Generative functions represent computations that accept some arguments, may use randomness internally, return an output, and cannot mutate externally observable state. We represent the randomness used during an execution of a generative function as a <strong>choice map</strong> from unique <strong>addresses</strong> to values of random choices, denoted <span>$t : A \to V$</span> where <span>$A$</span> is a finite (but not a priori bounded) address set and <span>$V$</span> is a set of possible values that random choices can take. In this section, we assume that random choices are discrete to simplify notation. We say that two choice maps <span>$t$</span> and <span>$s$</span> <strong>agree</strong> if they assign the same value for any address that is in both of their domains.</p><p>Generative functions may also use <strong>non-addressable randomness</strong>, which is not included in the map <span>$t$</span>. We denote non-addressable randomness by <span>$r$</span>. Untraced randomness is useful for example, when calling black box Julia code that implements a randomized algorithm.</p><p>The observable behavior of every generative function is defined by the following mathematical objects:</p><h3 id="Input-type"><a class="docs-heading-anchor" href="#Input-type">Input type</a><a id="Input-type-1"></a><a class="docs-heading-anchor-permalink" href="#Input-type" title="Permalink"></a></h3><p>The set of valid argument tuples to the function, denoted <span>$X$</span>.</p><h3 id="Probability-distribution-family"><a class="docs-heading-anchor" href="#Probability-distribution-family">Probability distribution family</a><a id="Probability-distribution-family-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-distribution-family" title="Permalink"></a></h3><p>A family of probability distributions <span>$p(t, r; x)$</span> on maps <span>$t$</span> from random choice addresses to their values, and non-addressable randomness <span>$r$</span>, indexed by arguments <span>$x$</span>, for all <span>$x \in X$</span>. Note that the distribution must be normalized:</p><p class="math-container">\[\sum_{t, r} p(t, r; x) = 1 \;\; \text{for all} \;\; x \in X\]</p><p>This corresponds to a requirement that the function terminate with probabability 1 for all valid arguments. We use <span>$p(t; x)$</span> to denote the marginal distribution on the map <span>$t$</span>:</p><p class="math-container">\[p(t; x) := \sum_{r} p(t, r; x)\]</p><p>And we denote the conditional distribution on non-addressable randomness <span>$r$</span>, given the map <span>$t$</span>, as:</p><p class="math-container">\[p(r | t; x) := p(t, r; x) / p(t; x)\]</p><h3 id="Return-value-function"><a class="docs-heading-anchor" href="#Return-value-function">Return value function</a><a id="Return-value-function-1"></a><a class="docs-heading-anchor-permalink" href="#Return-value-function" title="Permalink"></a></h3><p>A (deterministic) function <span>$f$</span> that maps the tuple <span>$(x, t)$</span> of the arguments and the choice map to the return value of the function (which we denote by <span>$y$</span>). Note that the return value cannot depend on the non-addressable randomness.</p><h3 id="Auxiliary-state"><a class="docs-heading-anchor" href="#Auxiliary-state">Auxiliary state</a><a id="Auxiliary-state-1"></a><a class="docs-heading-anchor-permalink" href="#Auxiliary-state" title="Permalink"></a></h3><p>Generative functions may expose additional <strong>auxiliary state</strong> associated with an execution, besides the choice map and the return value. This auxiliary state is a function <span>$z = h(x, t, r)$</span> of the arguments, choice map, and non-addressable randomness. Like the choice map, the auxiliary state is indexed by addresses. We require that the addresses of auxiliary state are disjoint from the addresses in the choice map. Note that when a generative function is called within a model, the auxiliary state is not available to the caller. It is typically used by inference programs, for logging and for caching the results of deterministic computations that would otherwise need to be reconstructed.</p><h3 id="Internal-proposal-distribution-family"><a class="docs-heading-anchor" href="#Internal-proposal-distribution-family">Internal proposal distribution family</a><a id="Internal-proposal-distribution-family-1"></a><a class="docs-heading-anchor-permalink" href="#Internal-proposal-distribution-family" title="Permalink"></a></h3><p>A family of probability distributions <span>$q(t; x, u)$</span> on maps <span>$t$</span> from random choice addresses to their values, indexed by tuples <span>$(x, u)$</span> where <span>$u$</span> is a map from random choice addresses to values, and where <span>$x$</span> are the arguments to the function. It must satisfy the following conditions:</p><p class="math-container">\[\sum_{t} q(t; x, u) = 1 \;\; \text{for all} \;\; x \in X, u\]</p><p class="math-container">\[p(t; x) &gt; 0 \text{ if and only if } q(t; x, u) &gt; 0 \text{ for all } u \text{ where } u \text{ and } t \text{ agree }\]</p><p class="math-container">\[q(t; x, u) &gt; 0 \text{ implies that } u \text{ and } t \text{ agree }.\]</p><p>There is also a family of probability distributions <span>$q(r; x, t)$</span> on non-addressable randomness, that satisfies:</p><p class="math-container">\[q(r; x, t) &gt; 0 \text{ if and only if } p(r | t, x) &gt; 0\]</p><h2 id="Traces"><a class="docs-heading-anchor" href="#Traces">Traces</a><a id="Traces-1"></a><a class="docs-heading-anchor-permalink" href="#Traces" title="Permalink"></a></h2><p>An <strong>execution trace</strong> (or just <em>trace</em>) is a record of an execution of a generative function. Traces are the primary data structures manipulated by Gen inference programs. There are various methods for producing, updating, and inspecting traces. Traces contain:</p><ul><li><p>the arguments to the generative function</p></li><li><p>the choice map</p></li><li><p>the return value</p></li><li><p>auxiliary state</p></li><li><p>other implementation-specific state that is not exposed to the caller or user of the generative function, but is used internally to facilitate e.g. incremental updates to executions and automatic differentiation</p></li><li><p>any necessary record of the non-addressable randomness</p></li></ul><p>Different concrete types of generative functions use different data structures and different Julia types for their traces, but traces are subtypes of <a href="../../../api/model/gfi/#Gen.Trace"><code>Trace</code></a>.</p><p>The concrete trace type that a generative function uses is the second type parameter of the <a href="../../../api/model/gfi/#Gen.GenerativeFunction"><code>GenerativeFunction</code></a> abstract type. For example, the trace type of <a href="../../../api/model/modeling/#Gen.DynamicDSLFunction"><code>DynamicDSLFunction</code></a> is <code>DynamicDSLTrace</code>.</p><p>A generative function can be executed to produce a trace of the execution using <a href="../../../api/model/gfi/#Gen.simulate"><code>simulate</code></a>:</p><pre><code class="language-julia hljs">trace = simulate(foo, (a, b))</code></pre><p>A traced execution that satisfies constraints on the choice map can be generated using <a href="../../../api/model/gfi/#Gen.generate"><code>generate</code></a>:</p><pre><code class="language-julia hljs">trace, weight = generate(foo, (a, b), choicemap((:z, false)))</code></pre><p>There are various methods for inspecting traces, including:</p><ul><li><p><a href="../../../api/model/gfi/#Gen.get_args"><code>get_args</code></a> (returns the arguments to the function)</p></li><li><p><a href="../../../api/model/gfi/#Gen.get_retval"><code>get_retval</code></a> (returns the return value of the function)</p></li><li><p><a href="../../../api/model/gfi/#Gen.get_choices"><code>get_choices</code></a> (returns the choice map)</p></li><li><p><a href="../../../api/model/gfi/#Gen.get_score"><code>get_score</code></a> (returns the log probability that the random choices took the values they did)</p></li><li><p><a href="../../../api/model/gfi/#Gen.get_gen_fn"><code>get_gen_fn</code></a> (returns a reference to the generative function)</p></li></ul><p>You can also access the values in the choice map and the auxiliary state of the trace by passing the address to <a href="../../../api/model/gfi/#Base.getindex"><code>Base.getindex</code></a>. For example, to retrieve the value of random choice at address <code>:z</code>:</p><pre><code class="language-julia hljs">z = trace[:z]</code></pre><p>When a generative function has default values specified for trailing arguments, those arguments can be left out when calling <a href="../../../api/model/gfi/#Gen.simulate"><code>simulate</code></a>, <a href="../../../api/model/gfi/#Gen.generate"><code>generate</code></a>, and other functions provided by the generative function interface. The default values will automatically be filled in:</p><pre><code class="language-julia hljs">trace = simulate(foo, (2,));
get_args(trace)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(2, 0)</code></pre><h2 id="Updating-traces"><a class="docs-heading-anchor" href="#Updating-traces">Updating traces</a><a id="Updating-traces-1"></a><a class="docs-heading-anchor-permalink" href="#Updating-traces" title="Permalink"></a></h2><p>It is often important to incrementally modify the trace of a generative function (e.g. within MCMC, numerical optimization, sequential Monte Carlo, etc.). In Gen, traces are <strong>functional data structures</strong>, meaning they can be treated as immutable values. There are several methods that take a trace of a generative function as input and return a new trace of the generative function based on adjustments to the execution history of the function. We will illustrate these methods using the following generative function:</p><pre><code class="language-julia hljs">@gen function bar()
    val = @trace(bernoulli(0.3), :a)
    if @trace(bernoulli(0.4), :b)
        val = @trace(bernoulli(0.6), :c) &amp;&amp; val
    else
        val = @trace(bernoulli(0.1), :d) &amp;&amp; val
    end
    val = @trace(bernoulli(0.7), :e) &amp;&amp; val
    return val
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[], false, Union{Nothing, Some{Any}}[], Main.var&quot;##bar#281&quot;, Bool[], false)</code></pre><p>Suppose we have a trace (<code>trace</code>) of <code>bar</code> with initial choices:</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :a : false
│
├── :b : true
│
├── :e : true
│
└── :c : false
</code></pre><p>Note that address <code>:d</code> is not present because the branch in which <code>:d</code> is sampled was not taken because random choice <code>:b</code> had value <code>true</code>.</p><h3 id="Update"><a class="docs-heading-anchor" href="#Update">Update</a><a id="Update-1"></a><a class="docs-heading-anchor-permalink" href="#Update" title="Permalink"></a></h3><p>The <a href="../../../api/model/gfi/#Gen.update"><code>update</code></a> method takes a trace and generates an adjusted trace that is consistent with given changes to the arguments to the function, and changes to the values of random choices made.</p><p><strong>Example.</strong> Suppose we run <a href="../../../api/model/gfi/#Gen.update"><code>update</code></a> on the example <code>trace</code>, with the following constraints:</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :b : false
│
└── :d : true
</code></pre><pre><code class="language-julia hljs">constraints = choicemap((:b, false), (:d, true))
(new_trace, w, _, discard) = update(trace, (), (), constraints)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[], false, Union{Nothing, Some{Any}}[], Main.var&quot;##bar#281&quot;, Bool[], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:a =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true), :b =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.5108256237659907, NaN, true), :d =&gt; Gen.ChoiceOrCallRecord{Bool}(true, -2.3025850929940455, NaN, true), :e =&gt; Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -3.5267606046375013, 0.0, (), false), -0.9808292530117263, UnknownChange(), DynamicChoiceMap(Dict{Any, Any}(:b =&gt; true, :c =&gt; false), Dict{Any, Any}()))</code></pre><p>Then <code>get_choices(new_trace)</code> will be:</p><pre><code class="language-julia hljs">get_choices(new_trace)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :a : false
│
├── :b : false
│
├── :d : true
│
└── :e : true
</code></pre><p>and <code>discard</code> will be:</p><pre><code class="language-julia hljs">discard</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :b : true
│
└── :c : false
</code></pre><p>Note that the discard contains both the previous values of addresses that were overwritten, and the values for addresses that were in the previous trace but are no longer in the new trace. The weight (<code>w</code>) is computed as:</p><p class="math-container">\[p(t; x) = 0.7 × 0.4 × 0.4 × 0.7 = 0.0784\\
p(t&#39;; x&#39;) = 0.7 × 0.6 × 0.1 × 0.7 = 0.0294\\
w = \log p(t&#39;; x&#39;)/p(t; x) = \log 0.0294/0.0784 = \log 0.375\]</p><p><strong>Example.</strong> Suppose we run <a href="../../../api/model/gfi/#Gen.update"><code>update</code></a> on the example <code>trace</code>, with the following constraints, which <em>do not</em> contain a value for <code>:d</code>:</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
└── :b : false
</code></pre><pre><code class="language-julia hljs">constraints = choicemap((:b, false))
(new_trace, w, _, discard) = update(trace, (), (), constraints)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[], false, Union{Nothing, Some{Any}}[], Main.var&quot;##bar#281&quot;, Bool[], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:a =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true), :b =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.5108256237659907, NaN, true), :d =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :e =&gt; Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.329536027301282, 0.0, (), false), 1.3217558399823193, UnknownChange(), DynamicChoiceMap(Dict{Any, Any}(:b =&gt; true, :c =&gt; false), Dict{Any, Any}()))</code></pre><p>Since <code>b</code> is constrained to <code>false</code>, the updated trace must now sample at address <code>d</code> (note address <code>e</code> remains fixed). There two possibilities for <code>get_choices(new_trace)</code>:</p><p>The first choicemap:</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :a : false
│
├── :b : false
│
├── :d : true
│
└── :e : true
</code></pre><p>occurs with probability 0.1. The second:</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :a : false
│
├── :b : false
│
├── :d : false
│
└── :e : true
</code></pre><p>occurs with probability 0.9. Also, <code>discard</code> will be:</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :b : true
│
└── :c : false
</code></pre><p>If the former case occurs and <code>:d</code> is assigned to <code>true</code>, then the weight (<code>w</code>) is computed as:</p><p class="math-container">\[p(t; x) = 0.7 × 0.4 × 0.4 × 0.7 = 0.0784\\
p(t&#39;; x&#39;) = 0.7 × 0.6 × 0.1 × 0.7 = 0.0294\\
q(t&#39;; x&#39;, t + u) = 0.1\\
w = \log p(t&#39;; x&#39;)/(p(t; x) q(t&#39;; x&#39;, t + u)) = \log 0.0294/(0.0784 \cdot 0.1) = \log (3.75)\]</p><h3 id="Regenerate"><a class="docs-heading-anchor" href="#Regenerate">Regenerate</a><a id="Regenerate-1"></a><a class="docs-heading-anchor-permalink" href="#Regenerate" title="Permalink"></a></h3><p>The <a href="../../../api/model/gfi/#Gen.regenerate"><code>regenerate</code></a> method takes a trace and generates an adjusted trace that is consistent with a change to the arguments to the function, and also generates new values for selected random choices.</p><p><strong>Example.</strong> Suppose we run <a href="../../../api/model/gfi/#Gen.regenerate"><code>regenerate</code></a> on the example <code>trace</code>, with selection <code>:a</code> and <code>:b</code>:</p><pre><code class="language-julia hljs">(new_trace, w, _) = regenerate(trace, (), (), select(:a, :b))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[], false, Union{Nothing, Some{Any}}[], Main.var&quot;##bar#281&quot;, Bool[], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:a =&gt; Gen.ChoiceOrCallRecord{Bool}(true, -1.2039728043259361, NaN, true), :b =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.5108256237659907, NaN, true), :d =&gt; Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :e =&gt; Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -2.1768338876884856, 0.0, (), false), 0.0, UnknownChange())</code></pre><p>Then, a new value for <code>:a</code> will be sampled from <code>bernoulli(0.3)</code>, and a new value for <code>:b</code> will be sampled from <code>bernoulli(0.4)</code>. If the new value for <code>:b</code> is <code>true</code>, then the previous value for <code>:c</code> (<code>false</code>) will be retained. If the new value for <code>:b</code> is <code>false</code>, then a new value for <code>:d</code> will be sampled from <code>bernoulli(0.7)</code>. The previous value for <code>:c</code> will always be retained. Suppose the new value for <code>:a</code> is <code>true</code>, and the new value for <code>:b</code> is <code>true</code>. Then <code>get_choices(new_trace)</code> will be:</p><pre><code class="language-julia hljs">get_choices(new_trace)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">│
├── :a : true
│
├── :b : false
│
├── :d : false
│
└── :e : true
</code></pre><p>&lt;!– <code>│ ├── :a : true │ ├── :b : true │ ├── :c : false │ └── :e : true</code> –&gt; The weight (<code>w</code>) is <span>$\log 1 = 0$</span>.</p><h3 id="Argdiffs"><a class="docs-heading-anchor" href="#Argdiffs">Argdiffs</a><a id="Argdiffs-1"></a><a class="docs-heading-anchor-permalink" href="#Argdiffs" title="Permalink"></a></h3><p>In addition to the input trace, and other arguments that indicate how to adjust the trace, each of these methods also accepts an <strong>args</strong> argument and an <strong>argdiffs</strong> argument, both of which are tuples. The args argument contains the new arguments to the generative function, which may differ from the previous arguments to the generative function (which can be retrieved by applying <a href="../../../api/model/gfi/#Gen.get_args"><code>get_args</code></a> to the previous trace). In many cases, the adjustment to the execution specified by the other arguments to these methods is &#39;small&#39; and only affects certain parts of the computation. Therefore, it is often possible to generate the new trace and the appropriate log probability ratios required for these methods without revisiting every state of the computation of the generative function.</p><p>To enable this, the argdiffs argument provides additional information about the <em>difference</em> between each of the previous arguments to the generative function, and its new argument value. This argdiff information permits the implementation of the update method to avoid inspecting the entire argument data structure to identify which parts were updated. Note that the correctness of the argdiff is in general not verified by Gen–-passing incorrect argdiff information may result in incorrect behavior.</p><p>The trace update methods for all generative functions above should accept at least the following types of argdiffs:</p><ul><li><a href="../../../api/model/gfi/#Gen.NoChange"><code>NoChange</code></a></li><li><a href="../../../api/model/gfi/#Gen.UnknownChange"><code>UnknownChange</code></a></li></ul><p>Generative functions may also be able to process more specialized diff data types for each of their arguments, that allow more precise information about the different to be supplied.</p><h3 id="Retdiffs"><a class="docs-heading-anchor" href="#Retdiffs">Retdiffs</a><a id="Retdiffs-1"></a><a class="docs-heading-anchor-permalink" href="#Retdiffs" title="Permalink"></a></h3><p>To enable generative functions that invoke other functions to efficiently make use of incremental computation, the trace update methods of generative functions also return a <strong>retdiff</strong> value, which provides information about the difference in the return value of the previous trace an the return value of the new trace.</p><h2 id="differentiable_programming_tutorial"><a class="docs-heading-anchor" href="#differentiable_programming_tutorial">Differentiable Programming</a><a id="differentiable_programming_tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#differentiable_programming_tutorial" title="Permalink"></a></h2><p>The trace of a generative function may support computation of gradients of its log probability with respect to some subset of (i) its arguments, (ii) values of random choice, and (iii) any of its <strong>trainable parameters</strong> (see below).</p><p>To compute gradients with respect to the arguments as well as certain selected random choices, use:</p><ul><li><a href="../../../api/model/gfi/#Gen.choice_gradients"><code>choice_gradients</code></a></li></ul><p>To compute gradients with respect to the arguments, and to increment a stateful gradient accumulator for the trainable parameters of the generative function, use:</p><ul><li><a href="../../../api/model/gfi/#Gen.accumulate_param_gradients!"><code>accumulate_param_gradients!</code></a></li></ul><p>A generative function statically reports whether or not it is able to compute gradients with respect to each of its arguments, through the function <a href="../../../api/model/gfi/#Gen.has_argument_grads"><code>has_argument_grads</code></a>.</p><h3 id="Trainable-parameters"><a class="docs-heading-anchor" href="#Trainable-parameters">Trainable parameters</a><a id="Trainable-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Trainable-parameters" title="Permalink"></a></h3><p>The <strong>trainable parameters</strong> of a generative function are (unlike arguments and random choices) <em>state</em> of the generative function itself, and are not contained in the trace. Generative functions that have trainable parameters maintain <em>gradient accumulators</em> for these parameters, which get incremented by the gradient induced by the given trace by a call to <a href="../../../api/model/gfi/#Gen.accumulate_param_gradients!"><code>accumulate_param_gradients!</code></a>. Users then use these accumulated gradients to update to the values of the trainable parameters.</p><h3 id="Return-value-gradient"><a class="docs-heading-anchor" href="#Return-value-gradient">Return value gradient</a><a id="Return-value-gradient-1"></a><a class="docs-heading-anchor-permalink" href="#Return-value-gradient" title="Permalink"></a></h3><p>The set of elements (either arguments, random choices, or trainable parameters) for which gradients are available is called the <strong>gradient source set</strong>. If the return value of the function is conditionally dependent on any element in the gradient source set given the arguments and values of all other random choices, for all possible traces of the function, then the generative function requires a <em>return value gradient</em> to compute gradients with respect to elements of the gradient source set. This static property of the generative function is reported by <a href="../../../api/model/gfi/#Gen.accepts_output_grad"><code>accepts_output_grad</code></a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../modeling_in_gen/">« Introduction to Modeling in Gen</a><a class="docs-footer-nextpage" href="../combinators/">Generative Combinators »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Friday 6 September 2024 16:47">Friday 6 September 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
