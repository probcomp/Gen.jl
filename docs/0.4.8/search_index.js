var documenterSearchIndex = {"docs":
[{"location":"ref/modeling/custom_gen_fns/#custom_gen_fns","page":"Custom Generative Functions","title":"Custom Generative Functions","text":"","category":"section"},{"location":"ref/modeling/custom_gen_fns/","page":"Custom Generative Functions","title":"Custom Generative Functions","text":"Gen provides scaffolding for custom (deterministic) generative functions that make use of either incremental computation or custom gradient updates.","category":"page"},{"location":"ref/modeling/custom_gen_fns/#Gen.CustomDetermGF","page":"Custom Generative Functions","title":"Gen.CustomDetermGF","text":"CustomDetermGF{T,S} <: GenerativeFunction{T,CustomDetermGFTrace{T,S}}\n\nAbstract type for a custom deterministic generative function.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/custom_gen_fns/#Gen.CustomDetermGFTrace","page":"Custom Generative Functions","title":"Gen.CustomDetermGFTrace","text":"CustomDetermGFTrace{T,S} <: Trace\n\nTrace type for custom deterministic generative function.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/custom_gen_fns/#Custom-Incremental-Computation","page":"Custom Generative Functions","title":"Custom Incremental Computation","text":"","category":"section"},{"location":"ref/modeling/custom_gen_fns/","page":"Custom Generative Functions","title":"Custom Generative Functions","text":"A CustomUpdateGF is a generative function that allows for easier implementation of custom incremental computation.","category":"page"},{"location":"ref/modeling/custom_gen_fns/#Gen.CustomUpdateGF","page":"Custom Generative Functions","title":"Gen.CustomUpdateGF","text":"CustomUpdateGF{T,S}\n\nAbstract type for a generative function with a custom update computation, and default behaviors for all other generative function interface methods.\n\nT is the type of the return value and S is the type of state used internally for incremental computation.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/custom_gen_fns/#Gen.apply_with_state","page":"Custom Generative Functions","title":"Gen.apply_with_state","text":"retval, state = apply_with_state(gen_fn::CustomDetermGF, args)\n\nExecute the generative function and return the return value and the state.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/custom_gen_fns/#Gen.update_with_state","page":"Custom Generative Functions","title":"Gen.update_with_state","text":"state, retval, retdiff = update_with_state(gen_fn::CustomDetermGF, state, args, argdiffs)\n\nUpdate the arguments to the generative function and return new return value and state.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/custom_gen_fns/#Gen.num_args","page":"Custom Generative Functions","title":"Gen.num_args","text":"num_args(::CustomUpdateGF)\n\nReturns the number of arguments.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/custom_gen_fns/#Custom-Gradient-Computations","page":"Custom Generative Functions","title":"Custom Gradient Computations","text":"","category":"section"},{"location":"ref/modeling/custom_gen_fns/","page":"Custom Generative Functions","title":"Custom Generative Functions","text":"A CustomGradientGF is a generative function that allows for easier implementation of custom gradients computations and updates.","category":"page"},{"location":"ref/modeling/custom_gen_fns/#Gen.CustomGradientGF","page":"Custom Generative Functions","title":"Gen.CustomGradientGF","text":"CustomGradientGF{T}\n\nAbstract type for a generative function with a custom gradient computation, and default behaviors for all other generative function interface methods.\n\nT is the type of the return value.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/custom_gen_fns/#Gen.apply","page":"Custom Generative Functions","title":"Gen.apply","text":"retval = apply(gen_fn::CustomGradientGF, args)\n\nApply the function to the arguments.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/custom_gen_fns/#Gen.gradient","page":"Custom Generative Functions","title":"Gen.gradient","text":"arg_grads = gradient(gen_fn::CustomDetermGF, args, retval, retgrad)\n\nReturn the gradient tuple with respect to the arguments, where nothing is for argument(s) whose gradient is not available.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#language-implementation","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"","category":"section"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"warning: Warning\nThe API described here is internal to Gen's design and is subject to changes with no deprecation.","category":"page"},{"location":"ref/internals/language_implementation/#Parsing-@gen-functions","page":"Modeling Language Implementation","title":"Parsing @gen functions","text":"","category":"section"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"Gen's built-in modeling languages are designed to preserve Julia's syntax as far as possible, apart from the Tilde syntax for calling generative functions, and the restrictions imposed on the Static Modeling Language. In order to preserve that syntax, including the use of non-Gen macros within @gen functions, we relegate as much of the parsing of @gen functions as possible to Julia's macro-expander and parser.","category":"page"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"In particular, we adopt an implementation strategy that enforces a separation between the surface syntax associated with Gen-specific macros (i.e., @trace and @param) and their corresponding implementations, which differ across the Dynamic Modeling Language (DML) and the Static Modeling Language (SML). We do this by introducing the custom expressions Expr(:gentrace, call, addr) and Expr(:genparam, name, type), which serve as intermediate representations in the macro-expanded abstract syntax tree.","category":"page"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"Each modeling language can then handle these custom expressions in their own manner, either by parsing them to nodes in the Static Computation Graphs (for the SML), or by substituting them with their implementations (for the DML). This effectively allows the SML and DML to have separate implementations of @trace and @param.","category":"page"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"For clarity, below is a procedural description of how the @gen macro processes Julia function syntax:","category":"page"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"macroexpand the entire function body with respect to the calling module. This expands any (properly-scoped) @trace calls to Expr(:gentrace, ...) expressions, and any (properly-scoped) @param calls to Expr(:genparam, ...) expressions, while also expanding non-Gen macros.\nDesugar any tilde expressions x ~ gen_fn(), including those that may have been generated by macros, to Expr(:gentrace, ...) expressions.\nPass the macro-expanded and de-sugared function body on to make_static_gen_function or make_dynamic_gen_function accordingly.\nFor static @gen functions, match :gentrace expressions when adding address nodes to the static computation graph, and match :genparam expressions when adding parameter nodes to the static computation graph. A StaticIRGenerativeFunction is then compiled from the static computation graph.\nFor dynamic @gen functions, rewrite any :gentrace expression with its implementation dynamic_trace_impl, and rewrite any :genparam expression with its implementation dynamic_param_impl. The rewritten syntax tree is then evaluated as a standard Julia function, which serves as the implementation of the constructed DynamicDSLFunction.","category":"page"},{"location":"ref/internals/language_implementation/#Dynamic-Modeling-Language","page":"Modeling Language Implementation","title":"Dynamic Modeling Language","text":"","category":"section"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"The following methods are used to implement the semantics of the DML via non-standard interpretation:","category":"page"},{"location":"ref/internals/language_implementation/#Gen.make_dynamic_gen_function","page":"Modeling Language Implementation","title":"Gen.make_dynamic_gen_function","text":"Construct a dynamic Gen function.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.dynamic_param_impl","page":"Modeling Language Implementation","title":"Gen.dynamic_param_impl","text":"Implementation of @param for the dynamic modeling language.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.rewrite_dynamic_gen_exprs","page":"Modeling Language Implementation","title":"Gen.rewrite_dynamic_gen_exprs","text":"Rewrites :gentrace and :genparam with their dynamic implementations.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.dynamic_trace_impl","page":"Modeling Language Implementation","title":"Gen.dynamic_trace_impl","text":"Implementation of @trace for the dynamic modeling language.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.arg_to_ast","page":"Modeling Language Implementation","title":"Gen.arg_to_ast","text":"Convert Argument structs to ASTs.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.escape_default","page":"Modeling Language Implementation","title":"Gen.escape_default","text":"Escape argument defaults (if present).\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.state","page":"Modeling Language Implementation","title":"Gen.state","text":"Global reference to the GFI state for the dynamic modeling language.\n\n\n\n\n\n","category":"constant"},{"location":"ref/internals/language_implementation/#Gen.choice_or_call_at","page":"Modeling Language Implementation","title":"Gen.choice_or_call_at","text":"Construct choice-at or call-at combinator depending on type.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Static-Modeling-Language","page":"Modeling Language Implementation","title":"Static Modeling Language","text":"","category":"section"},{"location":"ref/internals/language_implementation/","page":"Modeling Language Implementation","title":"Modeling Language Implementation","text":"The following methods are used to parse functions written in the SML into static computation graphs:","category":"page"},{"location":"ref/internals/language_implementation/#Gen.StaticIRGenerativeFunction","page":"Modeling Language Implementation","title":"Gen.StaticIRGenerativeFunction","text":"StaticIRGenerativeFunction{T,U} <: GenerativeFunction{T,U}\n\nAbstact type for a static IR generative function with return type T and trace type U.\n\nContains an intermediate representation based on a directed acyclic graph. Most generative function interface methods are generated from the intermediate representation.\n\n\n\n\n\n","category":"type"},{"location":"ref/internals/language_implementation/#Gen.make_static_gen_function","page":"Modeling Language Implementation","title":"Gen.make_static_gen_function","text":"Generates the code that builds the IR of a static Gen function.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.gen_node_name","page":"Modeling Language Implementation","title":"Gen.gen_node_name","text":"Generate informative node name for a Julia expression.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_static_dsl_line!","page":"Modeling Language Implementation","title":"Gen.parse_static_dsl_line!","text":"Parse line (i.e. top-level expression) of a static Gen function body.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_typed_var","page":"Modeling Language Implementation","title":"Gen.parse_typed_var","text":"Parse optionally typed variable expressions.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_julia_expr!","page":"Modeling Language Implementation","title":"Gen.parse_julia_expr!","text":"Parse a Julia expression and add a corresponding node to the IR.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_param_line!","page":"Modeling Language Implementation","title":"Gen.parse_param_line!","text":"Parse @param line and add corresponding trainable param node.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_trace_expr!","page":"Modeling Language Implementation","title":"Gen.parse_trace_expr!","text":"Parse @trace expression and add corresponding node to IR.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_and_rewrite_trace!","page":"Modeling Language Implementation","title":"Gen.parse_and_rewrite_trace!","text":"Parse and rewrite expression if it matches an @trace call.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_assignment_line!","page":"Modeling Language Implementation","title":"Gen.parse_assignment_line!","text":"Parse assignments and add corresponding nodes for the right-hand-side.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_return_line!","page":"Modeling Language Implementation","title":"Gen.parse_return_line!","text":"Parse a return line and add corresponding return node.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.parse_static_dsl_function_body!","page":"Modeling Language Implementation","title":"Gen.parse_static_dsl_function_body!","text":"Parse static Gen function body line by line.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.split_addr!","page":"Modeling Language Implementation","title":"Gen.split_addr!","text":"Split nested addresses into list of keys.\n\n\n\n\n\n","category":"function"},{"location":"ref/internals/language_implementation/#Gen.resolve_symbols","page":"Modeling Language Implementation","title":"Gen.resolve_symbols","text":"Look-up and return node names bound to each symbol in an expression.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/enumerative/#enumerative_tutorial","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumerative Inference","text":"","category":"section"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"When working with probabilistic models, we often rely on Monte Carlo methods like importance sampling (as introduced in Introduction to Modeling) and MCMC (as introduced in Basics of MCMC) to approximate posterior distributions. But how can we tell if these approximations are actually working correctly? Sometimes poor inference results stem from bugs in our inference algorithms, while other times they reveal fundamental issues with our model specification.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"This tutorial introduces enumerative inference as a debugging tool. Unlike the sampling-based methods we've seen in previous tutorials, which draw samples that are approximately distributed according to the posterior distribution over latent values, enumerative inference systematically evaluates the posterior probability of every value in the latent space (or a discretized version of this space).","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"When the latent space isn't too large (e.g. not too many dimensions), this approach can compute a \"gold standard\" posterior approximation that other methods can be compared against, helping us distinguish between inference failures and model misspecification. Enumerative inference is often slower than a well-tuned Monte Carlo algorithm (since it may enumerate over regions with very low probability), but having a gold-standard posterior allows us to check that faster and more efficient algorithms are working correctly.","category":"page"},{"location":"tutorials/enumerative/#Enumeration-for-Discrete-Models","page":"Debugging Models with Enumeration","title":"Enumeration for Discrete Models","text":"","category":"section"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Let's start with a simple example where enumeration can be used to perform exact inference, computing the exact posterior probability for every possible combination of discrete latent variables. We'll build a robust Bayesian linear regression model, but unlike the continuous model from the MCMC tutorial, we'll use discrete priors for all latent variables.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"@gen function discrete_regression(xs::Vector{<:Real})\n    # Discrete priors for slope and intercept\n    slope ~ uniform_discrete(-2, 2)  # Slopes: -2, -1, 0, 1, 2\n    intercept ~ uniform_discrete(-2, 2)  # Intercepts: -2, -1, 0, 1, 2\n    \n    # Sample outlier classification and y value for each x value\n    n = length(xs)\n    ys = Float64[]\n    for i = 1:n\n        # Prior on outlier probability\n        is_outlier = {:data => i => :is_outlier} ~ bernoulli(0.1)\n        \n        if is_outlier\n            # Outliers have large noise\n            y = {:data => i => :y} ~ normal(0., 5.)\n        else\n            # Inliers follow the linear relationship, with low noise\n            y_mean = slope * xs[i] + intercept\n            y = {:data => i => :y} ~ normal(y_mean, 1.)\n        end\n        push!(ys, y)\n    end\n    \n    return ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Let's generate some synthetic data with a true slope of 1 and intercept of 0:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Generate synthetic data\ntrue_slope = 1\ntrue_intercept = 0\nxs = [-2., -1., 0., 1., 2.]\nys = true_slope .* xs .+ true_intercept .+ 1.0 * randn(5)\n\n# Make one point an outlier\nys[3] = 4.0\n\n# Visualize the data\npoint_colors = [:blue, :blue, :red, :blue, :blue]\nscatter(xs, ys, label=\"Observations\", markersize=6, xlabel=\"x\", ylabel=\"y\",\n        color=point_colors)\nplot!(xs, true_slope .* xs .+ true_intercept, \n      label=\"True line\", linestyle=:dash, linewidth=2, color=:black)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Now we can use enumerative inference to compute the exact posterior. We'll enumerate over all possible combinations of slope, intercept, and outlier classifications:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Create observations choicemap\nobservations = choicemap()\nfor (i, y) in enumerate(ys)\n    observations[:data => i => :y] = y\nend\n\n# Set up the enumeration grid\n# We enumerate over discrete slope, intercept, and outlier classifications\ngrid_specs = Tuple[\n    (:slope, -2:2),  # 5 possible slopes\n    (:intercept, -2:2),  # 3 possible intercepts\n]\nfor i in 1:length(xs)\n    push!(grid_specs, (:data => i => :is_outlier, [false, true]))\nend\n\n# Create the enumeration grid\ngrid = choice_vol_grid(grid_specs...)\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Here, we used choice_vol_grid to enumerate over all possible combinations of slope, intercept, and outlier classifications. The resulting grid object is a multi-dimensional iterator, where each element consists of a ChoiceMap that specifies the values of all latent variables, and the log-volume of latent space covered by that element of the grid. Since all latent variables are discrete, the volume of latent space covered by each element is equal to 1 (and hence the log-volume is 0). We can inspect the first element of this grid using the first function:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"choices, log_vol = first(grid)\nprintln(\"Log volume: \", log_vol)\nprintln(\"Choices: \")\nshow(stdout, \"text/plain\", choices)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Having constructed the enumeration grid, we now pass this to the enumerative_inference function, along with the generative model (discrete_regression), model arguments (in this case, xs), and the observations:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Run enumerative inference\ntraces, log_norm_weights, lml_est = \n    enumerative_inference(discrete_regression, (xs,), observations, grid)\n\nprintln(\"Grid size: \", size(grid))\nprintln(\"Log marginal likelihood: \", lml_est)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"The enumerative_inference function returns an array of traces and an array of normalized log posterior probabilities (log_norm_weights) with the same shape as the input grid. It also returns an estimate of the log marginal likelihood (lml_est) of the observations. The estimate is exact in this case, since we enumerated over all possible combinations of latent variables.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Each trace corresponds to a full combination of the latent variables that were enumerated over. As such, the log_norm_weights array represents the joint posterior distribution over all latent variables. By summing over all traces which have the same value for a specific latent variable (or equivalently, by summing over a dimension of the log_norm_weights array), we can compute the marginal posterior distribution for that variable.  We'll do this below for the slope and intercept variables:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Compute 2D marginal posterior over slope and intercept\nsum_dims = Tuple(3:ndims(log_norm_weights)) # Sum over all other variables\nposterior_grid = sum(exp.(log_norm_weights), dims=sum_dims)\nposterior_grid = dropdims(posterior_grid; dims=sum_dims)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Let's visualize the marginal posteriors over these variables, as well the joint posterior for both variables together. Below is some code to plot a 2D posterior heatmap with 1D marginals as histograms.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"<details> <summary>Code to plot 2D grid of posterior values</summary>","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"using Plots\n\nfunction plot_posterior_grid(\n    x_range, y_range, xy_probs;\n    is_discrete = true, x_true = missing, y_true = missing,\n    xlabel = \"\", ylabel = \"\"\n)\n    # Create the main heatmap\n    p_main = heatmap(x_range, y_range, xy_probs, colorbar=false, widen=false,\n                     color=:grays, xlabel=xlabel, ylabel=ylabel)\n    if is_discrete\n        # Add true parameters\n        scatter!(p_main, [x_true], [y_true], legend=true,\n                 markersize=36, markershape=:rect, color=:white,\n                 markerstrokecolor=:red, label=\"True Parameters\")\n        # Annotate each cell with its posterior probability\n        for idx in CartesianIndices(xy_probs)\n            i, j = Tuple(idx)\n            prob_str = @sprintf(\"%.3f\", xy_probs[j, i])\n            prob_color = xy_probs[j, i] > 0.2 ? :black : :white\n            annotate!(x_range[i], y_range[j],\n                      text(prob_str, color = prob_color, pointsize=12))\n        end\n    else\n        # Add true parameters\n        if !ismissing(x_true) && !ismissing(y_true)    \n            scatter!(p_main, [x_true], [y_true], legend=true,\n                     markersize=6, color=:red, markershape=:cross,\n                     label=\"True Parameters\")\n        end\n        if !ismissing(x_true)\n            vline!([x_true], linestyle=:dash, linewidth=1, color=:red,\n                   label=\"\", alpha=0.5)\n        end\n        if !ismissing(y_true)\n            hline!([y_true], linestyle=:dash, linewidth=1, color=:red,\n                   label=\"\", alpha=0.5)\n        end\n    end\n\n    # Create 1D marginal histograms\n    x_probs = vec(sum(xy_probs, dims=1))\n    y_probs = vec(sum(xy_probs, dims=2))\n    p_top = bar(x_range, x_probs, orientation=:v, ylims=(0, maximum(x_probs)),\n                bar_width=diff(x_range)[1], linewidth=0, color=:black,\n                showaxis=true, ticks=false, legend=false, widen=false)\n    p_right = bar(y_range, y_probs, orientation=:h, xlims=(0, maximum(y_probs)),\n                  bar_width=diff(y_range)[1], linewidth=0, color=:black,\n                  showaxis=true, ticks=false, legend=false, widen=false)\n    if !is_discrete\n        xlims!(p_top, xlims(p_main))\n        ylims!(p_right, ylims(p_main))\n        if !ismissing(x_true)\n            vline!(p_top, [x_true], linestyle=:dash,\n                   linewidth=1, color=:red, legend=false)\n        end\n        if !ismissing(y_true)\n            hline!(p_right, [y_true], linestyle=:dash,\n                   linewidth=1, color=:red, legend=false)\n        end\n    end\n\n    # Create empty plot for top-right corner\n    p_empty = plot(legend=false, grid=false, showaxis=false, ticks=false)\n\n    # Combine plots using layout\n    plot(p_top, p_empty, p_main, p_right, \n         layout=@layout([a{0.9w,0.1h} b{0.1w,0.1h}; c{0.9w,0.9h} d{0.1w,0.9h}]),\n         size=(750, 750))\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"</details>","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Extract parameter ranges\nslope_range = [trs[1][:slope] for trs in eachslice(traces, dims=1)]\nintercept_range = [trs[1][:intercept] for trs in eachslice(traces, dims=2)]\n\n# Plot 2D posterior heatmap with 1D marginals as histograms\nplot_posterior_grid(intercept_range, slope_range, posterior_grid,\n                    x_true = true_intercept, y_true = true_slope,\n                    xlabel = \"Intercept\", ylabel = \"Slope\",\n                    is_discrete = true)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"As can be seen, the posterior concentrates around the true values of the slope and intercept, though there is some uncertainty about both.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"We can also examine which points are most likely to be outliers:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Compute posterior probability of each point being an outlier\noutlier_probs = zeros(length(xs))\nfor (j, trace) in enumerate(traces)\n    for i in 1:length(xs)\n        if trace[:data => i => :is_outlier]\n            outlier_probs[i] += exp(log_norm_weights[j])\n        end\n    end\nend\n\nbar(1:length(xs), outlier_probs, \n    xlabel=\"x\", ylabel=\"P(outlier | data)\",\n    color=:black, ylim=(0, 1), legend=false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Notice that enumerative inference correctly identifies that point 3 (which we made an outlier) has a high probability of being an outlier, while maintaining uncertainty about the exact classifications.","category":"page"},{"location":"tutorials/enumerative/#Enumeration-for-Continuous-Models","page":"Debugging Models with Enumeration","title":"Enumeration for Continuous Models","text":"","category":"section"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Many generative models of interest have continuous latent variables. While we can't enumerate over continuous spaces exactly, we can create a discrete approximation of a continuous target distribution by defining a grid. Let's extend our model to use continuous priors:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"@gen function continuous_regression(xs::Vector{<:Real})\n    # Continuous slope and intercept priors\n    slope ~ normal(0, 1)\n    intercept ~ normal(0, 2)\n    \n    # Sample outlier classification and y value for each x value\n    n = length(xs)\n    ys = Float64[]\n    for i = 1:n\n        # Prior on outlier probability\n        is_outlier = {:data => i => :is_outlier} ~ bernoulli(0.1)\n        \n        if is_outlier\n            # Outliers have large noise\n            y = {:data => i => :y} ~ normal(0., 5.)\n        else\n            # Inliers follow the linear relationship, with low noise\n            y_mean = slope * xs[i] + intercept\n            y = {:data => i => :y} ~ normal(y_mean, 1.)\n        end\n        push!(ys, y)\n    end\n    \n    return ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"We now construct a grid over the latent space using choice_vol_grid. For continuous variables, we need to provide a range of grid points (including start and end points), and specify that the variable is :continuous:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"grid = choice_vol_grid(\n    (:slope, -3:0.25:3, :continuous),  # 24 grid intervals\n    (:intercept, -4:0.5:4, :continuous),  # 16 grid intervals\n    # Still enumerate exactly over outlier classifications\n    (:data => 1 => :is_outlier, [false, true]),\n    (:data => 2 => :is_outlier, [false, true]),\n    (:data => 3 => :is_outlier, [false, true]),\n    (:data => 4 => :is_outlier, [false, true]),\n    (:data => 5 => :is_outlier, [false, true]);\n    anchor = :midpoint # Anchor evaluation point at midpoint of each interval\n)\n\nprintln(\"Grid size for continuous model: \", size(grid))\nprintln(\"Number of grid elements: \", length(grid))","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"When some variables are specified as :continuous, the choice_vol_grid function automatically computes the log-volume of each grid cell. Inspecting the first element of the grid, we see that the log-volume is equal to log(0.25 * 0.5) ≈ -2.0794, since that grid cell is covers a volume of 0.25 * 0.5 = 0.125 of the slope-intercept latent space. We also see that the slope and intercept variables lie at the midpoint of this grid cell, since the anchor keyword argument was set to :midpoint:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"choices, log_vol = first(grid)\nprintln(\"Log volume: \", log_vol)\nprintln(\"Choices: \")\nchoices","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Now let's generate some synthetic data to do inference on. We'll use ground-truth continuous parameters that don't lie exactly on the grid, in order to show that enumerative inference can still produce a reasonable approximation when the posterior is sufficiently smooth.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Generate synthetic data\ntrue_slope = -1.21\ntrue_intercept = 2.56\nxs = [-2., -1., 0., 1., 2.]\nys = true_slope .* xs .+ true_intercept .+ 1.0 * randn(5)\n\n# Make one point an outlier\nys[2] = 0.\n\n# Create observations choicemap\nobservations = choicemap()\nfor (i, y) in enumerate(ys)\n    observations[:data => i => :y] = y\nend\n\n# Visualize the data\npoint_colors = [:blue, :red, :blue, :blue, :blue]\nscatter(xs, ys, label=\"Observations\", markersize=6, xlabel=\"x\", ylabel=\"y\",\n        color=point_colors)\nplot!(xs, true_slope .* xs .+ true_intercept, \n      label=\"True line\", linestyle=:dash, linewidth=2, color=:black)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"As in the discrete case, we can use enumerative_inference to perform inference on the continuous model:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Run inference on the continuous model\ntraces, log_norm_weights, lml_est = \n    enumerative_inference(continuous_regression, (xs,), observations, grid)\n\nprintln(\"Log marginal likelihood: \", lml_est)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Again, we can visualize the joint posterior over the slope and intercept variables with the help of some plotting code.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Compute marginal posterior over slope and intercept\nsum_dims = Tuple(3:ndims(log_norm_weights)) # Sum over all other variables\nposterior_grid = sum(exp.(log_norm_weights), dims=sum_dims)\nposterior_grid = dropdims(posterior_grid; dims=sum_dims)\n\n# Extract parameter ranges\nslope_range = [trs[1][:slope] for trs in eachslice(traces, dims=1)]\nintercept_range = [trs[1][:intercept] for trs in eachslice(traces, dims=2)]\n\n# Plot 2D posterior heatmap with 1D marginals as histograms\np = plot_posterior_grid(intercept_range, slope_range, posterior_grid,\n                    x_true = true_intercept, y_true = true_slope,\n                    xlabel = \"Intercept\", ylabel = \"Slope\", is_discrete = false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"We can see that the true parameters lie in a cell with reasonably high posterior probability, though there is a fair amount of uncertainty due to bimodal nature of the posterior distribution. This manifests in the posterior over outlier classifications as well:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Compute posterior probability of each point being an outlier\noutlier_probs = zeros(length(xs))\nfor i = 1:length(xs)\n    for (j, trace) in enumerate(traces)\n        if trace[:data => i => :is_outlier]\n            outlier_probs[i] += exp(log_norm_weights[j])\n        end\n    end\nend\n\n# Plot posterior probability of each point being an outlier\nbar(1:length(xs), outlier_probs, \n    xlabel=\"x\", ylabel=\"P(outlier | data)\",\n    color=:black, ylim=(0, 1), legend=false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"The points at both x=1 and x=2 are inferred to be possible outliers, corresponding to each possible mode of the full posterior distribution. By extracting the slice of the log_norm_weights array that corresponds to x=2 being an outlier (i.e., when data => 2 => :is_outlier is true), we can visualize the posterior distribution over the slope and intercept variables conditional on x=2 being an outlier. As shown below, this conditional posterior is no longer bimodal, and concentrates more closely around the true parameters.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Extract slice of weights corresponding to x=2 being an outlier\ncond_log_norm_weights = log_norm_weights[:,:,:,end:end,:,:,:]\n\n# Compute marginal posterior over slope & intercept given that x=2 is an outlier\nsum_dims = Tuple(3:ndims(cond_log_norm_weights)) # Sum over all other variables\nposterior_grid = sum(exp.(cond_log_norm_weights), dims=sum_dims)\nposterior_grid = dropdims(posterior_grid; dims=sum_dims)\n\n# Extract parameter ranges\nslope_range = [trs[1][:slope] for trs in eachslice(traces, dims=1)]\nintercept_range = [trs[1][:intercept] for trs in eachslice(traces, dims=2)]\n\n# Plot 2D posterior heatmap with 1D marginals as histograms\nplot_posterior_grid(intercept_range, slope_range, posterior_grid,\n                    x_true = true_intercept, y_true = true_slope,\n                    xlabel = \"Intercept\", ylabel = \"Slope\", is_discrete = false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Instead of extracting a slice of the full weight array, we could also have used choice_vol_grid to construct an enumeration grid with data => 2 => :is_outlier constrained to true, and then called enumerative_inference with this conditional grid. This ability to compute conditional posteriors is another useful aspect of enumerative inference: Even when the latent space becomes too high-dimensional for enumeration over the full joint posterior, we can still inspect the conditional posteriors over some variables conditioned on the values of other variables, and check whether they make sense.","category":"page"},{"location":"tutorials/enumerative/#Diagnosing-Model-Misspecification","page":"Debugging Models with Enumeration","title":"Diagnosing Model Misspecification","text":"","category":"section"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"As we have seen above, enumerative inference allows us to approximate a posterior distribution with a high degree of fidelity (at the expense of additional computation). This allows us to distinguish between two ways that inference in a Bayesian model can go wrong:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Inference Failure: The inference algorithm fails to approximate the true posterior distribution well (e.g. due to a bad importance sampling proposal, a poorly-designed MCMC kernel, or insufficient computation).\nModel Misspecification: The Bayesian model itself is misspecified, such that the true posterior distribution does not correspond with our intuitions about what the posterior should look like.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Both of these issues can occur at the same time: an algorithm might fail to converge to the true posterior, and the model might be misspecified. Regardless, since enumerative inference can approximate the true posterior distribution arbitrarily well (by making the grid arbitrarily large and fine), we can use it to check whether some other algorithm converges to the true posterior, and also whether the true posterior itself concords with our intuitions.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"As a demonstration, let us write a version of the continuous regression model with narrow slope and intercept priors, and a high probability of outliers:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"@gen function misspecified_regression(xs::Vector{<:Real})\n    # Narrow slope and intercept priors\n    slope ~ normal(0, sqrt(0.5))\n    intercept ~ normal(0, sqrt(0.5))\n    \n    # Sample outlier classification and y value for each x value\n    n = length(xs)\n    ys = Float64[]\n    for i = 1:n\n        # High (25% chance) prior probability of being an outlier\n        is_outlier = {:data => i => :is_outlier} ~ bernoulli(0.25)\n        \n        if is_outlier\n            # Outliers have large noise\n            y = {:data => i => :y} ~ normal(0., 5.)\n        else\n            # Inliers follow the linear relationship, with low noise\n            y_mean = slope * xs[i] + intercept\n            y = {:data => i => :y} ~ normal(y_mean, 1.)\n        end\n        push!(ys, y)\n    end\n    \n    return ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"To create a case where the model is misspecified, we generate data with a steep slope and a large intercept, but no outliers:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Generate synthetic data\ntrue_slope = 2.8\ntrue_intercept = -2.4\nxs = [-2., -1., 0., 1., 2.]\nys = true_slope .* xs .+ true_intercept .+ 1.0 * randn(5)\n\n# Create observations choicemap\nobservations = choicemap()\nfor (i, y) in enumerate(ys)\n    observations[:data => i => :y] = y\nend\n\n# Visualize the data\npoint_colors = [:blue, :blue, :blue, :blue, :blue]\nscatter(xs, ys, label=\"Observations\", markersize=6, xlabel=\"x\", ylabel=\"y\",\n        color=point_colors)\nplot!(xs, true_slope .* xs .+ true_intercept, \n      label=\"True line\", linestyle=:dash, linewidth=2, color=:black)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Now let us try using importance_resampling to approximate the posterior distribution under the misspecified model:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Try importance resampling with 2000 inner samples and 100 outer samples\nprintln(\"Running importance sampling...\")\ntraces = [importance_resampling(misspecified_regression, (xs,), observations, 2000)[1] for i in 1:100]\n\n# Compute the mean slope and intercept\nmean_slope = sum(trace[:slope] for trace in traces) / length(traces)\nmean_intercept = sum(trace[:intercept] for trace in traces) / length(traces)\n\nprintln(\"Mean slope: \", mean_slope)\nprintln(\"Mean intercept: \", mean_intercept)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Instead of recovering anything close to the true parameters, importance sampling infers a much smaller mean for the slope and intercept. We can also visualize the joint posterior over the slope and intercept by plotting a 2D histogram from the samples:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"<details> <summary>Code to plot posterior samples</summary>","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"function plot_posterior_samples(\n    x_range, y_range, x_values, y_values;\n    x_true = missing, y_true = missing,\n    xlabel = \"\", ylabel = \"\"\n)\n    # Create the main heatmap\n    p_main = histogram2d(x_values, y_values, bins=(x_range, y_range),\n                         show_empty_bins=true, normalize=:probability,\n                         color=:grays, colorbar=false, legend=false,\n                         xlabel=xlabel, ylabel=ylabel)\n    xlims!(p_main, minimum(x_range), maximum(x_range))\n    ylims!(p_main, minimum(y_range), maximum(y_range))\n    # Add true parameters\n    if !ismissing(x_true) && !ismissing(y_true)    \n        scatter!(p_main, [true_intercept], [true_slope], \n                 markersize=6, color=:red, markershape=:cross,\n                 label=\"True Parameters\", legend=true)\n    end\n    if !ismissing(x_true)\n        vline!([x_true], linestyle=:dash, linewidth=1, color=:red,\n                label=\"\", alpha=0.5)\n    end\n    if !ismissing(y_true)\n        hline!([y_true], linestyle=:dash, linewidth=1, color=:red,\n                label=\"\", alpha=0.5)\n    end\n\n    # Create 1D marginal histograms\n    p_top = histogram(x_values, bins=x_range, orientation=:v, legend=false,\n                      normalize=:probability, linewidth=0, color=:black,\n                      showaxis=true, ticks=false)\n    x_probs_max = maximum(p_top.series_list[2].plotattributes[:y])\n    ylims!(p_top, 0, x_probs_max)\n    xlims!(p_top, minimum(x_range), maximum(x_range))\n    p_right = histogram(y_values, bins=y_range, orientation=:h, legend=false,\n                        normalize=:probability, linewidth=0, color=:black,\n                        showaxis=true, ticks=false)\n    y_probs_max = maximum(p_right.series_list[2].plotattributes[:y])\n    xlims!(p_right, 0, y_probs_max)\n    ylims!(p_right, minimum(y_range), maximum(y_range))\n    # Add true parameters\n    if !ismissing(x_true)\n        vline!(p_top, [x_true], linestyle=:dash,\n               linewidth=1, color=:red, legend=false)\n    end\n    if !ismissing(y_true)\n        hline!(p_right, [y_true], linestyle=:dash,\n               linewidth=1, color=:red, legend=false)\n    end\n\n    # Create empty plot for top-right corner\n    p_empty = plot(legend=false, grid=false, showaxis=false, ticks=false)\n\n    # Combine plots using layout\n    plot(p_top, p_empty, p_main, p_right, \n         layout=@layout([a{0.9w,0.1h} b{0.1w,0.1h}; c{0.9w,0.9h} d{0.1w,0.9h}]),\n         size=(750, 750))\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"</details>","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Plot a 2D histogram for the slope and intercept variables\nslopes = [trace[:slope] for trace in traces]\nintercepts = [trace[:intercept] for trace in traces]\nplot_posterior_samples(-4:0.25:4, -4:0.25:4, intercepts, slopes,\n                       x_true=true_intercept, y_true=true_slope,\n                       xlabel=\"Intercept\", ylabel=\"Slope\")","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"The distribution of samples produced by importance sampling lies far from the true slope and intercept, and concentrates around values that do not intuitively make sense given the data. The distribution over outlier classifications sheds some light on the problem:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Estimate posterior probability of each point being an outlier\noutlier_probs = zeros(length(xs))\nfor i = 1:length(xs)\n    for (j, trace) in enumerate(traces)\n        if trace[:data => i => :is_outlier]\n            outlier_probs[i] += 1/length(traces)\n        end\n    end\nend\n\n# Plot posterior probability of each point being an outlier\nbar(1:length(xs), outlier_probs, \n    xlabel=\"x\", ylabel=\"P(outlier | data)\",\n    color=:black, ylim=(0, 1), legend=false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Importance sampling infers that many of the points are likely to be outliers. That is, instead of inferring a steep slope and a negative intercept, importance sampling prefers to explain the data as a flatter line with many outliers. ","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"These inferences are indicative of model misspecification. Still, we can't be confident that this isn't just an inference failure. After all, we used importance sampling with the prior as our proposal distribution. Since the prior over slopes and intercepts is very narrow, it is very likely that none of the 2000 inner samples used by importance_resampling came close to the true slope and intercept. So it is possible that the issues above arise because importance sampling fails to produce a good approximation of the true posterior.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Before using enumerative inference to resolve this ambiguity, let us try using an MCMC inference algorithm, which might avoid the inference failures of importance sampling by exploring a broader region of the latent space. Similar to the tutorial on MCMC, we'll use an MCMC kernel that performs Gaussian drift on the continuous parameters, followed by block resimulation on the outlier classifications:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"@gen function line_proposal(trace)\n    slope ~ normal(trace[:slope], 0.5)\n    intercept ~ normal(trace[:intercept], 0.5)\nend\n\nfunction mcmc_kernel(trace)\n    # Gaussian drift on line parameters\n    (trace, _) = mh(trace, line_proposal, ())\n    \n    # Block resimulation: Update the outlier classifications\n    (xs,) = get_args(trace)\n    n = length(xs)\n    for i=1:n\n        (trace, _) = mh(trace, select(:data => i => :is_outlier))\n    end\n    return trace\nend\n\nfunction mcmc_sampler(kernel, trace, n_iters::Int, n_burnin::Int = 0)\n    traces = Vector{typeof(trace)}()\n    for i in 1:(n_iters + n_burnin)\n        trace = kernel(trace)\n        if i > n_burnin\n            push!(traces, trace)\n        end\n    end\n    return traces\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"In addition, we will intiialize MCMC at the true slope and intercept. This way, we can rule out the possibility that MCMC never explores the region of latent space near the true parameters.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Generate initial trace at true slope and intercept\nconstraints = choicemap(\n    :slope => true_slope,\n    :intercept => true_intercept\n)\nconstraints = merge(constraints, observations)\n(trace, _) = Gen.generate(misspecified_regression, (xs,), constraints)\n\n# Run MCMC for 10,000 iterations with a burn-in of 500\ntraces = mcmc_sampler(mcmc_kernel, trace, 10000, 500)\n\n# Compute the mean slope and intercept\nmean_slope = sum(trace[:slope] for trace in traces) / length(traces)\nmean_intercept = sum(trace[:intercept] for trace in traces) / length(traces)\n\nprintln(\"Mean slope: \", mean_slope)\nprintln(\"Mean intercept: \", mean_intercept)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Like importance sampling, MCMC infers a much smaller slope and intercept than the true parameters. Let us visualize the joint posterior.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Plot posterior samples\nslopes = [trace[:slope] for trace in traces]\nintercepts = [trace[:intercept] for trace in traces]\nplot_posterior_samples(-4:0.25:4, -4:0.25:4, intercepts, slopes,\n                       x_true=true_intercept, y_true=true_slope,\n                       xlabel=\"Intercept\", ylabel=\"Slope\")","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Let us also plot the inferred outlier probabilities:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Estimate posterior probability of each point being an outlier\noutlier_probs = zeros(length(xs))\nfor i = 1:length(xs)\n    for (j, trace) in enumerate(traces)\n        if trace[:data => i => :is_outlier]\n            outlier_probs[i] += 1/length(traces)\n        end\n    end\nend\n\n# Plot posterior probability of each point being an outlier\nbar(1:length(xs), outlier_probs, \n    xlabel=\"x\", ylabel=\"P(outlier | data)\",\n    color=:black, ylim=(0, 1), legend=false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Both MCMC and importance sampling produce similar inferences, inferring a flat slope with many outliers rather than a steep slope with few outliers. This is despite the fact that MCMC was initialized at the true parameters, strongly indicating that model misspecification is at play here.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"In general, however, we don't have access to the true parameters, nor do we always know if MCMC will converge to the posterior given a finite sample budget. To decisively diagnose model misspecification, we now use enumerative inference with a sufficiently fine grid, ensuring systemic coverage over the latent space.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Construct enumeration grid\ngrid = choice_vol_grid(\n    (:slope, -4:0.25:4, :continuous),  # 32 grid intervals\n    (:intercept, -4:0.25:4, :continuous),  # 32 grid intervals\n    # Enumerate exactly over outlier classifications\n    (:data => 1 => :is_outlier, [false, true]),\n    (:data => 2 => :is_outlier, [false, true]),\n    (:data => 3 => :is_outlier, [false, true]),\n    (:data => 4 => :is_outlier, [false, true]),\n    (:data => 5 => :is_outlier, [false, true]);\n    anchor = :midpoint # Anchor evaluation point at midpoint of each interval\n)\n\n# Run enumerative inference\ntraces, log_norm_weights, lml_est = \n    enumerative_inference(misspecified_regression, (xs,), observations, grid)\n\n# Compute marginal posterior over slope and intercept\nsum_dims = Tuple(3:ndims(log_norm_weights)) # Sum over all other variables\nposterior_grid = sum(exp.(log_norm_weights), dims=sum_dims)\nposterior_grid = dropdims(posterior_grid; dims=sum_dims)\n\n# Extract parameter ranges\nslope_range = [trs[1][:slope] for trs in eachslice(traces, dims=1)]\nintercept_range = [trs[1][:intercept] for trs in eachslice(traces, dims=2)]\n\n# Plot 2D posterior heatmap with 1D marginals as histograms\nplot_posterior_grid(intercept_range, slope_range, posterior_grid,\n                    x_true = true_intercept, y_true = true_slope,\n                    xlabel = \"Intercept\", ylabel = \"Slope\", is_discrete = false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"While enumerative inference produces a posterior approximation that is smoother than both importance sampling and MCMC, it still assigns a very low posterior density to the true slope and intercept. Inspecting the outlier classifications, we see that many points are inferred as likely outliers:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Compute posterior probability of each point being an outlier\noutlier_probs = zeros(length(xs))\nfor (j, trace) in enumerate(traces)\n    for i in 1:length(xs)\n        if trace[:data => i => :is_outlier]\n            outlier_probs[i] += exp(log_norm_weights[j])\n        end\n    end\nend\n\nbar(1:length(xs), outlier_probs, \n    xlabel=\"x\", ylabel=\"P(outlier | data)\",\n    color=:black, ylim=(0, 1), legend=false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"This confirms that model misspecification is the underlying issue: The generative model we wrote doesn't capture our intuitions about what posterior inference from the data should give us.","category":"page"},{"location":"tutorials/enumerative/#Addressing-Model-Misspecification","page":"Debugging Models with Enumeration","title":"Addressing Model Misspecification","text":"","category":"section"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Now that we know our model is misspecified, how do we fix it? In the specific example we considered, the priors over the slope and intercept are too narrow, whereas the outlier probability is too high. A straightforward fix would thus be to widen the slope and intercept priors, while lowering the outlier probability.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"However, this change might not generalize to other sets of observations. If some data really is well-characterized by a shallow slope with many outliers, we would like to infer this as well. A more robust solution then, is to introduce hyper-priors: Priors on the parameters of the slope and intercept priors and the outlier probability. Adding hyper-priors results in a hierarchical Bayesian model:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"@gen function h_bayes_regression(xs::Vector{<:Real})\n    # Hyper-prior on slope and intercept prior variances\n    slope_var ~ inv_gamma(1, 1)\n    intercept_var ~ inv_gamma(1, 1)\n    # Slope and intercept priors\n    slope ~ normal(0, sqrt(slope_var))\n    intercept ~ normal(0, sqrt(intercept_var))\n    # Prior on outlier probability\n    prob_outlier ~ beta(1, 1)\n    \n    # Sample outlier classification and y value for each x value\n    n = length(xs)\n    ys = Float64[]\n    for i = 1:n\n        # Sample outlier classification\n        is_outlier = {:data => i => :is_outlier} ~ bernoulli(prob_outlier)\n        \n        if is_outlier\n            # Outliers have large noise\n            y = {:data => i => :y} ~ normal(0., 5.)\n        else\n            # Inliers follow the linear relationship, with low noise\n            y_mean = slope * xs[i] + intercept\n            y = {:data => i => :y} ~ normal(y_mean, 1.)\n        end\n        push!(ys, y)\n    end\n    \n    return ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Let's run enumerative inference on this expanded model, using a coarser grid to compensate for the increased dimensionality of the latent space:","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Construct enumeration grid\ngrid = choice_vol_grid(\n    (:slope, -4:1:4, :continuous),  # 8 grid intervals\n    (:intercept, -4:1:4, :continuous),  # 8 grid intervals\n    (:slope_var, 0:1:5, :continuous),  # 5 grid intervals\n    (:intercept_var, 0:1:5, :continuous),  # 5 grid intervals\n    (:prob_outlier, 0.0:0.2:1.0, :continuous),  # 5 grid intervals\n    # Enumerate exactly over outlier classifications\n    (:data => 1 => :is_outlier, [false, true]),\n    (:data => 2 => :is_outlier, [false, true]),\n    (:data => 3 => :is_outlier, [false, true]),\n    (:data => 4 => :is_outlier, [false, true]),\n    (:data => 5 => :is_outlier, [false, true]);\n    anchor = :midpoint # Anchor evaluation point at midpoint of each interval\n)\n\n# Run enumerative inference (this may take a while)\ntraces, log_norm_weights, lml_est = \n    enumerative_inference(h_bayes_regression, (xs,), observations, grid)\n\n# Compute marginal posterior over slope and intercept\nsum_dims = Tuple(3:ndims(log_norm_weights)) # Sum over all other variables\nposterior_grid = sum(exp.(log_norm_weights), dims=sum_dims)\nposterior_grid = dropdims(posterior_grid; dims=sum_dims)\n\n# Extract parameter ranges\nslope_range = [trs[1][:slope] for trs in eachslice(traces, dims=1)]\nintercept_range = [trs[1][:intercept] for trs in eachslice(traces, dims=2)]\n\n# Plot 2D posterior heatmap with 1D marginals as histograms\nplot_posterior_grid(intercept_range, slope_range, posterior_grid,\n                    x_true = true_intercept, y_true = true_slope,\n                    xlabel = \"Intercept\", ylabel = \"Slope\", is_discrete = false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"We see that the mode of the posterior distribution is now close to the true parameters (though there is also a secondary mode corresponding to the interpretation that the data has a shallow slope with outliers). To get a sense of why inference is now reasonable under our new model, let us visualize the conditional posteriors over slope_var, intercept_var and prob_outlier when slope and intercept are fixed at their true values.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Construct enumeration grid conditional on true slope and intercept\ncond_grid = choice_vol_grid(\n    (:slope_var, 0.0:0.5:5.0, :continuous),  # 10 grid intervals\n    (:intercept_var, 0.0:0.5:5.0, :continuous),  # 10 grid intervals\n    (:prob_outlier, 0.0:0.1:1.0, :continuous),  # 10 grid intervals\n    # Enumerate exactly over outlier classifications\n    (:data => 1 => :is_outlier, [false, true]),\n    (:data => 2 => :is_outlier, [false, true]),\n    (:data => 3 => :is_outlier, [false, true]),\n    (:data => 4 => :is_outlier, [false, true]),\n    (:data => 5 => :is_outlier, [false, true]);\n    anchor = :midpoint # Anchor evaluation point at the right of each interval\n)\n\n# Run enumerative inference over conditional posterior\nconstraints = choicemap(:slope => true_slope, :intercept => true_intercept)\nconstraints = merge(constraints, observations)\ntraces, log_norm_weights, lml_est = \n    enumerative_inference(h_bayes_regression, (xs,), constraints, cond_grid)\n\n# Compute marginal posterior over slope_var and intercept_var\nsum_dims = Tuple(3:ndims(log_norm_weights)) # Sum over all other variables\nposterior_grid = sum(exp.(log_norm_weights), dims=sum_dims)\nposterior_grid = dropdims(posterior_grid; dims=sum_dims)\n\n# Extract parameter ranges\nslope_var_range = [trs[1][:slope_var] for trs in eachslice(traces, dims=1)]\nintercept_var_range = [trs[1][:intercept_var] for trs in eachslice(traces, dims=2)]\n\n# Plot 2D posterior heatmap with 1D marginals as histograms\nplot_posterior_grid(intercept_var_range, slope_var_range, posterior_grid,\n                    xlabel = \"Intercept Variance\", ylabel = \"Slope Variance\",\n                    is_discrete = false)","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"# Compute marginal posterior over prob_outlier\nsum_dims = (1, 2, 4:ndims(log_norm_weights)...) # Sum over all other variables\nprob_outlier_grid = sum(exp.(log_norm_weights), dims=sum_dims)\nprob_outlier_grid = dropdims(prob_outlier_grid; dims=sum_dims)\nprob_outlier_range = [trs[1][:prob_outlier] for trs in eachslice(traces, dims=3)]\n\n# Plot marginal posterior distribution over prob_outlier\nbar(prob_outlier_range, prob_outlier_grid, \n    legend=false, bar_width=diff(prob_outlier_range)[1],\n    linewidth=0, color=:black, widen=false, xlims=(0, 1),\n    xlabel = \"Outlier Probability (prob_outlier)\",\n    ylabel = \"Conditional Posterior Probability\")","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Conditional on the observed data and the true parameters (slope = 2.8 and intercept = -2.4), the distribution over slope_var and intercept_var skews towards large values, while the distribution over prob_outlier skews towards low values. This avoids the failure mode that arose when the slope and intercept priors were forced to be narrow. Instead, slope_var, intercept_var and prob_outlier can adjust upwards or downwards to adapt to the observed data.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"Having gained confidence that our new model is well-specified by performing enumerative inference at a coarse-grained level, we can now use MCMC to approximate the posterior more efficiently, and with a higher degree of spatial resolution.","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"function h_bayes_mcmc_kernel(trace)\n    # Gaussian drift on line parameters\n    (trace, _) = mh(trace, line_proposal, ())\n\n    # Block resimulation: Update the outlier classifications\n    (xs,) = get_args(trace)\n    n = length(xs)\n    for i=1:n\n        (trace, _) = mh(trace, select(:data => i => :is_outlier))\n    end\n    \n    # Block resimulation: Update the prior parameters\n    (trace, _) = mh(trace, select(:slope_var))\n    (trace, _) = mh(trace, select(:intercept_var))\n    (trace, _) = mh(trace, select(:prob_outlier))\n    return trace\nend\n\n# Generate initial trace from prior\ntrace, _ = Gen.generate(h_bayes_regression, (xs,), observations)\n\n# Run MCMC for 20,000 iterations with a burn-in of 500\ntraces = mcmc_sampler(h_bayes_mcmc_kernel, trace, 20000, 500)\n\n# Plot posterior samples\nslopes = [trace[:slope] for trace in traces]\nintercepts = [trace[:intercept] for trace in traces]\nplot_posterior_samples(-4:0.25:4, -4:0.25:4, intercepts, slopes,\n                       x_true=true_intercept, y_true=true_slope,\n                       xlabel=\"Intercept\", ylabel=\"Slope\")","category":"page"},{"location":"tutorials/enumerative/","page":"Debugging Models with Enumeration","title":"Debugging Models with Enumeration","text":"MCMC produces samples that concentrate around the true parameters, while still exhibiting some of the bimodality we saw when using coarse-grained enumerative inference.","category":"page"},{"location":"ref/core/selections/#Selections","page":"Selections","title":"Selections","text":"","category":"section"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"A selection represents a set of addresses of random choices. Selections allow users to specify to which subset of the random choices in a trace a given inference operation should apply.","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"An address that is added to a selection indicates that either the random choice at that address should be included in the selection, or that all random choices made by a generative function traced at that address should be included. For example, consider the following selection:","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"selection = select(:x, :y)","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"If we use this selection in the context of a trace of the function baz below, we are selecting two random choices, at addresses :x and :y:","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"@gen function baz()\n    @trace(bernoulli(0.5), :x)\n    @trace(bernoulli(0.5), :y)\nend","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"If we use this selection in the context of a trace of the function bar below, we are actually selecting three random choices–-the one random choice made by bar at address :x and the two random choices made by foo at addresses :y => :z and :y => :w:","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"@gen function foo()\n    @trace(normal(0, 1), :z)\n    @trace(normal(0, 1), :w)\nend\n\n@gen function bar()\n    @trace(bernoulli(0.5), :x)\n    @trace(foo(), :y)\nend","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"There is an abstract type for selections:","category":"page"},{"location":"ref/core/selections/#Gen.Selection","page":"Selections","title":"Gen.Selection","text":"Selection\n\nAbstract type for selections of addresses.\n\nAll selections implement the following methods:\n\nBase.in(addr, selection)\n\nIs the address selected?\n\nBase.getindex(selection, addr)\n\nGet the subselection at the given address.\n\nBase.isempty(selection)\n\nIs the selection guaranteed to be empty?\n\nget_address_schema(T)\n\nReturn a shallow, compile-time address schema, where T is the concrete type of the selection.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"There are various concrete types for selections, each of which is a subtype of Selection. Users can construct selections with the following methods:","category":"page"},{"location":"ref/core/selections/#Gen.select","page":"Selections","title":"Gen.select","text":"selection = select(addrs...)\n\nReturn a selection containing a given set of addresses.\n\nExamples:\n\nselection = select(:x, \"foo\", :y => 1 => :z)\nselection = select()\nselection = select(:x => 1, :x => 2)\n\n\n\n\n\n","category":"function"},{"location":"ref/core/selections/#Gen.selectall","page":"Selections","title":"Gen.selectall","text":"selection = selectall()\n\nConstruct a selection that includes all random choices.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/selections/#Gen.complement","page":"Selections","title":"Gen.complement","text":"comp_selection = complement(selection::Selection)\n\nReturn a selection that is the complement of the given selection.\n\nAn address is in the selection if it is not in the complement selection.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"The select method returns a selection with concrete type DynamicSelection. The selectall method returns a selection with concrete type AllSelection.","category":"page"},{"location":"ref/core/selections/","page":"Selections","title":"Selections","text":"The full list of concrete types of selections is shown below. Most users need not worry about these types. Note that only selections of type DynamicSelection are mutable (using push! and set_subselection!).","category":"page"},{"location":"ref/core/selections/#Gen.EmptySelection","page":"Selections","title":"Gen.EmptySelection","text":"struct EmptySelection <: Selection end\n\nA singleton type for a selection that is always empty.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/#Gen.AllSelection","page":"Selections","title":"Gen.AllSelection","text":"struct AllSelection <: Selection end\n\nA singleton type for a selection that contains all choices at or under an address.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/#Gen.HierarchicalSelection","page":"Selections","title":"Gen.HierarchicalSelection","text":"abstract type HierarchicalSelection <: Selection end\n\nAbstract type for selections that have a notion of sub-selections.\n\nget_subselections(selection::HierarchicalSelection)\n\nReturn an iterator over pairs of addresses and subselections at associated addresses.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/#Gen.DynamicSelection","page":"Selections","title":"Gen.DynamicSelection","text":"struct DynamicSelection <: HierarchicalSelection .. end\n\nA hierarchical, mutable, selection with arbitrary addresses.\n\nCan be mutated with the following methods:\n\nBase.push!(selection::DynamicSelection, addr)\n\nAdd the address and all of its sub-addresses to the selection.\n\nExample:\n\nselection = select()\n@assert !(:x in selection)\npush!(selection, :x)\n@assert :x in selection\n\nset_subselection!(selection::DynamicSelection, addr, other::Selection)\n\nChange the selection status of the given address and its sub-addresses that defined by other.\n\nExample:\n\nselection = select(:x)\n@assert :x in selection\nsubselection = select(:y)\nset_subselection!(selection, :x, subselection)\n@assert (:x => :y) in selection\n@assert !(:x in selection)\n\nNote that set_subselection! does not copy data in other, so other may be mutated by a later calls to set_subselection! for addresses under addr.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/#Gen.StaticSelection","page":"Selections","title":"Gen.StaticSelection","text":"struct StaticSelection{T,U} <: HierarchicalSelection .. end\n\nA hierarchical selection whose keys are among its type parameters.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/#Gen.ComplementSelection","page":"Selections","title":"Gen.ComplementSelection","text":"struct ComplementSelection <: Selection end\n\nA hierarchical selection that is the complement of the given selection. An address is in the selection if it is not in the complement selection.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/selections/#Gen.get_address_schema","page":"Selections","title":"Gen.get_address_schema","text":"schema = get_address_schema(::Type{T}) where {T <: ChoiceMap}\n\nReturn the (top-level) address schema for the given choice map.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Choice-Maps","page":"Choice Maps","title":"Choice Maps","text":"","category":"section"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Maps from the addresses of random choices to their values are stored in associative tree-structured data structures that have the following abstract type:","category":"page"},{"location":"ref/core/choice_maps/#Gen.ChoiceMap","page":"Choice Maps","title":"Gen.ChoiceMap","text":"abstract type ChoiceMap end\n\nAbstract type for maps from hierarchical addresses to values.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Choice maps are constructed by users to express observations and/or constraints on the traces of generative functions. Choice maps are also returned by certain Gen inference methods, and are used internally by various Gen inference methods.","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Choice maps provide the following methods:","category":"page"},{"location":"ref/core/choice_maps/#Gen.has_value","page":"Choice Maps","title":"Gen.has_value","text":"has_value(choices::ChoiceMap, addr)\n\nReturn true if there is a value at the given address.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.get_value","page":"Choice Maps","title":"Gen.get_value","text":"value = get_value(choices::ChoiceMap, addr)\n\nReturn the value at the given address in the assignment, or throw a KeyError if no value exists. A syntactic sugar is Base.getindex:\n\nvalue = choices[addr]\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.has_submap","page":"Choice Maps","title":"Gen.has_submap","text":"has_submap(choices::ChoiceMap, addr)\n\nReturn true if there is a non-empty sub-assignment at the given address.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.get_submap","page":"Choice Maps","title":"Gen.get_submap","text":"submap = get_submap(choices::ChoiceMap, addr)\n\nReturn the sub-assignment containing all choices whose address is prefixed by addr.\n\nIt is an error if the assignment contains a value at the given address. If there are no choices whose address is prefixed by addr then return an EmptyChoiceMap.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.get_values_shallow","page":"Choice Maps","title":"Gen.get_values_shallow","text":"key_submap_iterable = get_values_shallow(choices::ChoiceMap)\n\nReturn an iterator over tuples of the form (key, value) for each top-level key associated with a value.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.get_submaps_shallow","page":"Choice Maps","title":"Gen.get_submaps_shallow","text":"key_submap_iterable = get_submaps_shallow(choices::ChoiceMap)\n\nReturn an iterator over tuples of the form (key, submap::ChoiceMap) for each top-level key that has a non-empty sub-assignment.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.to_array","page":"Choice Maps","title":"Gen.to_array","text":"arr::Vector{T} = to_array(choices::ChoiceMap, ::Type{T}) where {T}\n\nPopulate an array with values of choices in the given assignment.\n\nIt is an error if each of the values cannot be coerced into a value of the given type.\n\nImplementation\n\nTo support to_array, a concrete subtype T <: ChoiceMap should implement the following method:\n\nn::Int = _fill_array!(choices::T, arr::Vector{V}, start_idx::Int) where {V}\n\nPopulate arr with values from the given assignment, starting at start_idx, and return the number of elements in arr that were populated.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.from_array","page":"Choice Maps","title":"Gen.from_array","text":"choices::ChoiceMap = from_array(proto_choices::ChoiceMap, arr::Vector)\n\nReturn an assignment with the same address structure as a prototype assignment, but with values read off from the given array.\n\nThe order in which addresses are populated is determined by the prototype assignment. It is an error if the number of choices in the prototype assignment is not equal to the length the array.\n\nImplementation\n\nTo support from_array, a concrete subtype T <: ChoiceMap should implement the following method:\n\n(n::Int, choices::T) = _from_array(proto_choices::T, arr::Vector{V}, start_idx::Int) where {V}\n\nReturn an assignment with the same address structure as a prototype assignment, but with values read off from arr, starting at position start_idx, and the number of elements read from arr.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.get_selected","page":"Choice Maps","title":"Gen.get_selected","text":"selected_choices = get_selected(choices::ChoiceMap, selection::Selection)\n\nFilter the choice map to include only choices in the given selection.\n\nReturns a new choice map.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Note that none of these methods mutate the choice map.","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Choice maps also implement:","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Base.isempty, which tests of there are no random choices in the choice map\nBase.merge, which takes two choice maps, and returns a new choice map containing all random choices in either choice map. It is an error if the choice maps both have values at the same address, or if one choice map has a value at an address that is the prefix of the address of a value in the other choice map.\n==, which tests if two choice maps have the same addresses and values at those addresses.","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"Gen.jl defines the following concrete types for choice maps:","category":"page"},{"location":"ref/core/choice_maps/#Gen.DynamicChoiceMap","page":"Choice Maps","title":"Gen.DynamicChoiceMap","text":"DynamicChoiceMap <: ChoiceMap\n\nA mutable map from arbitrary hierarchical addresses to values.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/choice_maps/#Gen.EmptyChoiceMap","page":"Choice Maps","title":"Gen.EmptyChoiceMap","text":"EmptyChoiceMap <: ChoiceMap\n\nAn empty choice map.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/choice_maps/#Gen.StaticChoiceMap","page":"Choice Maps","title":"Gen.StaticChoiceMap","text":"StaticChoiceMap <: ChoiceMap\n\nAn immutable mapping statically-traced addresses to values.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/choice_maps/#Gen.choicemap","page":"Choice Maps","title":"Gen.choicemap","text":"choices = choicemap()\n\nConstruct an empty mutable choice map.\n\n\n\n\n\nchoices = choicemap(tuples...)\n\nConstruct a mutable choice map initialized with given address, value tuples.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"A mutable choice map can be constructed with choicemap, and then populated:","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"choices = choicemap()\nchoices[:x] = true\nchoices[\"foo\"] = 1.25\nchoices[:y => 1 => :z] = -6.3","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"There is also a constructor that takes initial (address, value) pairs:","category":"page"},{"location":"ref/core/choice_maps/","page":"Choice Maps","title":"Choice Maps","text":"choices = choicemap((:x, true), (\"foo\", 1.25), (:y => 1 => :z, -6.3))","category":"page"},{"location":"ref/core/choice_maps/#Gen.set_value!","page":"Choice Maps","title":"Gen.set_value!","text":"set_value!(choices::DynamicChoiceMap, addr, value)\n\nSet the given value for the given address.\n\nWill cause any previous value or sub-assignment at this address to be deleted. It is an error if there is already a value present at some prefix of the given address.\n\nThe following syntactic sugar is provided:\n\nchoices[addr] = value\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.set_submap!","page":"Choice Maps","title":"Gen.set_submap!","text":"set_submap!(choices::DynamicChoiceMap, addr, submap::ChoiceMap)\n\nReplace the sub-assignment rooted at the given address with the given sub-assignment. Set the given value for the given address.\n\nWill cause any previous value or sub-assignment at the given address to be deleted. It is an error if there is already a value present at some prefix of address.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Base.merge-Tuple{ChoiceMap, ChoiceMap}","page":"Choice Maps","title":"Base.merge","text":"choices = Base.merge(choices1::ChoiceMap, choices2::ChoiceMap)\n\nMerge two choice maps.\n\nIt is an error if the choice maps both have values at the same address, or if one choice map has a value at an address that is the prefix of the address of a value in the other choice map.\n\n\n\n\n\n","category":"method"},{"location":"ref/core/choice_maps/#Base.merge-Tuple{ChoiceMap, Vararg{ChoiceMap}}","page":"Choice Maps","title":"Base.merge","text":"Variadic merge of choice maps.\n\n\n\n\n\n","category":"method"},{"location":"ref/core/choice_maps/#Base.isempty-Tuple{ChoiceMap}","page":"Choice Maps","title":"Base.isempty","text":"Base.isempty(choices::ChoiceMap)\n\nReturn true if there are no values in the assignment.\n\n\n\n\n\n","category":"method"},{"location":"ref/core/choice_maps/#Gen.pair","page":"Choice Maps","title":"Gen.pair","text":"choices = pair(choices1::ChoiceMap, choices2::ChoiceMap, key1::Symbol, key2::Symbol)\n\nReturn an assignment that contains choices1 as a sub-assignment under key1 and choices2 as a sub-assignment under key2.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.unpair","page":"Choice Maps","title":"Gen.unpair","text":"(choices1, choices2) = unpair(choices::ChoiceMap, key1::Symbol, key2::Symbol)\n\nReturn the two sub-assignments at key1 and key2, one or both of which may be empty.\n\nIt is an error if there are any top-level values, or any non-empty top-level sub-assignments at keys other than key1 and key2.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/choice_maps/#Gen.ChoiceMapNestedView","page":"Choice Maps","title":"Gen.ChoiceMapNestedView","text":"Wrapper for a ChoiceMap that provides nested-dict–like syntax, rather than the default syntax which looks like a flat dict of full keypaths.\n\njulia> using Gen\njulia> c = choicemap((:a, 1),\n                     (:b => :c, 2));\njulia> cv = nested_view(c);\njulia> c[:a] == cv[:a]\ntrue\njulia> c[:b => :c] == cv[:b][:c]\ntrue\njulia> length(cv)\n2\njulia> length(cv[:b])\n1\njulia> sort(collect(keys(cv)))\n[:a, :b]\njulia> sort(collect(keys(cv[:b])))\n[:c]\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/mcmc/#mcmc","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo (MCMC)","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Markov chain Monte Carlo (MCMC) is an approach to inference which involves initializing a hypothesis and then repeatedly sampling a new hypotheses given the previous hypothesis by making a change to the previous hypothesis.[1] ","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"[1]: For background on MCMC, see Andrieu, Christophe, et al. \"An introduction to MCMC for machine learning.\" Machine learning 50.1-2 (2003): 5-43. Link.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The function that samples the new hypothesis given the previous hypothesis is called the MCMC kernel (or `kernel' for short). If we design the kernel appropriately, then the distribution of the hypotheses will converge to the conditional (i.e. posterior) distribution as we increase the number of times we apply the kernel.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Gen includes primitives for constructing MCMC kernels and composing them into MCMC algorithms. Although Gen encourages you to write MCMC algorithms that converge to the conditional distribution, Gen does not enforce this requirement. You may use Gen's MCMC primitives in other ways, including for stochastic optimization.","category":"page"},{"location":"ref/inference/mcmc/#MCMC-in-Gen","page":"Markov Chain Monte Carlo","title":"MCMC in Gen","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Suppose we are doing inference in the following toy model:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@gen function model()\n    x = @trace(bernoulli(0.5), :x) # a latent variable\n    @trace(normal(x ? -1. : 1., 1.), :y) # the variable that will be observed\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"To do MCMC, we first need to obtain an initial trace of the model. Recall that a trace encodes both the observed data and hypothesized values of latent variables. We can obtain an initial trace that encodes the observed data, and contains a randomly initialized hypothesis, using generate, e.g.:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"observations = choicemap((:y, 1.23))\ntrace, = generate(model, (), observations)","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Then, an MCMC algorithm is Gen is implemented simply by writing Julia for loop, which repeatedly applies a kernel, which is a regular Julia function:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"for i=1:100\n    trace = kernel(trace)\nend","category":"page"},{"location":"ref/inference/mcmc/#Built-in-Stationary-Kernels","page":"Markov Chain Monte Carlo","title":"Built-in Stationary Kernels","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"However, we don't expect to be able to use any function for kernel and expect to converge to the conditional distribution. To converge to the conditional distribution, the kernels must satisfy some properties. One of these properties is that the kernel is stationary with respect to the conditional distribution. Gen's inference library contains a number of functions for constructing stationary kernels:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"metropolis_hastings with alias mh, which has three variants with differing tradeoffs between ease-of-use and efficiency. The simplest variant simply requires you to select the set of random choices to be updated, without specifying how. The middle variant allows you to use custom proposals that encode problem-specific heuristics, or custom proposals based on neural networks that are trained via amortized inference. The most sophisticated variant allows you to specify any kernel in the reversible jump MCMC framework.\nmala, which performs a Metropolis Adjusted Langevin algorithm update on a set of selected random choices.\nhmc, which performs a Hamiltonian Monte Carlo update on a set of selected random choices.\nelliptical_slice, which performs an elliptical slice sampling update on a selected multivariate normal random choice.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"For example, here is an MCMC inference algorithm that uses mh:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"function do_inference(y, num_iters)\n    trace, = generate(model, (), choicemap((:y, y)))\n    xs = Float64[]\n    for i=1:num_iters\n        trace, = mh(trace, select(:x))\n        push!(xs, trace[:x])\n    end\n    xs\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Note that each of the kernel functions listed above stationary with respect to the joint distribution on traces of the model, but may not be stationary with respect to the intended conditional distribution, which is determined by the set of addresses that consititute the observed data. If a kernel modifies the values of any of the observed data, then the kernel is not stationary with respect to the conditional distribution. Therefore, you should ensure that your MCMC kernels never propose to the addresses of the observations.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Note that stationarity with respect to the conditional distribution alone is not sufficient for a kernel to converge to the posterior with infinite iterations. Other requirements include that the chain is irreducible (it is possible to get from any state to any other state in a finite number of steps), and aperiodicity, which is a more complex requirement that is satisfied when kernels have some probability of staying in the same state, which most of the primitive kernels above satisfy. We refer interested readers to [1] for additional details on MCMC convergence.","category":"page"},{"location":"ref/inference/mcmc/#Enabling-Dynamic-Checks","page":"Markov Chain Monte Carlo","title":"Enabling Dynamic Checks","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Gen does not statically guarantee that kernels (either ones built-in or composed with the Composite Kernel DSL) are stationary. However, you can enable dynamic checks that will detect common bugs that break stationarity. To enable the dynamic checks we pass a keyword argument beyond those of the kernel itself:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"new_trace = k(trace, 2, check=true)","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Note that these checks aim to detect when a kernel is not stationary with respect to the model's joint distribution. To add an additional dynamic check for violation of stationarity with respect to the conditional distribution (conditioned on observations), we pass in an additional keyword argument containing a choice map with the observations:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"new_trace = k(traced, 2, check=true, observations=choicemap((:y, 1.2)))","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"If check is set to false, then the observation check is not performed.","category":"page"},{"location":"ref/inference/mcmc/#Composite-Kernel-DSL","page":"Markov Chain Monte Carlo","title":"Composite Kernel DSL","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"You can freely compose the primitive kernels listed above into more complex kernels. Common types of composition including e.g. cycling through multiple kernels, randomly choosing a kernel to apply, and choosing which kernel to apply based on the current state. However, not all such compositions of stationary kernels will result in kernels that are themselves stationary.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Gen's Composite Kernel DSL is an embedded inference DSL that allows for more safe composition of MCMC kernels, by formalizing properties of the compositions that are sufficient for stationarity, encouraging compositions with these properties, and dynamically checking for violation of these properties. Although the DSL does not guarantee stationarity of the composite kernels, its dynamic checks do catch common cases of non-stationary kernels. The dynamic checks can be enabled and disabled as needed (e.g. enabled during testing and prototyping and disabled during deployment for higher performance).","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The DSL consists of a macro – @kern for composing stationary kernels from primitive stationary kernels and composite stationary kernels, and two additional macros: –- @pkern for declaring Julia functions to be custom primitive stationary kernels, and @rkern for declaring the reversal of a custom primitive kernel (these two macros are advanced features not necessary for standard MCMC algorithms).","category":"page"},{"location":"ref/inference/mcmc/#Composing-Stationary-Kernels","page":"Markov Chain Monte Carlo","title":"Composing Stationary Kernels","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The @kern macro defines a composite MCMC kernel in a restricted DSL that is based on Julia's own function definition syntax.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Suppose we are doing inference in the following model:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@gen function model()\n    n = @trace(geometric(0.5), :n)\n    total = 0.\n    for i=1:n\n        total += @trace(normal(0, 1), (:x, i))\n    end\n    @trace(normal(total, 1.), :y)\n    total\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Here is an example composite kernel for MCMC in this model:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@kern function my_kernel(trace)\n    \n    # cycle through the x's and do a random walk update on each one\n    for i in 1:trace[:n]\n        trace ~ mh(trace, random_walk_proposal, (i,))\n    end\n\n    # repeatedly pick a random x and do a random walk update on it\n    if trace[:n] > 0\n        for rep in 1:10\n            let i ~ uniform_discrete(1, trace[:n])\n                trace ~ mh(trace, random_walk_proposal, (i,))\n            end\n        end\n    end\n\n    # remove the last x, or add a new one, a random number of times\n    let n_add_remove_reps ~ uniform_discrete(0, max_n_add_remove)\n        for rep in 1:n_add_remove_reps\n            trace ~ mh(trace, add_remove_proposal, (), add_remove_involution)\n        end\n    end\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"In the DSL, the first argument (trace in this case) represents the trace on which the kernel is acting. the kernel may have additional arguments. The code inside the body can read from the trace (e.g. trace[:n] reads the value of the random choice :n). Finally, the return value of the composite kernel is automatically set to the trace. NOTE: It is not permitted to assign to the trace variable, except with ~ expressions. Also note that stationary kernels, when treated as Julia functions, return a tuple, where the first element is the trace and the remaining arguments are metadata. When applying these kernels with ~ syntax within the DSL, it is not necessary to unpack the tuple (the metadata is ignored automatically).","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The language constructs supported by this DSL are:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Applying a stationary kernel. To apply a kernel, the syntax trace ~ k(trace, args..) is used. Note that the check and observations keyword arguments (see Enabling Dynamic Checks) should not be used here; they will be added automatically.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"For loops. The range of the for loop may be a deterministic function of the trace (as in trace[:n] above). The range must be invariant under all possible executions of the body of the for loop. For example, the random walk based kernel embedded in the for loop in our example above cannot modify the value of the random choice :n in the trace.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"If-end expressions. The predicate condition may be a deterministic function of the trace, but it also must be invariant (i.e. remain true) under all possible executions of the body.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Deterministic let expressions. We can use let x = value .. end to bind values to a variable, but the expression on the right-hand-side must be deterministic function of its free variables, its value must be invariant under all possible executions of the body.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Stochastic let expressions. We can use let x ~ dist(args...) .. end to sample a stochastic value and bind to a variable, but the expression on the right-hand-side must be the application of a Gen Distribution to arguments, and the distribution and its arguments must be invariant under all possible executions of the body.","category":"page"},{"location":"ref/inference/mcmc/#Declaring-primitive-kernels-for-use-in-composite-kernels","page":"Markov Chain Monte Carlo","title":"Declaring primitive kernels for use in composite kernels","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Note that all calls to built-in kernels like mh should be stationary, but that users are also free to declare their own arbitrary code as stationary. The @pkern macro declares a Julia function as a stationary MCMC kernel, for use with the MCMC Kernel DSL. The following custom primitive kernel permutes the random variables using random permutation generated from outside of Gen: ","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@pkern function permute_move(trace; check=false, observations=EmptyChoiceMap())\n    perm = Random.randperm(trace[:n])\n    constraints = choicemap()\n    for (i, j) in enumerate(perm)\n        constraints[(:x, i)] = trace[(:x, j)]\n        constraints[(:x, j)] = trace[(:x, i)]\n    end\n    trace, = update(trace, (), (), constraints)\n    metadata = nothing\n    trace, metadata\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The first argument to the function should be the trace, and the function must have keyword arguments check and observations (see Enabling Dynamic Checks). The return value should be a tuple where the first element is the new trace (and any remaining elements are optional metadata).","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Primitive kernels are Julia functions. Note that although we will be invoking these kernels within @kern functions, these kernels can still be called like a regular Julia function.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"new_trace = permute_move(trace, 2)","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Indeed, they are just regular Julia functions, but with some extra information attached so that the composite kernel DSL knows they have been declared as stationary kernels.","category":"page"},{"location":"ref/inference/mcmc/#involutive_mcmc","page":"Markov Chain Monte Carlo","title":"Involutive MCMC","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Gen's most flexible variant of metropolis_hastings, called Involutive MCMC, allows users to specify any MCMC kernel in the reversible jump MCMC (RJMCMC) framework. [2] Involution MCMC allows you to express a broad class of custom MCMC kernels that are not expressible using the other, simpler variants of Metropolis-Hastings supported by Gen. These kernels are particularly useful for inferring the structure (e.g. control flow) of a model.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"[2]: Green, Peter J. \"Reversible jump Markov chain Monte Carlo computation and Bayesian model determination.\" Biometrika 82.4 (1995): 711-732. Link","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"An involutive MCMC kernel in Gen takes as input a previous trace of the model (whose choice map we will denote by t), and performs three phases to obtain a new trace of the model:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"First, it traces the execution of a proposal, which is an auxiliary generative function that takes the previous trace of the model as its first argument. Mathematically, we will denote the choice map associated with the trace of the proposal by u. The proposal can of course be defined using the built-in modeling language, just like the model itself. However, unlike many other uses of proposals in Gen, these proposals can make random choices at addresses that the model does not.\nNext, it takes the tuple (t u) and passes it into an involution (denoted mathematically by h), which is a function that returns a new tuple (t u), where t is the choice map for a new proposed trace of the model, and u are random choices for a new trace of the proposal. The defining property of the involution is that it is invertible, and it is its own inverse; i.e. (t u) = h(h(t u)). Intuitively, u is a description of a way that the proposal could be reversed, taking t to t.\nFinally, it computes an acceptance probability, which involves computing certain derivatives associated with the involution, and stochastically accepts or rejects the proposed model trace according to this probability. The involution is typically defined using the Trace Transform DSL, in which case the acceptance probability calculation is fully automated.","category":"page"},{"location":"ref/inference/mcmc/#Example","page":"Markov Chain Monte Carlo","title":"Example","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Consider the following generative model of two pieces of observed data, at addresses :y1 and :y2.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@gen function model()\n    if ({:z} ~ bernoulli(0.5))\n        m1 = ({:m1} ~ gamma(1, 1))\n        m2 = ({:m2} ~ gamma(1, 1))\n    else\n        m = ({:m} ~ gamma(1, 1))\n        (m1, m2) = (m, m)\n    end\n    {:y1} ~ normal(m1, 0.1)\n    {:y2} ~ normal(m2, 0.1)\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Because this model has stochastic control flow, it represents two distinct structural hypotheses about how the observed data could have been generated: If :z is true then we enter the first branch, and we hypothesize that the two data points were generated from separate means, sampled at addresses :m1 and :m2. If :z is false then we enter the second branch, and we hypohesize that there is a single mean that explains both data points, sampled at address :m.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"We want to construct an MCMC kernel that is able to transition between these two distinct structural hypotheses. We could construct such a kernel with the simpler 'selection' variant of Metropolis-Hastings, by selecting the address :z, e.g.:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"select_mh_structure_kernel(trace) = mh(trace, select(:z))[1]","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Sometimes, this kernel would propose to change the value of :z. We could interleave this kernel with another kernel that does inference over the mean random choices, without changing the structure, e.g.:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@gen function fixed_structure_proposal(trace)\n    if trace[:z]\n        {:m1} ~ normal(trace[:m1], 0.1)\n        {:m2} ~ normal(trace[:m2], 0.1)\n    else\n        {:m} ~ normal(trace[:m], 0.1)\n    end\nend\n\nfixed_structure_kernel(trace) = mh(trace, fixed_structure_proposal, ())[1]","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Combining these together, and applying to particular data and with a specific initial hypotheses:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"(y1, y2) = (1.0, 1.3)\ntrace, = generate(model, (), choicemap((:y1, y1), (:y2, y2), (:z, false), (:m, 1.2)))\nfor iter=1:100\n    trace = select_mh_structure_kernel(trace)\n    trace = fixed_structure_kernel(trace)\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"However, this algorithm will not be very efficient, because the internal proposal used by the selection variant of MH is not specialized to the model. In particular, when switching from the model with a single mean to the model with two means, the values of the new addresses :m1 and :m2 will be proposed from the prior distribution. This is wasteful, since if we have inferred an accurate value for :m, we expect the values for :m1 and :m2 to be near this value. The same is true when proposing a structure change in the opposite direction. That means it will take many more steps to get an accurate estimate of the posterior probability distribution on the two structures.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"We would like to use inferred values for :m1 and :m2 to inform our proposal for the value of :m. For example, we could take the geometric mean:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"m = sqrt(m1 * m2)","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"However, there are many combinations of m1 and m2 that have the same geometric mean. In other words, the geometric mean is not invertible. However, if we return the additional degree of freedom alongside the geometric mean (u), then we do have an invertible function:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"function merge_means(m1, m2)\n    m = sqrt(m1 * m2)\n    u = m1 / (m1 + m2)\n    (m, u)\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The inverse function is:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"function split_mean(m, u)\n    m1 = m * sqrt((u / (1 - u)))\n    m2 = m * sqrt(((1 - u) / u))\n    (m1, m2)\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"We use these two functions to construct an involution, and we use this involution with metropolis_hastings to construct an MCMC kernel that we call a 'split/merge' kernel, because it either splits a parameter value, or merges two parameter values. The proposal is responsible for generating the extra degree of freedom when splitting:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@gen function split_merge_proposal(trace)\n    if trace[:z]\n        # currently two segments, switch to one\n    else\n        # currently one segment, switch to two\n        {:u} ~ uniform_continuous(0, 1)\n    end\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Finally, we write the involution itself, using the Trace Transform DSL:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@transform split_merge_involution (model_in, aux_in) to (model_out, aux_out) begin\n    if @read(model_in[:z], :discrete)\n\n        # currently two means, switch to one\n        @write(model_out[:z], false, :discrete)\n        m1 = @read(model_in[:m1], :continuous)\n        m2 = @read(model_in[:m2], :continuous)\n        (m, u) = merge_means(m1, m2)\n        @write(model_out[:m], m, :continuous)\n        @write(aux_out[:u], u, :continuous)\n    else\n\n        # currently one mean, switch to two\n        @write(model_out[:z], true, :discrete)\n        m = @read(model_in[:m], :continuous)\n        u = @read(aux_in[:u], :continuous)\n        (m1, m2) = split_mean(m, u)\n        @write(model_out[:m1], m1, :continuous)\n        @write(model_out[:m2], m2, :continuous)\n    end\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The body of this function reads values from (t u) at specific addresses and writes values to (t u) at specific addresses, where t and t are called 'model' choice maps, and u and u are called 'proposal' choice maps. Note that the inputs and outputs of this function are not represented in the same way as arguments or return values of regular Julia functions –- they are implicit and can only be read from and written to, respectively, using a set of special macros (listed below). You should convince yourself that this function is invertible and its own inverse.","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Finally, we compose a structure-changing MCMC kernel using this involution:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"split_merge_kernel(trace) = mh(trace, split_merge_proposal, (), split_merge_involution)[1]","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"We then compose this move with the fixed structure move, and run it on the observed data:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"(y1, y2) = (1.0, 1.3)\ntrace, = generate(model, (), choicemap((:y1, y1), (:y2, y2), (:z, false), (:m, 1.)))\nfor iter=1:100\n    trace = split_merge_kernel(trace)\n    trace = fixed_structure_kernel(trace)\nend","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"We can then compare the results to the results from the Markov chain that used the selection-based structure-changing kernel:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"(Image: rjmcmc plot)","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"We see that if we initialize the Markov chains from the same state with a single mean (:z is false) then the selection-based kernel fails to accept any moves to the two-mean structure within 100 iterations, whereas the split-merge kernel transitions back and forth many times, If we repeated the selection-based kernel for enough iterations, it would eventually transition back and forth at the same rate as the split-merge. The split-merge kernel gives a much more efficient inference algorithm for estimating the posterior probability on the two structures.","category":"page"},{"location":"ref/inference/mcmc/#Reverse-Kernels","page":"Markov Chain Monte Carlo","title":"Reverse Kernels","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"The reversal of a stationary MCMC kernel with distribution k_1(t t), for model with distribution p(t x), is another MCMC kernel with distribution:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"k_2(t t) = fracp(t x)p(t x) k_1(t t)","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"For custom primitive kernels declared with @pkern, users can declare the reversal kernel with the @rkern macro:","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"@rkern k1 : k2","category":"page"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"This also assigns k1 as the reversal of k2. The composite kernel DSL automatically generates the reversal kernel for composite kernels, and built-in stationary kernels like mh. The reversal of a kernel (primitive or composite) can be obtained with reversal.","category":"page"},{"location":"ref/inference/mcmc/#API","page":"Markov Chain Monte Carlo","title":"API","text":"","category":"section"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Built-in stationary kernels: ","category":"page"},{"location":"ref/inference/mcmc/#Gen.metropolis_hastings","page":"Markov Chain Monte Carlo","title":"Gen.metropolis_hastings","text":"(new_trace, accepted) = metropolis_hastings(\n    trace, selection::Selection;\n    check=false, observations=EmptyChoiceMap())\n\nPerform a Metropolis-Hastings update that proposes new values for the selected addresses from the internal proposal (often using ancestral sampling), returning the new trace (which is equal to the previous trace if the move was not accepted) and a Bool indicating whether the move was accepted or not.\n\n\n\n\n\n(new_trace, accepted) = metropolis_hastings(\n    trace, proposal::GenerativeFunction, proposal_args::Tuple;\n    check=false, observations=EmptyChoiceMap())\n\nPerform a Metropolis-Hastings update that proposes new values for some subset of random choices in the given trace using the given proposal generative function, returning the new trace (which is equal to the previous trace if the move was not accepted) and a Bool indicating whether the move was accepted or not.\n\nThe proposal generative function should take as its first argument the current trace of the model, and remaining arguments proposal_args. If the proposal modifies addresses that determine the control flow in the model, values must be provided by the proposal for any addresses that are newly sampled by the model.\n\n\n\n\n\n(new_trace, accepted) = metropolis_hastings(\n    trace, proposal::GenerativeFunction, proposal_args::Tuple,\n    involution::Union{TraceTransformDSLProgram,Function};\n    check=false, observations=EmptyChoiceMap())\n\nPerform a generalized (reversible jump) Metropolis-Hastings update based on an involution (bijection that is its own inverse) on a space of choice maps, returning the new trace (which is equal to the previous trace if the move was not accepted) and a Bool indicating whether the move was accepted or not.\n\nMost users will want to construct involution using the Trace Transform DSL with the @transform macro, but for more user control it is also possible to provide a Julia function for involution, that has the following signature:\n\n(new_trace, bwd_choices::ChoiceMap, weight) = involution(trace::Trace, fwd_choices::ChoiceMap, fwd_retval, fwd_args::Tuple)\n\nThe generative function proposal is executed on arguments (trace, proposal_args...), producing a choice map fwd_choices and return value fwd_ret. For each value of model arguments (contained in trace) and proposal_args, the involution function applies an involution that maps the tuple (get_choices(trace), fwd_choices) to the tuple (get_choices(new_trace), bwd_choices). Note that fwd_ret is a deterministic function of fwd_choices and proposal_args. When only discrete random choices are used, the weight must be equal to get_score(new_trace) - get_score(trace).\n\nWhen continuous random choices are used, the weight returned by the involution must include an additive correction term that is the determinant of the the Jacobian of the bijection on the continuous random choices that is obtained by currying the involution on the discrete random choices (this correction term is automatically computed if the involution is constructed using the Trace Transform DSL). NOTE: The Jacobian matrix of the bijection on the continuous random choices must be full-rank (i.e. nonzero determinant). The check keyword argument to the involution can be used to enable or disable any dynamic correctness checks that the involution performs; for successful executions, check does not alter the return value.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/mcmc/#Gen.mh","page":"Markov Chain Monte Carlo","title":"Gen.mh","text":"(new_trace, accepted) = mh(trace, selection::Selection; ..)\n(new_trace, accepted) = mh(trace, proposal::GenerativeFunction, proposal_args::Tuple; ..)\n(new_trace, accepted) = mh(trace, proposal::GenerativeFunction, proposal_args::Tuple, involution; ..)\n\nAlias for metropolis_hastings. Perform a Metropolis-Hastings update on the given trace.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/mcmc/#Gen.mala","page":"Markov Chain Monte Carlo","title":"Gen.mala","text":"(new_trace, accepted) = mala(\n    trace, selection::Selection, tau::Real;\n    check=false, observations=EmptyChoiceMap())\n\nApply a Metropolis-Adjusted Langevin Algorithm (MALA) update.\n\nReference URL\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/mcmc/#Gen.hmc","page":"Markov Chain Monte Carlo","title":"Gen.hmc","text":"(new_trace, accepted) = hmc(\n    trace, selection::Selection; L=10, eps=0.1,\n    check=false, observations=EmptyChoiceMap())\n\nApply a Hamiltonian Monte Carlo (HMC) update that proposes new values for the selected addresses, returning the new trace (which is equal to the previous trace if the move was not accepted) and a Bool indicating whether the move was accepted or not.\n\nHamilton's equations are numerically integrated using leapfrog integration with step size eps for L steps. See equations (5.18)-(5.20) of Neal (2011).\n\nReferences\n\nNeal, Radford M. (2011), \"MCMC Using Hamiltonian Dynamics\", Handbook of Markov Chain Monte Carlo, pp. 113-162. URL: http://www.mcmchandbook.net/HandbookChapter5.pdf\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/mcmc/#Gen.elliptical_slice","page":"Markov Chain Monte Carlo","title":"Gen.elliptical_slice","text":"new_trace = elliptical_slice(\n    trace, addr, mu, cov;\n    check=false, observations=EmptyChoiceMap())\n\nApply an elliptical slice sampling update to a given random choice with a multivariate normal prior.\n\nAlso takes the mean vector and covariance matrix of the prior.\n\nReference URL\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/mcmc/#Gen.involutive_mcmc","page":"Markov Chain Monte Carlo","title":"Gen.involutive_mcmc","text":"(new_trace, accepted) = involutive_mcmc(trace, proposal::GenerativeFunction, proposal_args::Tuple, involution; ..)\n\nAlias for the involutive form of metropolis_hastings.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/mcmc/","page":"Markov Chain Monte Carlo","title":"Markov Chain Monte Carlo","text":"Macros and functions for defining custom stationary kernels:","category":"page"},{"location":"ref/inference/mcmc/#Gen.@pkern","page":"Markov Chain Monte Carlo","title":"Gen.@pkern","text":"@pkern function k(trace, args...; \n                  check=false, observations=EmptyChoiceMap())\n    ...\n    return trace\nend\n\nDeclare a Julia function as a primitive stationary kernel.\n\nThe first argument of the function should be a trace, and the return value of the function should be a (trace, metadata) where metadata is user-provided (but could be useful information, like the result of an accept-reject decision.\n\nThere should be keyword arguments check and observations.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/mcmc/#Gen.@kern","page":"Markov Chain Monte Carlo","title":"Gen.@kern","text":"@kern function k(trace, args...)\n    ...\nend\n\nConstruct a composite MCMC kernel.\n\nThe resulting object is a Julia function that is annotated as a composite MCMC kernel, and can be called as a Julia function or applied within other composite kernels.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/mcmc/#Gen.@rkern","page":"Markov Chain Monte Carlo","title":"Gen.@rkern","text":"@rkern k1 : k2\n\nDeclare that two primitive stationary kernels are reversals of one another.\n\nThe two kernels must have the same argument type signatures.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/mcmc/#Gen.reversal","page":"Markov Chain Monte Carlo","title":"Gen.reversal","text":"k2 = reversal(k1)\n\nReturn the reversal kernel for a given kernel.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/sml/#sml","page":"Static Modeling Language","title":"Static Modeling Language","text":"","category":"section"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"The Static Modeling Language (SML) is a restricted variant of the built-in dynamic modeling language. Models written in the static modeling language can result in better inference performance (more inference operations per second and less memory consumption), than the full built-in modeling language, especially for models used with iterative inference algorithms like Markov Chain Monte Carlo or particle filtering.","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"A function is identified as using the static modeling language by adding the static annotation to the function. For example:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"@gen (static) function foo(prob::Float64)\n    z1 = @trace(bernoulli(prob), :a)\n    z2 = @trace(bernoulli(prob), :b)\n    z3 = z1 || z2\n    z4 = !z3\n    return z4\nend","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"After running this code, foo is a Julia value whose type is a subtype of StaticIRGenerativeFunction, which is a subtype of GenerativeFunction.","category":"page"},{"location":"ref/modeling/sml/#Static-Computation-Graphs","page":"Static Modeling Language","title":"Static Computation Graphs","text":"","category":"section"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"Using the static annotation instructs Gen to statically construct a directed acyclic graph for the computation represented by the body of the function. For the function foo above, the static graph looks like:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"<div style=\"text-align:center\">\n    <img src=\"../../../assets/static_graph.png\" alt=\"example static computation graph\" width=\"50%\"/>\n</div>","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"In this graph, oval nodes represent random choices, square nodes represent Julia computations, and diamond nodes represent arguments. The light blue shaded node is the return value of the function. Having access to the static graph allows Gen to generate specialized code for Updating traces that skips unecessary parts of the computation. Specifically, when applying an update operation, the graph is analyzed, and each value in the graph identified as having possibly changed, or not. Nodes in the graph do not need to be re-executed if none of their input values could have possibly changed. Also, even if some inputs to a generative function node may have changed, knowledge that some of the inputs have not changed often allows the generative function being called to more efficiently perform its update operation. This is the case for functions produced by Generative Function Combinators.","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"You can plot the graph for a function with the static annotation if you have PyCall installed, and a Python environment that contains the graphviz Python package, using, e.g.:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"using PyCall\n@pyimport graphviz\nusing Gen: draw_graph\ndraw_graph(foo, graphviz, \"test\")","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"This will produce a file test.pdf in the current working directory containing the rendered graph.","category":"page"},{"location":"ref/modeling/sml/#Restrictions","page":"Static Modeling Language","title":"Restrictions","text":"","category":"section"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"First, the definition of a (static) generative function is always expected to occur as a top-level definition (aka global variable); usage in non–top-level scopes is unsupported and may result in incorrect behavior.","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"Next, in order to be able to construct the static graph, Gen restricts the permitted syntax that can be used in functions annotated with static. In particular, each statement in the body must be one of the following:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"A @param statement specifying any trainable parameters, e.g.:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"@param theta::Float64","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"An assignment, with a symbol or tuple of symbols on the left-hand side, and a Julia expression on the right-hand side, which may include @trace expressions, e.g.:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"mu, sigma = @trace(bernoulli(p), :x) ? (mu1, sigma1) : (mu2, sigma2)","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"A top-level @trace expression, e.g.:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"@trace(bernoulli(1-prob_tails), :flip)","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"All @trace expressions must use a literal Julia symbol for the first component in the address. Unlike the full built-in modeling-language, the address is not optional.","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"A return statement, with a Julia expression on the right-hand side, e.g.:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"return @trace(geometric(prob), :n_flips) + 1","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"The functions are also subject to the following restrictions:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"Default argument values are not supported.\nConstructing named or anonymous Julia functions (and closures) is not allowed.\nList comprehensions with internal @trace calls are not allowed.\nSplatting within @trace calls is not supported\nGenerative functions that are passed in as arguments cannot be traced.\nFor composite addresses (e.g. :a => 2 => :c) the first component of the address must be a literal symbol, and there may only be one statement in the function body that uses this symbol for the first component of its address.\nJulia control flow constructs (e.g. if, for, while) cannot be used as top-level statements in the function body. Control flow should be implemented inside either Julia functions that are called, or other generative functions.","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"Certain loop constructs can be implemented using Generative Function Combinators instead. For example, the following loop:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"for (i, prob) in enumerate(probs)\n    @trace(foo(prob), :foo => i)\nend","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"can instead be implemented as:","category":"page"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"@trace(Map(foo)(probs), :foo)","category":"page"},{"location":"ref/modeling/sml/#Loading-generated-functions","page":"Static Modeling Language","title":"Loading generated functions","text":"","category":"section"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"Once a (static) generative function is defined, it can be used in the same way as a non-static generative function. In previous versions of Gen, the @load_generated_functions macro had to be called before a function with a (static) annotation could be used. This macro is no longer necessary, and will be removed in a future release.","category":"page"},{"location":"ref/modeling/sml/#Performance-tips","page":"Static Modeling Language","title":"Performance tips","text":"","category":"section"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"For better performance when the arguments are simple data types like Float64, annotate the arguments with the concrete type. This permits a more optimized trace data structure to be generated for the generative function.","category":"page"},{"location":"ref/modeling/sml/#Caching-Julia-values","page":"Static Modeling Language","title":"Caching Julia values","text":"","category":"section"},{"location":"ref/modeling/sml/","page":"Static Modeling Language","title":"Static Modeling Language","text":"By default, the values of Julia computations (all calls that are not random choices or calls to generative functions) are cached as part of the trace, so that Updating traces can avoid unecessary re-execution of Julia code. However, this cache may grow the memory footprint of a trace. To disable caching of Julia values, use the function annotation nojuliacache (this annotation is ignored unless the static function annotation is also used).","category":"page"},{"location":"ref/inference/trace_translators/#Trace-Translators","page":"Trace Translators","title":"Trace Translators","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"While generative functions define probability distributions on traces, Trace Translators convert from one space of traces to another space of traces.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Trace translators are building blocks of inference programs that utilize multiple model representations, like Involutive MCMC or SMCP³.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Trace translators are significantly more general than Bijectors. Trace translators can (i) convert between spaces of traces that include mixed numeric discrete random choices, as well as stochastic control flow, and (ii) convert between spaces for which there is no one-to-one correspondence (e.g. between models of different dimensionality, or between discrete and continuous models). Bijectors are limited to deterministic transformations between real-valued vectors of constant dimension.","category":"page"},{"location":"ref/inference/trace_translators/#Deterministic-Trace-Translators","page":"Trace Translators","title":"Deterministic Trace Translators","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Inference programs manipulate traces, but they also keep track of probabilities and probability densities associated with these traces. Suppose we have two generative functions p1 and p2. Given a trace t2 of p2 we can easily compute the probability (or probability density) that the trace would have been generated by p2 using get_score(t2). But suppose we want to construct the trace of p2 first sampling a trace t1 of p1 and then applying a deterministic transformation to that trace to obtain t2. How can we compute the probability that a trace t2 would have been produced by this process? This probability is needed if, for example, p2 defines a probabilistic model and want to use p1 as a proposal distribution within importance sampling. If we produce t2 via an arbitrary deterministic transformation of the random choices in t1, then computing the necessary probability is difficult.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"If we restrict ourselves to deterministic transformations that are bijections (one-to-one correspondences) from the set of traces of p1 to the set of traces of p2, then the problem is much simplified. If the transformation is a bijection this means that (i) each trace of p1 gets mapped to a different trace of p2, and (ii) for every trace of p2 there is some trace of p1 that maps to it. Bijective transformations between traces are useful components of inference programs because the probability that a given trace t2 of p2 would have been produced by first sampling from p1 and then applying the transform can be computed simply as the probability that p1 would produce  the (unique) trace t1 that gets mapped to the given trace by the transform. Conceptually, bijective trace transforms preserve probability. When trace transforms operate on traces with continuous random choices, computing probability densities of the transformed traces requires computing a Jacobian associated with the continuous part of the transformation.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Gen provides a DSL for expressing bijections between spaces of traces, called the Trace Transform DSL. We introduce this DSL via an example. Below are two generative functions. The first samples polar coordinates and the second uses cartesian coordinates.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p1()\n    r ~ inv_gamma(1, 1)\n    theta ~ uniform(-pi/2, pi/2)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p2()\n    x ~ normal(0, 1)\n    y ~ normal(0, 1)\nend","category":"page"},{"location":"ref/inference/trace_translators/#Defining-a-trace-transform-with-the-Trace-Transform-DSL","page":"Trace Translators","title":"Defining a trace transform with the Trace Transform DSL","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"The following trace transform DSL program defines a transformation (called f) that transforms traces of p1 into traces of p2:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f (t1) to (t2) begin\n    r = @read(t1[:r], :continuous)\n    theta = @read(t1[:theta], :continuous)\n    @write(t2[:x], r * cos(theta), :continuous)\n    @write(t2[:y], r * sin(theta), :continuous)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"This transform reads values of random choices in the input trace (t1) at specific addresses (indicated by the syntax t1[addr]) using @read and writes values to the output trace (t2) using @write. Each read and write operation is labeled with whether the random choice is discrete or continuous. The section Trace Transform DSL defines the DSL in more detail.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"It is usually a good idea to write the inverse of the bijection. The inverse can provide a dynamic check that the transform truly is a bijection. The inverse of the above transformation is:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform finv (t2) to (t1) begin\n    x = @read(t2[:x], :continuous)\n    y = @read(t2[:y], :continuous)\n    r = sqrt(x^2 + y^2)\n    @write(t1[:r], sqrt(x^2 + y^2), :continuous)\n    @write(t1[:theta], atan(y, x), :continuous)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"We can inform Gen that two transforms are inverses of one another using pair_bijections!:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"pair_bijections!(f, finv)","category":"page"},{"location":"ref/inference/trace_translators/#Wrapping-a-trace-transform-in-a-trace-translator","page":"Trace Translators","title":"Wrapping a trace transform in a trace translator","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Note that the transform DSL code does not specify what the two generative functions are, or what the arguments to these generative functions are. This information will be required for computing probabilities and probability densities of traces. We provide this information by constructing a Trace Translator that wraps the transform along with this transformation:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"translator = DeterministicTraceTranslator(p2, (), choicemap(), f)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"We then can then apply the translator to a trace of p1 using function call syntax. The translator returns a trace of p2 and a log-weight that we can use to compute the probability (density) of the resulting trace:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"t2, log_weight = translator(t1)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Specifically, the log probability (density) that the trace t2 was produced by first sampling t1 = simulate(p1, ()) and then applying the trace translator, is:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"get_score(t1) + log_weight","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Let's unpack the previous few code blocks in more detail. First, note that we did not pass in the source generative function (p1) or its arguments (()) when we constructed the trace translator. This is because this information will be attached to the input trace t1 itself. We did need to pass in the target generative function (p2) and its arguments (()) however, because this information is not included in t1.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"In this case, because continuous random choices are involved, the probabilities are probability densities, and the trace translator used automatic differentiation of the code in the transform f to compute a change-of-variables Jacobian that is necessary to compute the correct probability density of the new trace t2.","category":"page"},{"location":"ref/inference/trace_translators/#Observations","page":"Trace Translators","title":"Observations","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Typically, there are observations associated with one or both of the generative functions involved, and we have values for these in a choice map, so we do not want the trace translator to be responsible for populating the values of these observed random choices. For example, suppose we want to condition p2 on an observed random choice z:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p2()\n    x ~ normal(0, 1)\n    y ~ normal(0, 1)\n    z ~ normal(x + y, 0.1)\nend\nobservations = choicemap()\nobservations[:z] = 2.3","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"When p2 has observations, these can be passed in as an additional argument to the trace translator constructor:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"translator = DeterministicTraceTranslator(p2, (), observations, f)","category":"page"},{"location":"ref/inference/trace_translators/#Discrete-random-choices-and-stochastic-control-flow","page":"Trace Translators","title":"Discrete random choices and stochastic control flow","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Trace transforms and trace translators interoperate seamlessly with discrete random choices and stochastic control flow. Both the input and the output traces can contain a mix of discrete and continuous choices, and arbitrary stochastic control flow. Consider the following simple example, where we use two different discrete representations to represent probability distributions the integers 0-7:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p1()\n    bit1 ~ bernoulli(0.5)\n    bit2 ~ bernoulli(0.5)\n    bit3 ~ bernoulli(0.5)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p2()\n    n ~ categorical([0.1, 0.1, 0.1, 0.2, 0.2, 0.15, 0.15])\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"We define the forward and inverse transforms:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f (t1) to (t2) begin\n    n = (\n        @read(t1[:bit1], :discrete) * 1 +\n        @read(t1[:bit2], :discrete) * 2 +\n        @read(t1[:bit3], :discrete) * 4)\n    @write(t2[:n], n, :discrete)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform finv (t2) to (t1) begin\n    bits = digits(@read(t2[:n], :discrete), base=2)\n    @write(t1[:bit1], bits[1], :discrete)\n    @write(t1[:bit2], bits[2], :discrete)\n    @write(t1[:bit3], bits[3], :discrete)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Here is an example that includes discrete random choices, stochastic control flow, and continuous random choices.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p1()\n    if ({:branch} ~ bernoulli(0.5))\n        x ~ normal(0, 1)\n    else\n        other ~ categorical([0.3, 0.7])\n    end\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p2()\n    k ~ uniform_discrete(1, 4)\n    if k <= 2\n        y ~ gamma(1, 1)\n    end\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Note that transformations between spaces of traces need not be intuitive (although they probably should)! Try to convince yourself that the functions below are indeed a pair of bijections between the traces of these two generative functions.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f (t1) to (t2) begin\n    if @read(t1[:branch], :discrete)\n        x = @read(t1[:x], :continuous)\n        if x > 0\n            @write(t2[:k], 2, :discrete)\n        else\n            @write(t2[:k], 1, :discrete)\n        end\n        @write(t2[:y], abs(x), :continuous)\n    else\n        other = @read(t1[:other], :discrete)\n        @write(t2[:k], (other == 1) ? 3 : 4, :discrete)\n    end\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform finv (t2) to (t1) begin\n    k = @read(t2[:k], :discrete)\n    if k <= 2\n        y = @read(t2[:y], :continuous)\n        @write(t2[:x], (k == 1) ? -y : y, :continuous)\n    else\n        @write(t1[:other], (k == 3) ? 1 : 2, :discrete)\n    end\nend","category":"page"},{"location":"ref/inference/trace_translators/#General-Trace-Translators","page":"Trace Translators","title":"General Trace Translators","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Note that for two arbitrary generative functions p1 and p2 there may not exist any one-to-one correspondence between their spaces of traces. For example, consider a generative function p1 that samples points within the unit square 0 1^2","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p1()\n    x ~ uniform(0, 1)\n    y ~ uniform(0, 1)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"and another generative function p2 that samples one of 100 possible discrete values, each value representing one cell of the unit square:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function p2()\n    i ~ uniform_discrete(1, 10) # interval [(i-1)/10, i/10]\n    j ~ uniform_discrete(1, 10) # interval [(j-1)/10, j/10]\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"There is no one-to-one correspondence between the spaces of traces of these two generative functions: The first is an uncountably infinite set, and the other is a finite set with 100 elements in it.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"However, there is an intuitive notion of correspondence that we would like to be able to encode. Each discrete cell (i j) corresponds to a subset of the unit square (i - 1)10 i10 times (j-1)10 j10.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"We can express this correspondence (and any correspondence between two arbitrary generative functions) by introducing two auxiliary generative functions q1 and q2. The first function q1 will take a trace of p1 as input, and the second function q2 will take a trace of p2 as input. Then, instead of a transfomation between traces of p1 and traces of p2 our trace transform will transform between (i) the space of pairs of traces of p1 and q1 and (ii) the space of pairs of traces of p2 and q2. We construct q1 and q2 so that the two spaces have the same size, and a one-to-one correspondence is possible.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"For our example above, we construct q2 to sample the coordinate (0 01^2) relative to the cell. We construct q1 to be empty–there is already a mapping from each trace of p1 to each trace of p2 that simply identifies what cell (i j) a given point in 0 1^2 is in, so no extra random choices are needed.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function q1(p1_trace)\nend\n\n@gen function q2(p2_trace)\n    dx ~ uniform(0.0, 0.1)\n    dy ~ uniform(0.0, 0.1)\nend","category":"page"},{"location":"ref/inference/trace_translators/#Trace-transforms-between-pairs-of-traces","page":"Trace Translators","title":"Trace transforms between pairs of traces","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"To handle general trace translators that require auxiliary probability distributions, the trace trace DSL supports defining transformations between pairs of traces. For example, the following defines a trace transform that maps from pairs of traces of p1 and q1 to pairs of traces of p2 and q2:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f (p1_trace, q1_trace) to (p2_trace, q2_trace) begin\n    x = @read(p1_trace[:x], :continuous)\n    y = @read(p1_trace[:y], :continuous)\n    i = ceil(x * 10)\n    j = ceil(y * 10)\n    @write(p2_trace[:i], i, :discrete)\n    @write(p2_trace[:j], j, :discrete)\n    @write(q2_trace[:dx], x - (i-1)/10, :continuous)\n    @write(q2_trace[:dy], y - (j-1)/10, :continuous)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"and the inverse transform:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f_inv (p2_trace, q2_trace) to (p1_trace, q1_trace) begin\n    i = @read(p2_trace[:i], :discrete)\n    j = @read(p2_trace[:j], :discrete)\n    dx = @read(q2_trace[:dx], :continuous)\n    dy = @read(q2_trace[:dy], :continuous)\n    x = (i-1)/10 + dx\n    y = (j-1)/10 + dy\n    @write(p1_trace[:x], x, :continuous)\n    @write(p1_trace[:y], y, :continuous)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"which we associate as inverses:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"pair_bijections!(f, f_inv)","category":"page"},{"location":"ref/inference/trace_translators/#Constructing-a-general-trace-translator","page":"Trace Translators","title":"Constructing a general trace translator","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"We now wrap the transform above into a general trace translator, by providing the three probabilistic programs p2, q1, q2 that it uses (a reference to p1 will included in the input trace), and the arguments to these functions.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"translator = GeneralTraceTranslator(\n    p_new=p2,\n    p_new_args=(),\n    new_observations=choicemap(),\n    q_forward=q1,\n    q_forward_args=(),\n    q_backward=q2,\n    q_backward_args=(),\n    f=f)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Then, we can apply the trace translator to a trace (t1) of p1 and get a trace (t2) of p2 and a log-weight:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"t2, log_weight = translator(t1)","category":"page"},{"location":"ref/inference/trace_translators/#Symmetric-Trace-Translators","page":"Trace Translators","title":"Symmetric Trace Translators","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"When the previous and new generative functions (e.g. p1 and p2 in the previous example) are the same, and their arguments are the same, and q_forward and q_backward (and their arguments) are also identical, we call this the trace translator a Symmetric Trace Translator. Symmetric trace translators are important because they form the basis of Involutive MCMC. Instead of translating a trace of one generative function to the trace of another generative function, they translate a trace of a generative function to another trace of the same generative function.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Symmetric trace translators have the interesting property that the function f is an involution, or a function that is its own inverse. To indicate that a trace transform is an involution, use is_involution!.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Because symmetric trace translators translate within the same generative function, their implementation uses update to incrementally modify the trace from the previous to the new trace. This has two benefits when the previous and new traces have random choices that aren't modified between them: (i) the incremental modification may be more efficient than writing the new trace entirely from scratch, and (ii) the transform DSL program does not need to specify a value for addresses whose value is not changed from the previous trace.","category":"page"},{"location":"ref/inference/trace_translators/#Simple-Extending-Trace-Translators","page":"Trace Translators","title":"Simple Extending Trace Translators","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Simple extending trace translators extend an existing trace with new random choices sampled from a proposal distribution, as well as any new observations. The arguments of the trace may also be updated. This type of trace translation is the basic operation used in Particle Filtering. For example, we might have a model that sequentially samples new latent variables (:z, t) and observations (:x, t) for each timestep t:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function model(T::Int)\n    for t in 1:T\n        z = {(:z, t)} ~ normal(0, 1)\n        x = {(:x, t)} ~ normal(z, 1)\n    end\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Each time we observe a new (:x ,t), we might want to propose (:z, t) so that it is close in value:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@gen function proposal(trace::Trace, x::Real)\n    t = get_args(trace)[1] + 1\n    {(:z, t)} ~ normal(x, 1)\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Suppose we initially generated a trace up to timestep t=1, e.g. by calling t1 = simulate(model, (1,)). Now we observe (:x, 2) to be 5.0. By constructing a simple extending trace translator, we can simultaneously update the trace t1 with new arguments, introduce the new observation at (:x, 2), and propose a likely value for (:z, 2):","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"translator = SimpleExtendingTraceTranslator(\n    p_new_args=(2,), p_argdiffs=(UnknownChange(),),\n    new_observations=choicemap((:x, 2) => 5.0),\n    q_forward=proposal, q_forward_args=(5.0,))\nt2, log_weight = translator(t1)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Similar functionality can be achieved through a combination of propose on the proposal and update on the original trace, but using a trace translator provides a nice layer of abstraction.","category":"page"},{"location":"ref/inference/trace_translators/#Trace-Transform-DSL","page":"Trace Translators","title":"Trace Transform DSL","text":"","category":"section"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"The Trace Transform DSL is a differentiable programming language for writing deterministic transformations of traces. Programs written in this DSL are called transforms. Transforms read the value of random choices from input trace(s) and write values of random choices to output trace(s). These programs are not typically executed directly by users, but are instead wrapped into one of the several forms of trace translators listed above (GeneralTraceTranslator, and SymmetricTraceTranslator).","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"A transform is identified with the @transform macro, and uses one of the following four syntactic forms for the signature (the name of the transform, and the names of the input and output traces are all user-defined varibles; the only keywords are @transform, to, begin, and end):","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"A transform from one trace to another, without extra parameters","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f t1 to t2 begin\n    ...\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"A transform from one trace to another, with extra parameters","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f(x, y, ..) t1 to t2 begin\n    ...\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"A transform from pairs of traces to pairs of traces, without extra parameters","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f (t1, t2) to (t3, t4) begin\n    ...\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"A transform from one trace to another, with extra parameters","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform f(x, y, ..) (t1, t2) to (t3, t4) begin\n    ...\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"The extra parameters are optional, and can be used to pass arguments to a transform function that is invoked, from another transform function, using the @tcall macro. For example:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@transform g(x) t1 to t2 begin\n    ...\nend\n@transform f t1 to t2 begin\n    x = ..\n    @tcall(g(x))\nend","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"The callee transform function (g above) reads and writes to the same input and output traces as the caller transform function (f above). Note that the input and output traces can be assigned different names in the caller and the callee.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"The body of a transform reads the values of random choices at addresses in the input trace(s), performs computation using regular Julia code (provided this code can be differentiated with ForwardDiff.jl) and writes valeus of random choices at addresses in the output trace(s). In the body @read expressions read a value from a particular address of an input trace:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"val = @read(<source>, <type-label>)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"where <source> is an expression of the form <trace>[<addr>] where <trace> must be the name of an input trace in the transform's signature. The <type-label> is either :continuous or :discrete, and indicates whether the random choice is discrete or continuous (in measure-theoretic terms, whether it uses the counting measure, or a Lebesgue-measure a Euclidean space of some dimension). Similarly, @write expressions write a value to a particular address in an output trace:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@write(<destination>, <value>, <type-label>)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Sometimes trace transforms need to directly copy the value from one address in an input trace to one address in an output trace. In these cases, it is recommended to use the explicit @copy expression:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@copy(<source>, <destination>)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"where <source> and <destination> are of the form <trace>[<addr>] as above. Note you can also copy collections of multiple random choices under an address namespace in an input trace to an address namespace in an output trace. For example,","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"@copy(trace1[:foo], trace2[:bar])","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"will copy every random choice in trace1 with an address of the form :foo => <rest> to trace2 at address :bar => <rest>.","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"It is also possible to read the return value from an input trace using the following syntax, but this value must be discrete (in the local neighborhood of traces, the return value must be constant as a function of all continuous random choices in input traces):","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"val = @read(<trace>[], :discrete)","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"This feature is useful when the generative function precomputes a quantity as part of its return value, and we would like to reuse this value, instead of having to recompute it as part of the transform. The `discrete' requirement is needed because the transform DSL does not currently backpropagate through the return value (this feature could be added in the future).","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"Tips for defining valid transforms:","category":"page"},{"location":"ref/inference/trace_translators/","page":"Trace Translators","title":"Trace Translators","text":"If you find yourself copying the same continuous source address to multiple locations, it probably means your transform is not valid (the Jacobian matrix will have rows that are identical, and so the Jacobian determinant will be zero).\nYou can gain some confidence that your transform is valid by enabling dynamic checks (check=true) in the trace translator that uses it.","category":"page"},{"location":"ref/inference/trace_translators/#API","page":"Trace Translators","title":"API","text":"","category":"section"},{"location":"ref/inference/trace_translators/#Gen.@transform","page":"Trace Translators","title":"Gen.@transform","text":"@transform f[(params...)] (in1 [,in2]) to (out1 [,out2])\n    ..\nend\n\nWrite a program in the Trace Transform DSL.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/trace_translators/#Gen.@read","page":"Trace Translators","title":"Gen.@read","text":"@read(<source>, <annotation>)\n\nMacro for reading the value of a random choice from an input trace in the Trace Transform DSL.\n\n<source> is of the form <trace>[<addr>] where <trace> is an input trace, and <annotation> is either :discrete or :continuous.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/trace_translators/#Gen.@write","page":"Trace Translators","title":"Gen.@write","text":"@write(<destination>, <value>, <annotation>)\n\nMacro for writing the value of a random choice to an output trace in the Trace Transform DSL.\n\n<destination> is of the form <trace>[<addr>] where <trace> is an input trace, and <annotation> is either :discrete or :continuous.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/trace_translators/#Gen.@copy","page":"Trace Translators","title":"Gen.@copy","text":"@copy(<source>, <destination>)\n\nMacro for copying the value of a random choice (or a whole namespace of random choices) from an input trace to an output trace in the Trace Transform DSL.\n\n<destination> is of the form <trace>[<addr>] where <trace> is an input trace, and <annotation> is either :discrete or :continuous.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/trace_translators/#Gen.@tcall","page":"Trace Translators","title":"Gen.@tcall","text":"@tcall(ex)\n\nA macro to call a transformation function from inside another transformation fuction.\n\n\n\n\n\n","category":"macro"},{"location":"ref/inference/trace_translators/#Gen.pair_bijections!","page":"Trace Translators","title":"Gen.pair_bijections!","text":"pair_bijections!(f1::TraceTransformDSLProgram, f2::TraceTransformDSLProgram)\n\nAssert that a pair of bijections constructed using the Trace Transform DSL are inverses of one another.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/trace_translators/#Gen.is_involution!","page":"Trace Translators","title":"Gen.is_involution!","text":"is_involution!(f::TraceTransformDSLProgram)\n\nAssert that a bijection constructed with the Trace Transform DSL is its own inverse.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/trace_translators/#Gen.inverse","page":"Trace Translators","title":"Gen.inverse","text":"b::TraceTransformDSLProgram = inverse(a::TraceTransformDSLProgram)\n\nObtain the inverse of a bijection that was constructed with the Trace Transform DSL.\n\nThe inverse must have been associated with the bijection either via pair_bijections! or [is_involution!])(@ref).\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/trace_translators/#Gen.TraceTranslator","page":"Trace Translators","title":"Gen.TraceTranslator","text":"Abstract type for trace translators.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/trace_translators/#Gen.DeterministicTraceTranslator","page":"Trace Translators","title":"Gen.DeterministicTraceTranslator","text":"translator = DeterministicTraceTranslator(;\n    p_new::GenerativeFunction, p_args::Tuple=();\n    new_observations::ChoiceMap=EmptyChoiceMap()\n    f::TraceTransformDSLProgram)\n\nConstructor for a deterministic trace translator.\n\nRun the translator with:\n\n(output_trace, log_weight) = translator(input_trace)\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/trace_translators/#Gen.GeneralTraceTranslator","page":"Trace Translators","title":"Gen.GeneralTraceTranslator","text":"translator = GeneralTraceTranslator(;\n    p_new::GenerativeFunction,\n    p_new_args::Tuple = (),\n    new_observations::ChoiceMap = EmptyChoiceMap(),\n    q_forward::GenerativeFunction,\n    q_forward_args::Tuple  = (),\n    q_backward::GenerativeFunction,\n    q_backward_args::Tuple  = (),\n    f::TraceTransformDSLProgram)\n\nConstructor for a general trace translator.\n\nRun the translator with:\n\n(output_trace, log_weight) = translator(input_trace; check=false, prev_observations=EmptyChoiceMap())\n\nUse check to enable a bijection check (this requires that the transform f has been paired with its inverse using `pair_bijections! or is_involution!).\n\nIf check is enabled, then prev_observations is a choice map containing the observed random choices in the previous trace.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/trace_translators/#Gen.SimpleExtendingTraceTranslator","page":"Trace Translators","title":"Gen.SimpleExtendingTraceTranslator","text":"translator = SimpleExtendingTraceTranslator(;\n    p_new_args::Tuple = (),\n    p_argdiffs::Tuple = (),\n    new_observations::ChoiceMap = EmptyChoiceMap(),\n    q_forward::GenerativeFunction,\n    q_forward_args::Tuple  = ())\n\nConstructor for a simple extending trace translator.\n\nRun the translator with:\n\n(output_trace, log_weight) = translator(input_trace)\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/trace_translators/#Gen.SymmetricTraceTranslator","page":"Trace Translators","title":"Gen.SymmetricTraceTranslator","text":"translator = SymmetricTraceTranslator(;\n    q::GenerativeFunction,\n    q_args::Tuple = (),\n    involution::Union{TraceTransformDSLProgram,Function})\n\nConstructor for a symmetric trace translator.\n\nThe involution is either constructed via the @transform macro (recommended), or can be provided as a Julia function.\n\nRun the translator with:\n\n(output_trace, log_weight) = translator(input_trace; check=false, observations=EmptyChoiceMap())\n\nUse check to enable the involution check (this requires that the transform f has been marked with is_involution!).\n\nIf check is enabled, then observations is a choice map containing the observed random choices, and the check will additionally ensure they are not mutated by the involution.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/trace_translators/#Gen.TraceTransformDSLProgram","page":"Trace Translators","title":"Gen.TraceTransformDSLProgram","text":"TraceTransformDSLProgram\n\nA program compiled from the Trace Transform DSL.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/enumerative/#Enumerative-Inference","page":"Enumerative Inference","title":"Enumerative Inference","text":"","category":"section"},{"location":"ref/inference/enumerative/","page":"Enumerative Inference","title":"Enumerative Inference","text":"Enumerative inference can be used to compute the exact posterior distribution for a generative model with a finite number of discrete random choices, to compute a grid approximation of a continuous  posterior density, or to perform stratified sampling by enumerating over discrete random choices and sampling  the continuous random choices. This functionality is provided by enumerative_inference.","category":"page"},{"location":"ref/inference/enumerative/#Gen.enumerative_inference","page":"Enumerative Inference","title":"Gen.enumerative_inference","text":"(traces, log_norm_weights, lml_est) = enumerative_inference(\n    model::GenerativeFunction, model_args::Tuple,\n    observations::ChoiceMap, choice_vol_iter\n)\n\nRun enumerative inference over a model, given observations and an iterator over  choice maps and their associated log-volumes (choice_vol_iter), specifying the choices to be iterated over. An iterator over a grid of choice maps and log-volumes can be constructed with choice_vol_grid.\n\nReturn an array of traces and associated log-weights with the same shape as  choice_vol_iter. The log-weight of each trace is normalized, and corresponds to the log probability of the volume of sample space that the trace represents. Also return an estimate of the log marginal likelihood of the observations (lml_est).\n\nAll addresses in the observations choice map must be sampled by the model when given the model arguments. The same constraint applies to choice maps enumerated over by choice_vol_iter, which must also avoid sharing addresses with the  observations. When the choice maps in choice_vol_iter do not fully specify the values of all unobserved random choices, the unspecified choices are sampled from the internal proposal distribution of the model.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/enumerative/","page":"Enumerative Inference","title":"Enumerative Inference","text":"To construct a rectangular grid of choice maps and their associated log-volumes to iterate over, use the choice_vol_grid function.","category":"page"},{"location":"ref/inference/enumerative/#Gen.choice_vol_grid","page":"Enumerative Inference","title":"Gen.choice_vol_grid","text":"choice_vol_grid((addr, vals, [support, dims])::Tuple...; anchor=:midpoint)\n\nGiven tuples of the form (addr, vals, [support, dims]), construct an iterator over tuples of the form (choices::ChoiceMap, log_vol::Real) via grid enumeration. \n\nEach addr is an address of a random choice, and vals are the corresponding  values or intervals to enumerate over. The (optional) support denotes whether each random choice is :discrete (default) or :continuous. This controls how the grid is constructed:\n\nsupport = :discrete: The grid iterates over each value in vals.\nsupport = :continuous and dims == Val(1): The grid iterates over the anchors of 1D intervals whose endpoints are given by vals.\nsupport = :continuous and dims == Val(N) where N > 1:  The grid iterates over the anchors of multi-dimensional regions defined vals, which is a tuple of interval endpoints for each dimension. \n\nContinuous choices are assumed to have dims = Val(1) dimensions by default. The anchor keyword argument controls which point in each interval is used as the anchor (:left, :right, or :midpoint).\n\nThe log-volume log_vol associated with each set of choices in the grid is given by the log-product of the volumes of each continuous region used to construct those choices. If all addresses enumerated over are :discrete, then log_vol = 0.0.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/enumerative/","page":"Enumerative Inference","title":"Enumerative Inference","text":"When the space of possible choice maps is not rectangular (e.g. some addresses only exist depending on the values of other addresses), iterators over choice maps and log-volumes can be also be manually constructed.","category":"page"},{"location":"tutorials/modeling_in_gen/#modeling_tutorial","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Welcome! In this tutorial, you'll get your feet wet with Gen, a multi-paradigm platform for probabilistic modeling and inference. By \"multi-paradigm,\" we mean that Gen supports many different approaches to modeling and inference:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Unsupervised learning and posterior inference in generative models using Monte Carlo,  variational, EM, and stochastic gradient techniques.\nSupervised learning of conditional inference models (e.g. supervised classification and regression).\nHybrid approaches including amortized inference / inference compilation, variational autoencoders, and semi-supervised learning.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Don't worry if you haven't seen some of these approaches before. One goal of these tutorials will be to introduce you to a subset of them, from a unified probabilistic programming perspective.","category":"page"},{"location":"tutorials/modeling_in_gen/#In-this-Tutorial","page":"Introduction to Modeling in Gen","title":"In this Tutorial","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Approaching a problem from a probabilistic perspective requires both modeling and inference:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Modeling: You first need to frame the problem — and any assumptions you bring to the table — as a probabilistic model. A huge variety of problems can be viewed from a modeling & inference lens, if you set them up properly.  This tutorial is about how to think of problems in this light, and how to use Gen to formally specify your assumptions and the tasks you wish to solve.\nInference: You then need to do the hard part: inference, that is,  solving the problem. In this tutorial, we'll use a particularly simple  generic inference algorithm: importance sampling with the prior as our proposal distributions. With enough computation, the algorithm  can in theory solve any modeling and inference problem, but in practice, for most problems of interest, it is too slow to achieve accurate results in a reasonable amount of time.  Future tutorials introduce some of Gen's programmable inference features,  which let you tailor the inference algorithm for use with more complex models (Gen will still automate the math!).","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Throughout this tutorial, we will emphasize key degrees of modeling flexibility afforded by the probabilistic programming approach, for example:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Using a stochastic branching and function abstraction to express uncertainty about which of multiple models is appropriate.\nRepresenting models with an unbounded number of parameters (a 'Bayesian non-parametric' model) using loops and recursion.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We'll also introduce a technique for validating a model and inference algorithm by predicting new data from inferred parameters, and comparing this data to the observed data set.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"However, this tutorial does not exhaustively cover all features of Gen's modeling language.  For example, Gen's modeling combinators and its static modeling language enable improved performance, but are not covered here.","category":"page"},{"location":"tutorials/modeling_in_gen/#Gen-and-Julia","page":"Introduction to Modeling in Gen","title":"Gen and Julia","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Gen is a package for the Julia language. The package can be loaded with:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"using Gen","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Gen programs typically consist of a combination of (i) probabilistic models written in modeling languages and (ii) inference programs written in regular Julia code. Gen provides a built-in modeling language that is itself based on Julia.  This tutorial uses the Plots.jl Julia package for plotting.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"using Plots","category":"page"},{"location":"tutorials/modeling_in_gen/#gfi_tutorial_section","page":"Introduction to Modeling in Gen","title":"Generative Functions","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Probabilistic models are represented in Gen as generative functions. Generative functions are used to represent a variety of different types of probabilistic computations including generative models, inference models, custom proposal distributions, and variational approximations (see the Gen documentation or the  paper). In this tutorial, we focus on implementing generative models. A generative model represents a data-generating process; as such, it encodes any assumptions we have about our data and our problem domain.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The simplest way to construct a generative function is by using the built-in modeling DSL. Generative functions written in the built-in modeling DSL are based on Julia function definition syntax, but are prefixed with the @gen macro:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function function_name_here(input_arguments)\n    # Function body...\nend","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The function represents the data-generating process we are modeling. Conceptually, every time we run the function, it should generate a new \"synthetic dataset\" in line with our assumptions. Along the way, it will make random choices; each random choice it makes can be thought of as adding a random variable to a probabilistic model.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Within the function body, most Julia code is permitted, but random choices use special syntax that annotates them with an address:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"{addr} ~ distribution(parameters)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"A simple example of such an invocation is a normal distribution parametrized with mean 0 and standard deviation 1:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"my_variable = {:my_variable_address} ~ normal(0, 1)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Every random choice must be given an address, which can be an arbitrary value—but we often use a symbol.  (:my_variable_address is a symbol in the Julia language.) Think of the address as the name of a particular random choice, which is distinct from the name of the variable. For example, consider the following code:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"x = {:initial_x} ~ normal(0, 1)\nif x < 0\n    x = x + ({:addition_to_x} ~ normal(2, 1))\nend","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"This code manipulates a single variable, x, but may make up to two random choices: :initial_x and :addition_to_x.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Note that we can only use ~ to give addresses to random choices.  The following will not work because the code is trying to trace the expression sin(x) which is an invocation of an ordinary Julia function, not a distribution. ","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"# INVALID:\nmy_variable = {:not_a_random_choice} ~ sin(x)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"(We will see a bit later that it is also possible to use ~ to sample from helper generative functions, not just primitive  distributions like normal. But for now, think of ~ as being for making random choices.)","category":"page"},{"location":"tutorials/modeling_in_gen/#Example-1:-Linear-regression","page":"Introduction to Modeling in Gen","title":"Example 1: Linear regression","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Suppose we have a dataset of points (x y) in the plane, and we'd like  to infer a likely slope and intercept that explains their (linear) relationship. To approach this problem from a probabilistic perspective, we first need to develop a model. The model answers the question: how might this dataset have come to be? It also encodes our assumptions, e.g., our assumption that our data is explained by a linear relationship between x and y.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The generative function below represents a probabilistic model of a linear relationship in the x-y plane. Given a set of x coordinates, it randomly chooses a line in the plane and generates corresponding y coordinates so that each (x y) is near the line. We might think of this function as modeling house prices as a function of square footage, or the measured volume of a gas as a function of its measured temperature.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function line_model(xs::Vector{Float64})\n    # We begin by sampling a slope and intercept for the line.\n    # Before we have seen the data, we don't know the values of\n    # these parameters, so we treat them as random choices. The\n    # distributions they are drawn from represent our prior beliefs\n    # about the parameters: in this case, that neither the slope nor the\n    # intercept will be more than a couple points away from 0.\n    slope = ({:slope} ~ normal(0, 1))\n    intercept = ({:intercept} ~ normal(0, 2))\n    \n    # We define a function to compute y for a given x\n    function y(x)\n        return slope * x + intercept\n    end\n\n    # Given the slope and intercept, we can sample y coordinates\n    # for each of the x coordinates in our input vector.\n    for (i, x) in enumerate(xs)\n        # Note that we name each random choice in this loop\n        # slightly differently: the first time through,\n        # the name (:y, 1) will be used, then (:y, 2) for\n        # the second point, and so on.\n        ({(:y, i)} ~ normal(y(x), 0.1))\n    end\n\n    # Most of the time, we don't care about the return\n    # value of a model, only the random choices it makes.\n    # It can sometimems be useful to return something\n    # meaningful, however; here, we return the function `y`.\n    return y\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The generative function takes as an argument a vector of x-coordinates. We create one below:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"xs = [-5., -4., -3., -2., -1., 0., 1., 2., 3., 4., 5.]\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Given this vector, the generative function samples a random choice representing the slope of a line from a normal distribution with mean 0 and standard deviation 1, and a random choice representing the intercept of a line from a normal distribution with mean 0 and standard deviation 2. In Bayesian statistics terms, these distributions are the prior distributions of the slope and intercept respectively. Then, the function samples values for the y-coordinates corresponding to each of the provided x-coordinates.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"This generative function returns a function y encoding the slope and intercept.  We can run the model like we run a regular Julia function:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"y = line_model(xs)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"This gives us the return value of the model, but we may be more interested in the values of the random choices that line_model makes. Crucially, each random choice is annotated with a unique address. A random choice is assigned an address using the {addr} ~ ... keyword. Addresses can be any Julia value. In this program, there are two types of addresses used – Julia symbols and tuples of symbols and integers. Note that within the for loop, the same line of code is executed multiple times, but each time, the random choice it makes is given a distinct address.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Although the random choices are not included in the return value, they are included in the execution trace of the generative function. We can run the generative function and obtain its trace using the simulate method from the Gen API:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace = Gen.simulate(line_model, (xs,));\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"This method takes the function to be executed, and a tuple of arguments to the function, and returns a trace and a second value that we will not be using in this tutorial. When we print the trace, we see that it is a complex data structure.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"println(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"A trace of a generative function contains various information about an execution of the function. For example, it contains the arguments on which the function was run, which are available with the API method get_args:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Gen.get_args(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The trace also contains the value of the random choices, stored in a map from address to value called a choice map. This map is available through the API method get_choices:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Gen.get_choices(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We can pull out individual values from this map using Julia's subscripting syntax [...]:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"choices = Gen.get_choices(trace)\nchoices[:slope]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We can also read the value of a random choice directly from the trace, without having to use get_choices first:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace[:slope]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The return value is also recorded in the trace, and is accessible with the get_retval API method:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Gen.get_retval(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Or we can access the return value directly from the trace via the syntactic sugar trace[]:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace[]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"In order to understand the probabilistic behavior of a generative function, it is helpful to be able to visualize its traces. Below, we define a function that uses PyPlot to render a trace of the generative function above. The rendering shows the x-y data points and the line that is represented by the slope and intercept choices.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function render_trace(trace; show_data=true)\n    \n    # Pull out xs from the trace\n    xs, = get_args(trace)\n    \n    xmin = minimum(xs)\n    xmax = maximum(xs)\n\n    # Pull out the return value, useful for plotting\n    y = get_retval(trace)\n    \n    # Draw the line\n    test_xs = collect(range(-5, stop=5, length=1000))\n    fig = plot(test_xs, map(y, test_xs), color=\"black\", alpha=0.5, label=nothing,\n                xlim=(xmin, xmax), ylim=(xmin, xmax))\n\n    if show_data\n        ys = [trace[(:y, i)] for i=1:length(xs)]\n        \n        # Plot the data set\n        scatter!(xs, ys, c=\"black\", label=nothing)\n    end\n    \n    return fig\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"render_trace(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Because a generative function is stochastic, we need to visualize many runs in order to understand its behavior. The cell below renders a grid of traces.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function grid(renderer::Function, traces)\n    Plots.plot(map(renderer, traces)...)\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [Gen.simulate(line_model, (xs,)) for _=1:12]\ngrid(render_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Write a generative function that uses the same address twice. Run it to see what happens.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-2","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Write a model that generates a sine wave with random phase, period and amplitude, and then generates y-coordinates from a given vector of x-coordinates by adding noise to the value of the wave at each x-coordinate. Use a  gamma(1, 1) prior distribution for the period, and a gamma(1, 1) prior distribution on the amplitude (see Gen.gamma). Sampling from a Gamma distribution will ensure to give us postive real values. Use a uniform distribution between 0 and 2pi for the phase (see Gen.uniform).","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The sine wave should implement:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"$ y(x) = a \\sin(2\\pi \\frac{1}{p} x + \\varphi)$,","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"where a is the amplitude, p is the period and varphi is the phase.  In Julia the constant pi can be expressed as either pi or π (unicode).","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"When calling trace = Gen.simulate(sine_model, (xs,)), the following choices should appear:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"amplitude: trace[:amplitude]\nperiod: trace[:period]\nphase: trace[:phase]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We have provided some starter code for the sine wave model:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function sine_model(xs::Vector{Float64})\n    \n    # < your code here, for sampling a phase, period, and amplitude >\n\n    function y(x)\n        return 1 # < Edit this line to compute y for a given x >\n    end\n    \n    for (i, x) in enumerate(xs)\n        {(:y, i)} ~ normal(y(x), 0.1)\n    end\n    \n    return y # We return the y function so it can be used for plotting, below. \nend","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"<details><summary>Solution</summary>","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function sine_model(xs)\n    period = {:period} ~ gamma(1, 1)\n    amplitude = {:amplitude} ~ gamma(1, 1)\n    phase = {:phase} ~ uniform(0, 2*pi)\n\n    # Define a deterministic sine wave with the values above\n    function y(x)\n        return amplitude * sin(x * (2 * pi / period) + phase)\n    end\n\n    for (i, x) in enumerate(xs)\n        {(:y, i)} ~ normal(y(x), 0.1)\n    end\n\n    return y\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [Gen.simulate(sine_model, (xs,)) for _=1:12];\ngrid(render_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"</details>","category":"page"},{"location":"tutorials/modeling_in_gen/#Posterior-Inference","page":"Introduction to Modeling in Gen","title":"Posterior Inference","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Of course, we don't really care about generating lots of pictures of lines (or sine waves). We'd really like to begin with an actual dataset of observed (x y) points, and infer the corresponding slope and intercept (or phase, period, and amplitude). This task is called posterior inference.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We now will provide a data set of y-coordinates and try to draw inferences about the process that generated the data. We begin with the following data set:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"ys = [6.75003, 6.1568, 4.26414, 1.84894, 3.09686, 1.94026, 1.36411, -0.83959, -0.976, -1.93363, -2.91303];\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"scatter(xs, ys, color=\"black\", label=nothing, title=\"Observed data (linear)\", xlabel=\"X\", ylabel=\"Y\")\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We will assume that the line model was responsible for generating the data, and infer values of the slope and intercept that explain the data.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"To do this, we write a simple inference program that takes the model we are assuming generated our data, the data set, and the amount of computation to perform, and returns a trace of the function that is approximately sampled from the posterior distribution on traces of the function, given the observed data. That is, the inference program will try to find a trace that well explains the dataset we created above. We can inspect that trace to find estimates of the slope and intercept of a line that fits the data.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Functions like importance_resampling expect us to provide a model and also an choice map representing our data set and relating it to the model. A choice map maps random choice addresses from the model to values from our data set. Here, we want to tie model addresses like (:y, 4) to data set values like ys[4]:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function do_inference(model, xs, ys, amount_of_computation)\n    \n    # Create a choice map that maps model addresses (:y, i)\n    # to observed values ys[i]. We leave :slope and :intercept\n    # unconstrained, because we want them to be inferred.\n    observations = Gen.choicemap()\n    for (i, y) in enumerate(ys)\n        observations[(:y, i)] = y\n    end\n    \n    # Call importance_resampling to obtain a likely trace consistent\n    # with our observations.\n    (trace, _) = Gen.importance_resampling(model, (xs,), observations, amount_of_computation);\n    return trace\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We can run the inference program to obtain a trace, and then visualize the result:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace = do_inference(line_model, xs, ys, 100)\nrender_trace(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We see that importance_resampling found a reasonable slope and intercept to explain the data. We can also visualize many samples in a grid:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [do_inference(line_model, xs, ys, 100) for _=1:10];\ngrid(render_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We can see here that there is some uncertainty: with our limited data, we can't be 100% sure exactly where the line is. We can get a better sense for the variability in the posterior distribution by visualizing all the traces in one plot, rather than in a grid. Each trace is going to have the same observed data points, so we only plot those once, based on the values in the first trace:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function overlay(renderer, traces; same_data=true, args...)\n    fig = renderer(traces[1], show_data=true, args...)\n    \n    xs, = get_args(traces[1])\n    xmin = minimum(xs)\n    xmax = maximum(xs)\n\n    for i=2:length(traces)\n        y = get_retval(traces[i])\n        test_xs = collect(range(-5, stop=5, length=1000))\n        fig = plot!(test_xs, map(y, test_xs), color=\"black\", alpha=0.5, label=nothing,\n                    xlim=(xmin, xmax), ylim=(xmin, xmax))\n    end\n    return fig\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [do_inference(line_model, xs, ys, 100) for _=1:10];\noverlay(render_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-3","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The results above were obtained for amount_of_computation = 100. Run the algorithm with this value set to 1, 10, and 1000, etc.  Which value seems like a good tradeoff between accuracy and running time? Discuss.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-4","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Consider the following data set.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"ys_sine = [2.89, 2.22, -0.612, -0.522, -2.65, -0.133, 2.70, 2.77, 0.425, -2.11, -2.76];","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"scatter(xs, ys_sine, color=\"black\", label=nothing)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Write an inference program that generates traces of sine_model that explain this data set. Visualize the resulting distribution of traces. Temporarily change the prior distribution on the period to be gamma(1, 1)  (by changing and re-running the cell that defines sine_model from a previous exercise). Can you explain the difference in inference results when using gamma(1, 1) vs gamma(5, 1) prior on the period? How much computation did you need to get good results?","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Predicting-New-Data","page":"Introduction to Modeling in Gen","title":"Predicting New Data","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"What if we'd want to predict ys given xs?","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Using the API method generate, we can generate a trace of a generative function in which the values of certain random choices are constrained to given values. The constraints are a choice map that maps the addresses of the constrained random choices to their desired values.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"For example:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"constraints = Gen.choicemap()\nconstraints[:slope] = 0.\nconstraints[:intercept] = 0.\n(trace, _) = Gen.generate(line_model, (xs,), constraints)\nrender_trace(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Note that the random choices corresponding to the y-coordinates are still made randomly. Run the cell above a few times to verify this.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We will use the ability to run constrained executions of a generative function to predict the value of the y-coordinates at new x-coordinates by running new executions of the model generative function in which the random choices corresponding to the parameters have been constrained to their inferred values.  We have provided a function below (predict_new_data) that takes a trace, and a vector of new x-coordinates, and returns a vector of predicted y-coordinates corresponding to the x-coordinates in new_xs. We have designed this function to work with multiple models, so the set of parameter addresses is an argument (param_addrs):","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function predict_new_data(model, trace, new_xs::Vector{Float64}, param_addrs)\n    \n    # Copy parameter values from the inferred trace (`trace`)\n    # into a fresh set of constraints.\n    constraints = Gen.choicemap()\n    for addr in param_addrs\n        constraints[addr] = trace[addr]\n    end\n    \n    # Run the model with new x coordinates, and with parameters \n    # fixed to be the inferred values.\n    (new_trace, _) = Gen.generate(model, (new_xs,), constraints)\n    \n    # Pull out the y-values and return them.\n    ys = [new_trace[(:y, i)] for i=1:length(new_xs)]\n    return ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"To illustrate, we call the function above given the previous trace (which constrained slope and intercept to be zero).","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"predict_new_data(line_model, trace, [1., 2., 3.], [:slope, :intercept])","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The cell below defines a function that first performs inference on an observed data set (xs, ys), and then runs predict_new_data to generate predicted y-coordinates. It repeats this process num_traces times, and returns a vector of the resulting y-coordinate vectors.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function infer_and_predict(model, xs, ys, new_xs, param_addrs, num_traces, amount_of_computation)\n    pred_ys = []\n    for i=1:num_traces\n        trace = do_inference(model, xs, ys, amount_of_computation)\n        push!(pred_ys, predict_new_data(model, trace, new_xs, param_addrs))\n    end\n    pred_ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"To illustrate, we generate predictions at [1., 2., 3.] given one (approximate) posterior trace.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"pred_ys = infer_and_predict(line_model, xs, ys, [1., 2., 3.], [:slope, :intercept], 1, 1000)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Finally, we define a cell that plots the observed data set (xs, ys) as red dots, and the predicted data as small black dots.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function plot_predictions(xs, ys, new_xs, pred_ys; title=\"predictions\")\n    fig = scatter(xs, ys, color=\"red\", label=\"observed data\", title=title)\n    for (i, pred_ys_single) in enumerate(pred_ys)\n        scatter!(new_xs, pred_ys_single, color=\"black\", alpha=0.1, label=i == 1 ? \"predictions\" : nothing)\n    end\n    return fig\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Recall the original dataset for the line model. The x-coordinates span the interval -5 to 5.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"scatter(xs, ys, color=\"red\", label=\"observed data\")","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We will use the inferred values of the parameters to predict y-coordinates for x-coordinates in the interval 5 to 10 from which data was not observed. We will also predict new data within the interval -5 to 5, and we will compare this data to the original observed data. Predicting new data from inferred parameters, and comparing this new data to the observed data is the core idea behind posterior predictive checking. This tutorial does not intend to give a rigorous overview behind techniques for checking the quality of a model, but intends to give high-level intuition.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"new_xs = collect(range(-5, stop=10, length=100));\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We generate and plot the predicted data:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"pred_ys = infer_and_predict(line_model, xs, ys, new_xs, [:slope, :intercept], 20, 1000)\nplot_predictions(xs, ys, new_xs, pred_ys)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The results look reasonable, both within the interval of observed data and in the extrapolated predictions on the right.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Now consider the same experiment run with the following data set, which has significantly more noise.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"ys_noisy = [5.092, 4.781, 2.46815, 1.23047, 0.903318, 1.11819, 2.10808, 1.09198, 0.0203789, -2.05068, 2.66031];","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"pred_ys = infer_and_predict(line_model, xs, ys_noisy, new_xs, [:slope, :intercept], 20, 1000)\nplot_predictions(xs, ys_noisy, new_xs, pred_ys)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"It looks like the generated data is less noisy than the observed data in the regime where data was observed, and it looks like the forecasted data is too overconfident. This is a sign that our model is mis-specified. In our case, this is because we have assumed that the noise has value 0.1. However, the actual noise in the data appears to be much larger. We can correct this by making the noise a random choice as well and inferring its value along with the other parameters.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We first write a new version of the line model that samples a random choice for the noise from a gamma(1, 1) prior distribution.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function line_model_fancy(xs::Vector{Float64})\n    slope = ({:slope} ~ normal(0, 1))\n    intercept = ({:intercept} ~ normal(0, 2))\n    \n    function y(x)\n        return slope * x + intercept\n    end\n    \n    noise = ({:noise} ~ gamma(1, 1))\n    for (i, x) in enumerate(xs)\n        {(:y, i)} ~ normal(slope * x + intercept, noise)\n    end\n    return y\nend;","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Then, we compare the predictions using inference of the unmodified and modified models on the ys data set:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"pred_ys = infer_and_predict(line_model, xs, ys, new_xs, [:slope, :intercept], 20, 1000)\nfixed_noise_plot = plot_predictions(xs, ys, new_xs, pred_ys; title=\"fixed noise\")\n\npred_ys = infer_and_predict(line_model_fancy, xs, ys, new_xs, [:slope, :intercept, :noise], 20, 10000)\ninferred_noise_plot = plot_predictions(xs, ys, new_xs, pred_ys; title=\"inferred noise\")\n\nplot(fixed_noise_plot, inferred_noise_plot)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Notice that there is more uncertainty in the predictions made using the modified model.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We also compare the predictions using inference of the unmodified and modified models on the ys_noisy data set:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"pred_ys = infer_and_predict(line_model, xs, ys_noisy, new_xs, [:slope, :intercept], 20, 1000)\nfixed_noise_plot = plot_predictions(xs, ys_noisy, new_xs, pred_ys; title=\"fixed noise\")\n\npred_ys = infer_and_predict(line_model_fancy, xs, ys_noisy, new_xs, [:slope, :intercept, :noise], 20, 10000)\ninferred_noise_plot = plot_predictions(xs, ys_noisy, new_xs, pred_ys; title=\"inferred noise\")\n\nplot(fixed_noise_plot, inferred_noise_plot)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Notice that while the unmodified model was very overconfident, the modified model has an appropriate level of uncertainty, while still capturing the general negative trend.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-5","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Write a modified version of the sine model that makes noise into a random choice. Compare the predicted data with the observed data using infer_and_predict and plot_predictions for the unmodified and modified models, and for the ys_sine and ys_noisy data sets. Discuss the results. Experiment with the amount of inference computation used. The amount of inference computation will need to be higher for the model with the noise as a random choice.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We have provided you with starter code:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function sine_model_fancy(xs::Vector{Float64})\n\n    # < your code here >\n\n    for (i, x) in enumerate(xs)\n        {(:y, i)} ~ normal(0., 0.1) # < edit this line >\n    end\n    return nothing\nend","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"<details><summary>Solution</summary>","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function sine_model_fancy(xs::Vector{Float64})\n    period = ({:period} ~ gamma(5, 1))\n    amplitude = ({:amplitude} ~ gamma(1, 1))\n    phase = ({:phase} ~ uniform(0, 2*pi))\n    noise = ({:noise} ~ gamma(1, 1))\n\n    function y(x)\n        return amplitude * sin(x * (2 * pi / period) + phase)\n    end\n\n    for (i, x) in enumerate(xs)\n        {(:y, i)} ~ normal(y(x), noise)\n    end\n\n    return y\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"# Modify the line below to experiment with the amount_of_computation parameter\npred_ys = infer_and_predict(sine_model, xs, ys_sine, new_xs, [], 20, 1)\nfixed_noise_plot = plot_predictions(xs, ys_sine, new_xs, pred_ys; title=\"Fixed noise level\")\n\n# Modify the line below to experiment with the amount_of_computation parameter\npred_ys = infer_and_predict(sine_model_fancy, xs, ys_sine, new_xs, [], 20, 1)\ninferred_noise_plot = plot_predictions(xs, ys_sine, new_xs, pred_ys; title=\"Inferred noise level\")\n\nPlots.plot(fixed_noise_plot, inferred_noise_plot)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"# Modify the line below to experiment with the amount_of_computation parameter\npred_ys = infer_and_predict(sine_model, xs, ys_noisy, new_xs, [], 20, 1)\nfixed_noise_plot = plot_predictions(xs, ys_noisy, new_xs, pred_ys; title=\"Fixed noise level\")\n\n# Modify the line below to experiment with the amount_of_computation parameter\npred_ys = infer_and_predict(sine_model_fancy, xs, ys_noisy, new_xs, [], 20, 1)\ninferred_noise_plot = plot_predictions(xs, ys_noisy, new_xs, pred_ys; title=\"Inferred noise level\")\n\nPlots.plot(fixed_noise_plot, inferred_noise_plot)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"</details>","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Calling-Other-Generative-Functions","page":"Introduction to Modeling in Gen","title":"Calling Other Generative Functions","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"In addition to making random choices, generative functions can invoke other generative functions. To illustrate this, we will write a probabilistic model that combines the line model and the sine model. This model is able to explain data using either model, and which model is chosen will depend on the data. This is called model selection.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"A generative function can invoke another generative function in three ways:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"(NOT RECOMMENDED) using regular Julia function call syntax: f(x)\nusing the ~ snytax with an address for the call: {addr} ~ f(x)\nusing the ~ syntax with a wildcard address: {*} ~ f(x)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"When invoking using regular function call syntax, the random choices made by the callee function are not traced at all, and Gen cannot reason about them during inference.  When invoking using ~ with a wildcard address ({*} ~ f(x)), the random choices of the  callee function are imported directly into the caller's trace. So, for example, if f makes a choice called :f_choice, then the caller's trace will have a choice called :f_choice too.  Note that a downside of this is that if f is called twice by the same caller, then the two  choices called :f_choice will clash, leading to an error. In this case, it is best to provide an address ({addr} ~ f(x)): f's random choices will be placed under the namespace addr. ","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function foo()\n    {:y} ~ normal(0, 1)\nend\n\n@gen function bar()\n    {:x} ~ bernoulli(0.5)\n    # Call `foo` with a wildcard address.\n    # Its choices (:y) will appear directly\n    # within the trace of `bar`.\n    {*} ~ foo()\nend\n\n@gen function bar_using_namespace()\n    {:x} ~ bernoulli(0.5)\n    # Call `foo` with the address `:z`.\n    # The internal choice `:y` of `foo`\n    # will appear in our trace at the\n    # hierarchical address `:z => :y`.\n    {:z} ~ foo()\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We first show the addresses sampled by bar:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace = Gen.simulate(bar, ())\nGen.get_choices(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"And the addresses sampled by bar_using_namespace:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace = Gen.simulate(bar_using_namespace, ())\nGen.get_choices(trace)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Using {addr} ~ f(), with a namespace, can help avoid address collisions for complex models.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"A hierarchical address is represented as a Julia Pair, where the first element of the pair is the first element of the address and the second element of the pair is the rest of the address:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace[Pair(:z, :y)]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Julia uses the => operator as a shorthand for the Pair constructor, so we can access choices at hierarchical addresses like:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace[:z => :y]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"If we have a hierarchical address with more than two elements, we can construct the address by chaining the => operator:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function baz()\n    {:a} ~ bar_using_namespace()\nend\n\ntrace = simulate(baz, ())\n\ntrace[:a => :z => :y]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Note that the => operator associated right, so this is equivalent to:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"trace[Pair(:a, Pair(:z, :y))]","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Now, we write a generative function that combines the line and sine models. It makes a Bernoulli random choice (e.g. a coin flip that returns true or false) that determines which of the two models will generate the data.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function combined_model(xs::Vector{Float64})\n    if ({:is_line} ~ bernoulli(0.5))\n        # Call line_model_fancy on xs, and import\n        # its random choices directly into our trace.\n        return ({*} ~ line_model_fancy(xs))\n    else\n        # Call sine_model_fancy on xs, and import\n        # its random choices directly into our trace\n        return ({*} ~ sine_model_fancy(xs))\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We visualize some traces, and see that sometimes it samples linear data and other times sinusoidal data.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [Gen.simulate(combined_model, (xs,)) for _=1:12];\ngrid(render_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We run inference using this combined model on the ys data set and the ys_sine data set. ","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [do_inference(combined_model, xs, ys, 10000) for _=1:10];\nlinear_dataset_plot = overlay(render_trace, traces)\ntraces = [do_inference(combined_model, xs, ys_sine, 10000) for _=1:10];\nsine_dataset_plot = overlay(render_trace, traces)\nPlots.plot(linear_dataset_plot, sine_dataset_plot)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The results should show that the line model was inferred for the ys data set, and the sine wave model was inferred for the ys_sine data set.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-6","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Construct a data set for which it is ambiguous whether the line or sine wave model is best. Visualize the inferred traces using render_combined to illustrate the ambiguity. Write a program that takes the data set and returns an estimate of the posterior probability that the data was generated by the sine wave model, and run it on your data set.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Hint: To estimate the posterior probability that the data was generated by the sine wave model, run the inference program many times to compute a large number of traces, and then compute the fraction of those traces in which :is_line is false.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Modeling-with-an-Unbounded-Number-of-Parameters","page":"Introduction to Modeling in Gen","title":"Modeling with an Unbounded Number of Parameters","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Gen's built-in modeling language can be used to express models that use an unbounded number of parameters. This section walks you through development of a model of data that does not a-priori specify an upper bound on the complexity of the model, but instead infers the complexity of the model as well as the parameters. This is a simple example of a Bayesian nonparametric model.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We will consider two data sets:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"xs_dense = collect(range(-5, stop=5, length=50))\nys_simple = fill(1., length(xs_dense)) .+ randn(length(xs_dense)) * 0.1\nys_complex = [Int(floor(abs(x/3))) % 2 == 0 ? 2 : 0 for x in xs_dense] .+ randn(length(xs_dense)) * 0.1;\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"simple_plot = scatter(xs_dense, ys_simple, color=\"black\", label=nothing, title=\"ys-simple\", ylim=(-1, 3))\ncomplex_plot = scatter(xs_dense, ys_complex, color=\"black\", label=nothing, title=\"ys-complex\", ylim=(-1, 3))\nPlots.plot(simple_plot, complex_plot)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The data set on the left appears to be best explained as a contant function with some noise. The data set on the right appears to include two changepoints, with a constant function in between the changepoints. We want a model that does not a-priori choose the number of changepoints in the data. To do this, we will recursively partition the interval into regions. We define a Julia data structure that represents a binary tree of intervals; each leaf node represents a region in which the function is constant.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"struct Interval\n    l::Float64\n    u::Float64\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"abstract type Node end\n    \nstruct InternalNode <: Node\n    left::Node\n    right::Node\n    interval::Interval\nend\n\nstruct LeafNode <: Node\n    value::Float64\n    interval::Interval\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We now write a generative function that randomly creates such a tree. Note the use of recursion in this function to create arbitrarily large trees representing arbitrarily many changepoints. Also note that we assign the address namespaces :left and :right to the calls made for the two recursive calls to generate_segments.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"@gen function generate_segments(l::Float64, u::Float64)\n    interval = Interval(l, u)\n    if ({:isleaf} ~ bernoulli(0.7))\n        value = ({:value} ~ normal(0, 1))\n        return LeafNode(value, interval)\n    else\n        frac = ({:frac} ~ beta(2, 2))\n        mid  = l + (u - l) * frac\n        # Call generate_segments recursively!\n        # Because we will call it twice -- one for the left \n        # child and one for the right child -- we use\n        # addresses to distinguish the calls.\n        left = ({:left} ~ generate_segments(l, mid))\n        right = ({:right} ~ generate_segments(mid, u))\n        return InternalNode(left, right, interval)\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We also define some helper functions to visualize traces of the generate_segments function.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function render_node!(node::LeafNode)\n    plot!([node.interval.l, node.interval.u], [node.value, node.value], label=nothing, linewidth=5)\nend\n\nfunction render_node!(node::InternalNode)\n    render_node!(node.left)\n    render_node!(node.right)\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function render_segments_trace(trace; xlim=(0,1))\n    node = get_retval(trace)\n    fig = plot(xlim=xlim, ylim=(-3, 3))\n    render_node!(node)\n    return fig\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We generate 12 traces from this function and visualize them below. We plot the piecewise constant function that was sampled by each run of the generative function. Different constant segments are shown in different colors. Run the cell a few times to get a better sense of the distribution on functions that is represented by the generative function.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [Gen.simulate(generate_segments, (0., 1.)) for i=1:12]\ngrid(render_segments_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Because we only sub-divide an interval with 30% probability, most of these sampled traces have only one segment.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Now that we have a generative function that generates a random piecewise-constant function, we write a model that adds noise to the resulting constant functions to generate a data set of y-coordinates. The noise level will be a random choice.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"# get_value_at searches a binary tree for\n# the leaf node containing some value.\nfunction get_value_at(x::Float64, node::LeafNode)\n    @assert x >= node.interval.l && x <= node.interval.u\n    return node.value\nend\n\nfunction get_value_at(x::Float64, node::InternalNode)\n    @assert x >= node.interval.l && x <= node.interval.u\n    if x <= node.left.interval.u\n        get_value_at(x, node.left)\n    else\n        get_value_at(x, node.right)\n    end\nend\n\n# Our full model\n@gen function changepoint_model(xs::Vector{Float64})\n    node = ({:tree} ~ generate_segments(minimum(xs), maximum(xs)))\n    noise = ({:noise} ~ gamma(0.5, 0.5))\n    for (i, x) in enumerate(xs)\n        {(:y, i)} ~ normal(get_value_at(x, node), noise)\n    end\n    return node\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We write a visualization for changepoint_model below:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"function render_changepoint_model_trace(trace; show_data=true)\n    xs = Gen.get_args(trace)[1]\n    node = Gen.get_retval(trace)\n    fig = render_segments_trace(trace; xlim=(minimum(xs), maximum(xs)))\n    render_node!(node)\n    if show_data\n        ys = [trace[(:y, i)] for i=1:length(xs)]\n        scatter!(xs, ys, c=\"gray\", label=nothing, alpha=0.3, markersize=3)\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Finally, we generate some simulated data sets and visualize them on top of the underlying piecewise constant function from which they were generated:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [Gen.simulate(changepoint_model, (xs_dense,)) for i=1:12]\ngrid(render_changepoint_model_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Notice that the amount of variability around the piecewise constant mean function differs from trace to trace.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Now we perform inference for the simple data set:","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [do_inference(changepoint_model, xs_dense, ys_simple, 10000) for _=1:12];\ngrid(render_changepoint_model_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"We see that we inferred that the mean function that explains the data is a constant with very high probability.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"For inference about the complex data set, we use more computation. You can experiment with different amounts of computation to see how the quality of the inferences degrade with less computation. Note that we are using a very simple generic inference algorithm in this tutorial, which really isn't suited for this more complex task. In later tutorials, we will learn how to write more efficient algorithms, so that accurate results can be obtained with significantly less computation. We will also see ways of annotating the model for better performance, no matter the inference algorithm.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"warning: Warning\nThe following cell may run for 2-3 minutes.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"traces = [do_inference(changepoint_model, xs_dense, ys_complex, 100000) for _=1:12];\ngrid(render_changepoint_model_trace, traces)","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"The results show that more segments are inferred for the more complex data set.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-7","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Write a function that takes a data set of x- and y-coordinates and plots the histogram of the probability distribution on the number of changepoints. Show the results for the ys_simple and ys_complex data sets.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Hint: The return value of changepoint_model is the tree of Node values. Walk this tree.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"","category":"page"},{"location":"tutorials/modeling_in_gen/#Exercise-8","page":"Introduction to Modeling in Gen","title":"Exercise","text":"","category":"section"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Write a new version of changepoint_model that uses {*} ~ ... without an address to make the recursive calls.","category":"page"},{"location":"tutorials/modeling_in_gen/","page":"Introduction to Modeling in Gen","title":"Introduction to Modeling in Gen","text":"Hint: You will need to guarantee that all addresses are unique. How can you label each node in a binary tree using an integer?","category":"page"},{"location":"tutorials/smc/#smc_tutorial","page":"Object Tracking with SMC","title":"Object Tracking with Sequential Monte Carlo","text":"","category":"section"},{"location":"tutorials/smc/#Introduction","page":"Object Tracking with SMC","title":"Introduction","text":"","category":"section"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"So far, we've seen two general classes of inference algorithm, importance sampling and MCMC. Very informally, and focusing only on one aspect of the algorithms, we might describe them as follows:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Importance Sampling: guesses solutions \"all at once\" using a proposal distribution. That proposal may be \"smart\" (e.g., a neural network), but still guesses an entire solution in one go. We make many guesses, and weight them according to the importance weighting formula.\nMCMC: beginning with an initial guess, iteratively refine the guess to explore the space of  possible solutions. At every iteration, the current state is an entire proposed solution to the problem.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"In this tutorial, we will explore a third paradigm: Sequential Monte Carlo (SMC). SMC methods, such as particle filtering, iteratively solve a sequence of inference problems using techniques  based on importance sampling and in some cases MCMC [1][2]. The solution to each problem in the sequence  is represented as a collection of samples or particles. The particles for each problem are based on  extending or adjusting the particles for the previous problem in the sequence.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"The sequence of inference problems that are solved often arise naturally from observations that arrive incrementally, as in particle filtering. Particle filtering algorithms are a subclass of SMC algorithms, often applied to state-space models in which we observe an evolving process over time. We begin by only considering the first time step, inferring the latent variables at that time step given that time step's observations. We then consider a slightly more difficult inference problem: joint inference of the first two time steps' latent variables, given both time steps' observations. And so on, until the observations stop.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"SMC is a more general algorithm than the particle filter might suggest. Sometimes, the sequence of problems does not arise from data arriving incrementally, but is rather constructed instrumentally to facilitate inference, as in annealed importance sampling [3]. ","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"However, this tutorial focuses on particle filtering for a typical tracking problem. We show how Gen's support for SMC integrates with its support for MCMC, enabling \"rejuvenation\" MCMC moves. Specifically, we will address the \"bearings only tracking\" problem described in [4]. ","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"This tutorial will also introduce you to the  Unfold combinator,  which can be used to improve performance of SMC. Unfold is just one example of the levers that Gen provides for improving performance; once you understand it, you can check Gen's documentation to see how similar principles apply to the  Map combinator  and to the static DSL. (These features are also covered in the previous tutorial, Scaling with the Static Modeling Language)","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Prerequisites for this tutorial","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Static Modeling Language for the second half of the tutorial.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"[1]: Doucet, Arnaud, Nando De Freitas, and Neil Gordon. \"An introduction to sequential Monte Carlo methods.\" Sequential Monte Carlo methods in practice. Springer, New York, NY, 2001. 3-14.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"[2]: Del Moral, Pierre, Arnaud Doucet, and Ajay Jasra. \"Sequential Monte Carlo samplers.\" Journal of the Royal Statistical Society: Series B (Statistical Methodology) 68.3 (2006): 411-436.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"[3]: Neal, Radford M. \"Annealed importance sampling.\" Statistics and computing 11.2 (2001): 125-139.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"[4]: Gilks, Walter R., and Carlo Berzuini. \"Following a moving target—Monte Carlo inference for dynamic Bayesian models.\" Journal of the Royal Statistical Society: Series B (Statistical Methodology) 63.1 (2001): 127-146. PDF","category":"page"},{"location":"tutorials/smc/#Implementing-the-Generative-Model","page":"Object Tracking with SMC","title":"Implementing the Generative Model","text":"","category":"section"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We will implement a generative model for the movement of a point in the x-y plane and bearing measurements of the location of this point relative to the origin over time. We imagine, for example, that we are located at the origin, and can measure the location of a far-away ship (the object we are tracking) only by measuring its bearing relative to us, i.e., the angle formed with the x axis by the ray connecting us to the ship. We would like to infer its (x, y) position over time.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We assume that we know the approximate initial position and velocity of the ship. We assume the point's x- and y- velocity are subject to random perturbations drawn from some normal distribution with a known variance. Each bearing measurement consists of the angle of the point being tracked relative to the positive x-axis.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We write the generative model as a generative function below. The function first samples the initial state of the ship from a prior distribution, and then generates T successive states in a for loop. The argument to the model (T) is the number of time steps not including the initial state.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"using Gen, Plots\nbearing(x, y) = atan(y, x)\n\n@gen function model(T::Int)\n\n    measurement_noise = 0.005\n    velocity_var = 1e-6\n\n    xs = Vector{Float64}(undef, T+1)\n    ys = Vector{Float64}(undef, T+1)\n\n    # prior on initial x-coordinate\n    x = {:x0} ~ normal(0.01, 0.01)\n\n    # prior on initial y-coordinate\n    y = {:y0} ~ normal(0.95, 0.01)\n\n    # prior on x-component of initial velocity\n    vx = {:vx0} ~ normal(0.002, 0.01)\n\n    # prior on y-component of initial velocity\n    vy = {:vy0} ~ normal(-0.013, 0.01)\n\n    # initial bearing measurement\n    z0 ~ normal(bearing(x, y), measurement_noise)\n\n    # record position\n    xs[1] = x\n    ys[1] = y\n\n    # generate successive states and measurements\n    for t=1:T\n\n        # update the state of the point\n        vx = {(:vx, t)} ~ normal(vx, sqrt(velocity_var))\n        vy = {(:vy, t)} ~ normal(vy, sqrt(velocity_var))\n        x += vx\n        y += vy\n\n        # bearing measurement\n        {(:z, t)} ~ normal(bearing(x, y), measurement_noise)\n\n        # record position\n        xs[t+1] = x\n        ys[t+1] = y\n    end\n\n    # return the sequence of positions\n    return (xs, ys)\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Note that the model function itself uses mutation to evolve the variables x, y, vx, and vy over time. The {addr} ~ distribution() syntax keeps the names of traced random variables (for which each address may only be used once) separate from the names of program variables, like x, which may be reassigned multiple times during the function's execution.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We generate a data set of positions, and observed bearings, by sampling from this model, with T=50:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"import Random\nRandom.seed!(3)\n\n# generate trace with specific initial conditions\nT = 50\nconstraints = Gen.choicemap((:x0, 0.01), (:y0, 0.95), (:vx0, 0.002), (:vy0, -0.013))\n(trace, _) = Gen.generate(model, (T,), constraints)\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Let's extract the observed data zs from the trace","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"choices = Gen.get_choices(trace)\nzs = Vector{Float64}(undef, T+1)\nzs[1] = choices[:z0]\nfor t=1:T\n    zs[t+1] = choices[(:z, t)]\nend\nzs","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We next write a visualization for full traces of this model. It shows the ship's positions (as dots) as well as the observed bearings (as fixed length line  segments from the origin):","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function render(trace; show_data=true, max_T=get_args(trace)[1], overlay=false)\n    (T,) = Gen.get_args(trace)\n    (xs, ys) = Gen.get_retval(trace)\n    \n    zs = Vector{Float64}(undef, T+1)\n    zs[1] = trace[:z0]\n    for t=1:T\n        zs[t+1] = trace[(:z, t)]\n    end\n    \n    f = overlay ? scatter! : scatter\n    fig = f(xs[1:max_T+1], ys[1:max_T+1], msize=3, msw=1, label=nothing)\n    \n    if show_data\n        for z in zs[1:max_T+1]\n            dx = cos(z) * 0.5\n            dy = sin(z) * 0.5\n            plot!([0., dx], [0., dy], color=\"red\", alpha=0.3, label=nothing)\n        end\n    end\n    \n    return fig\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We visualize the synthetic trace below:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"render(trace)\ntitle!(\"Observed bearings (lines) and positions (dots)\")","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Note that these are the observed bearings, but we are not plotting the \"ground truth\" locations of the ship. There are many trajectories consistent with these bearings; for each of the red rays in the above plot, the ship could be anywhere along the ray (or even slightly off it, given that our measurements are noisy). However, our assumptions about the dynamics of the situation &mdash; that is, the conditional distributions P(x_t+1 y_t+1 mid x_t y_t) &mdash; will ensure that physics-defying trajectories (e.g., where the ship moves from a very high Y coordinate to a very low one in a short time) are ruled out.","category":"page"},{"location":"tutorials/smc/#Implementing-a-Basic-Particle-Filter","page":"Object Tracking with SMC","title":"Implementing a Basic Particle Filter","text":"","category":"section"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"In Gen, a particle is represented as a trace and the particle filter state contains a weighted collection of traces. Below we define an inference program that runs a particle filter on an observed data set of bearings (zs). We use num_particles particles internally, and then we return a sample of num_samples traces from the weighted collection that the particle filter produces.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Gen provides methods for initializing and updating the state of a particle filter, documented in Particle Filtering.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Gen.initialize_particle_filter\nGen.particle_filter_step!","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Both of these methods can used either with the default proposal or a custom proposal. In this problem, we will use the default proposal. There is also a method that resamples particles based on their weights, which serves to redistribute the particles to more promising parts of the latent space.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Gen.maybe_resample!","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Gen also provides a method for sampling a collection of unweighted traces from the current weighted collection in the particle filter state:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Gen.sample_unweighted_traces","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function particle_filter(num_particles::Int, zs::Vector{Float64}, num_samples::Int)\n\n    # construct initial observations\n    init_obs = Gen.choicemap((:z0, zs[1]))\n    state = Gen.initialize_particle_filter(model, (0,), init_obs, num_particles)\n\n    # steps\n    for t=1:length(zs)-1\n        Gen.maybe_resample!(state, ess_threshold=num_particles/2)\n        obs = Gen.choicemap(((:z, t), zs[t+1]))\n        Gen.particle_filter_step!(state, (t,), (UnknownChange(),), obs)\n    end\n\n    # return a sample of unweighted traces from the weighted collection\n    return Gen.sample_unweighted_traces(state, num_samples)\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"The initial state is obtained by providing the following to initialize_particle_filter:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"The generative function for the generative model (model)\nThe initial arguments to the generative function.\nThe initial observations, expressed as a map from choice address to values (init_obs).\nThe number of particles.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"At each step, we resample from the collection of traces (maybe_resample!) and then we introduce one additional bearing measurement by calling particle_filter_step! on the state. We pass the following arguments to particle_filter_step!:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"The state (it will be mutated)\nThe new arguments to the generative function for this step. In our case, this is the number of measurements beyond the first measurement.\nThe argdiff value, which provides detailed information about the change to the arguments between the previous step and this step. We will revisit this value later.  For now, we indicate that we do not know how the T::Int argument will change with each step.\nThe new observations associated with the new step. In our case, this just contains the latest measurement.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We run this particle filter with 5000 particles, and return a sample of 200 particles. This will take 30-60 seconds. We will see one way of speeding up the particle filter in a later section.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"@time pf_traces = particle_filter(5000, zs, 200);\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"To render these traces, we first define a function that overlays many renderings:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function overlay(renderer, traces; same_data=true, args...)\n    fig = plot(xlabel=\"X\", ylabel=\"Y\",\n        title=\"Observed bearings (red) and \\npositions of individual traces (one color per trace)\")\n    \n    renderer(traces[1], show_data=true, overlay=true, args...)\n    for i=2:length(traces)\n        renderer(traces[i], show_data=!same_data, overlay=true, args...)\n    end\n    fig\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We then render the traces from the particle filter:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"overlay(render, pf_traces)","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We see a broad posterior; many trajectories (i.e. x- and y-positions) explain the observed bearings.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Notice that as during the period of denser bearing measurements, the trajectories tend to turn so that the heading is more parallel to the bearing vector. An alternative explanation is that the point maintained a constant heading, but just slowed down significantly. It is interesting to see that the inferences favor the \"turning explanation\" over the \"slowing down explanation\".","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"note: Note\nRun the particle filter with fewer particles and visualize the results.Run the particle filter without the maybe_resample! step, and visualize the results.  What do you observe? Why do you think this is? Answer in the free response section below.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"The code for particle_filter (from above) is copied in the body of the function below. Modify it so that it does NOT perform resampling after each time step.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function particle_filter_no_resampling(num_particles::Int, zs::Vector{Float64}, num_samples::Int)\n\n    # construct initial observations\n    init_obs = Gen.choicemap((:z0, zs[1]))\n    state = Gen.initialize_particle_filter(model, (0,), init_obs, num_particles)\n\n    # steps\n    for t=1:length(zs)-1\n        Gen.maybe_resample!(state, ess_threshold=num_particles/2)\n        obs = Gen.choicemap(((:z, t), zs[t+1]))\n        Gen.particle_filter_step!(state, (t,), (UnknownChange(),), obs)\n    end\n\n    # return a sample of unweighted traces from the weighted collection\n    return Gen.sample_unweighted_traces(state, num_samples)\nend\n\n@time pf_traces_no_resampling = particle_filter_no_resampling(5000, zs, 200);\noverlay(render, pf_traces_no_resampling)","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"note: Note\nDescribe how the inference differs with and without resampling (based on the two plots above). Why do you think that is? Is it desirable?","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function particle_filter_no_resampling(num_particles::Int, zs::Vector{Float64}, num_samples::Int)\n\n    # construct initial observations\n    init_obs = Gen.choicemap((:z0, zs[1]))\n    state = Gen.initialize_particle_filter(model, (0,), init_obs, num_particles)\n\n    # steps\n    for t=1:length(zs)-1\n        obs = Gen.choicemap(((:z, t), zs[t+1]))\n        Gen.particle_filter_step!(state, (t,), (UnknownChange(),), obs)\n    end\n\n    # return a sample of unweighted traces from the weighted collection\n    return Gen.sample_unweighted_traces(state, num_samples)\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Without resampling, we get particle collapse, because the model converges on one best guess. This is not desirable; we have lost diversity in our samples.","category":"page"},{"location":"tutorials/smc/#Adding-Rejuvenation-Moves","page":"Object Tracking with SMC","title":"Adding Rejuvenation Moves","text":"","category":"section"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"The particle filter we developed above works as follows:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"At the start, guess many possible initial positions and velocities for the ship.\nScore these proposals based on the initial observation, z0. \nUse maybe_resample! to clone the guesses that explain z0 well, and cull the guesses that explain it poorly.\nFor each data point:\nFor each guess (particle) from the previous time step, guess many possible  extensions of the particle to include values of vx and vy for the next  time step.\nScore these extended proposed particles based on the latest bearing.\nUse maybe_resample! to clone the guesses that explain the z's so far, and cull the guesses that don't.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"A problem with this procedure is that after the initial guesses for a quantity have been made, they are never revised. This is despite the fact that learning about later bearings may tell us a lot about earlier positions. This can be especially problematic in the presence of resampling: notice how, in the above results, the starting locations of all the particles are likely nearly identical, even though the paths become more diverse as time goes on. This is because \"good\" particles at the first step were likely cloned and propagated through the particle filter, never changing the x0 and y0 values.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Therefore, it is sometimes useful to add MCMC moves to particles in a particle filter between steps. These MCMC moves are often called \"rejuvenation moves\" [4].  Each rejuvenation move targets the current posterior distribution at the given step. For example, when applying the rejuvenation move after incorporating 3 observations, our rejuvenation moves have as their stationary distribution the conditional distribution on the latent variables, given the first three observations.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Rejuvenation moves can target any portion of the latent space. It is common for rejuvenation moves to target \"global\" variables that affect every time step (e.g., the initial position of the ship), or a sliding window of recent variables, e.g., the velocities from the previous five time steps. ","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"In this section, we write two new versions of the particle filter, each of which uses Metropolis-Hastings rejuvenation moves to adjust each particle at every time step.  The first version uses so-called \"resimulation MH\" to adjust the initial choices (x0, y0, and the initial velocities). This means that the proposal distribution for MH is equal to the prior of the generative model.  The proposed next state under this rejuvenation move is independent of the current state.  By contrast, the second version we write will use Gaussian drift proposals, and therefore we refer to it as \"random walk MH.\" The Gaussian drift rejuvenation moves will target a sliding window of recent velocities, perturbing them to see if &mdash; in light of new data &mdash; we can find better values for them.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"First, the resimulation MH rejuvenation move (this function is the same as the previous, but with the addition of a rejuvenation move targeting the initial choices of each particle):","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function particle_filter_rejuv_resim(num_particles::Int, zs::Vector{Float64}, num_samples::Int)\n    init_obs = Gen.choicemap((:z0, zs[1]))\n    state = Gen.initialize_particle_filter(model, (0,), init_obs, num_particles)\n    for t=1:length(zs)-1\n\n        # apply a rejuvenation move to each particle\n        for i=1:num_particles\n            initial_choices = select(:x0, :y0, :vx0, :vy0)\n            state.traces[i], _  = mh(state.traces[i], initial_choices)\n        end\n\n        Gen.maybe_resample!(state, ess_threshold=num_particles/2)\n        obs = Gen.choicemap(((:z, t), zs[t+1]))\n        Gen.particle_filter_step!(state, (t,), (UnknownChange(),), obs)\n    end\n\n    # return a sample of unweighted traces from the weighted collection\n    return Gen.sample_unweighted_traces(state, num_samples)\nend\n\n@time pf_rejuv_resim_traces = particle_filter_rejuv_resim(5000, zs, 200);\noverlay(render, pf_rejuv_resim_traces)\ntitle!(\"Rejuvenation with resimulation MH on the starting points\")","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"You may notice slightly more variety in the initial state, compared to our first round of particle filtering.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"note: Note\nWrite a random walk MH rejuvenation move that perturbs the velocity vectors for a block of time steps between a and b inclusive. In this move, draw the perturbation from a normal distribution with standard deviation 1e-3. When sampling a new vx and vy for time step t (where a <= t <= b), make sure you use the right address –- you want to use the same address in your proposal as was used in the model.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"@gen function perturbation_proposal(prev_trace, a::Int, b::Int)\n    choices = get_choices(prev_trace)\n    (T,) = get_args(prev_trace)\n    speed = Array{Float64}(undef, 2, 1)\n    for t=a:b\n        speed[1] = {(:vx, t)} ~ normal(choices[(:vx, t)], 1e-3)\n        speed[2] = {(:vy, t)} ~ normal(choices[(:vy, t)], 1e-3)\n    end\n    return speed\nend\n\nfunction perturbation_move(trace, a::Int, b::Int)\n    Gen.metropolis_hastings(trace, perturbation_proposal, (a, b))\nend; \nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We add this into our particle filtering inference program below. We apply the rejuvenation move to adjust the velocities for the previous 5 time steps.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function particle_filter_rejuv(num_particles::Int, zs::Vector{Float64}, num_samples::Int)\n    init_obs = Gen.choicemap((:z0, zs[1]))    \n    state = Gen.initialize_particle_filter(model, (0,), init_obs, num_particles)\n    for t=1:length(zs)-1\n\n        # apply a rejuvenation move to each particle\n        for i=1:num_particles\n            state.traces[i], _ = perturbation_move(state.traces[i], max(1, t-5), t-1)\n        end\n\n        Gen.maybe_resample!(state, ess_threshold=num_particles/2)\n        obs = Gen.choicemap(((:z, t), zs[t+1]))\n        Gen.particle_filter_step!(state, (t,), (UnknownChange(),), obs)\n    end\n\n    # return a sample of unweighted traces from the weighted collection\n    return Gen.sample_unweighted_traces(state, num_samples)\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We run the particle filter with rejuvenation below. This will take a minute or two. We will see one way of speeding up the particle filter in a later section.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"@time pf_rejuv_traces = particle_filter_rejuv(5000, zs, 200);\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We render the traces:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"overlay(render, pf_rejuv_traces)\ntitle!(\"Rejuvenation with resimulation MH on the starting points\")","category":"page"},{"location":"tutorials/smc/#Speeding-Up-Inference-Using-the-Unfold-Combinator","page":"Object Tracking with SMC","title":"Speeding Up Inference Using the Unfold Combinator","text":"","category":"section"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"For the particle filtering algorithms above, within an update step it is only necessary to revisit the most recent state (or the most recent 5 states if the rejuvenation moves are used) because the initial states are never updated, and the contribution of these states to the weight computation cancel.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"However, each update step of the particle filter inference programs above scales linearly in the size of the trace because it visits every state when computing the weight update. This is because the built-in modeling DSL by default always performs an end-to-end execution of the generative function body whenever performing a trace update. This allows the built-in modeling DSL to be very flexible and to have a simple implementation, at the cost of performance. There are several ways of improving performance after one has a prototype written in the built-in modeling DSL. One of these is Generative Function Combinators, which make  the flow of information through the generative process more explicit to Gen,  and enable asymptotically more efficient inference programs.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"To exploit the opportunity for incremental computation, and improve the scaling behavior of our particle filter inference programs, we will write a new model using a generative function combinator to replaces the following  Julia for loop in our model.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"    # generate successive states and measurements\n    for t=1:T\n\n        # update the state of the point\n        vx = {(:vx, t)} ~ normal(vx, sqrt(velocity_var))\n        vy = {(:vy, t)} ~ normal(vy, sqrt(velocity_var))\n        x += vx\n        y += vy\n\n        # bearing measurement\n        {(:z, t)} ~ normal(bearing(x, y), measurement_noise)\n\n        # record position\n        xs[t+1] = x\n        ys[t+1] = y\n    end","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"This for loop has a very specific pattern of information flow&mdash;there is a sequence of states (represented by x, y, vx, and vy), and each state is generated from the previous state. This is exactly the pattern that the Unfold generative function combinator is designed to handle.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Below, we re-express the Julia for loop over the state sequence using the Unfold combinator. Specifically, we define a generative function (kernel) that takes the prevous state as its second argument, and returns the new state. The Unfold combinator takes the kernel and returns a new generative function (chain) that applies kernel repeatedly. Read the Unfold combinator documentation for details on the behavior of the resulting generative function (chain).","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"struct State\n    x::Float64\n    y::Float64\n    vx::Float64\n    vy::Float64\nend\n\n@gen (static) function kernel(t::Int, prev_state::State,\n                              velocity_var::Float64, measurement_noise::Float64)\n    vx ~ normal(prev_state.vx, sqrt(velocity_var))\n    vy ~ normal(prev_state.vy, sqrt(velocity_var))\n    x = prev_state.x + vx\n    y = prev_state.y + vy\n    z ~ normal(bearing(x, y), measurement_noise)\n    next_state = State(x, y, vx, vy)\n    return next_state\nend\n\nchain = Gen.Unfold(kernel)\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We can understand the behavior of chain by getting a trace of it and printing the random choices:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"trace = Gen.simulate(chain, (4, State(0., 0., 0., 0.), 0.01, 0.01)) Gen.get_choices(trace)","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We now write a new version of the generative model that invokes chain instead of using the Julia for loop:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"@gen (static) function unfold_model(T::Int)\n\n    # parameters\n    measurement_noise = 0.005\n    velocity_var = 1e-6\n\n    # initial conditions\n    x0  ~ normal(0.01, 0.01)\n    y0  ~ normal(0.95, 0.01)\n    vx0 ~ normal(0.002, 0.01)\n    vy0 ~ normal(-0.013, 0.01)\n\n    # initial measurement\n    z0 ~ normal(bearing(x0, y0), measurement_noise)\n\n    # record initial state\n    init_state = State(x0, y0, vx0, vy0)\n\n    # run `chain` function under address namespace `:chain`, producing a vector of states\n    chain ~ chain(T, init_state, velocity_var, measurement_noise)\n\n    result = (init_state, chain)\n    return result\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Let's generate a trace of this new model program to understand its structure:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"(trace, _) = Gen.generate(unfold_model, (4,))\nGen.get_choices(trace)","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We can now run a particle filter on the Unfold model and see a speedup:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"function unfold_particle_filter(num_particles::Int, zs::Vector{Float64}, num_samples::Int)\n    init_obs = Gen.choicemap((:z0, zs[1]))\n    state = Gen.initialize_particle_filter(unfold_model, (0,), init_obs, num_particles)\n    \n    for t=1:length(zs)-1\n        maybe_resample!(state, ess_threshold=num_particles/2)\n        obs = Gen.choicemap((:chain => t => :z, zs[t+1]))\n        Gen.particle_filter_step!(state, (t,), (UnknownChange(),), obs)\n    end\n\n    # return a sample of traces from the weighted collection:\n    return Gen.sample_unweighted_traces(state, num_samples)\nend\n\n@time unfold_pf_traces = unfold_particle_filter(5000, zs, 200);\n\nfunction unfold_render(trace; show_data=true, max_T=get_args(trace)[1], overlay=false)\n    (T,) = Gen.get_args(trace)\n    choices = Gen.get_choices(trace)\n    (init_state, states) = Gen.get_retval(trace)\n    xs = Vector{Float64}(undef, T+1)\n    ys = Vector{Float64}(undef, T+1)\n    zs = Vector{Float64}(undef, T+1)\n    xs[1] = init_state.x\n    ys[1] = init_state.y\n    zs[1] = choices[:z0]\n    for t=1:T\n        xs[t+1] = states[t].x\n        ys[t+1] = states[t].y\n        zs[t+1] = choices[:chain => t => :z]\n    end\n    f = overlay ? scatter! : scatter\n    fig = f(xs[1:max_T+1], ys[1:max_T+1], msize=3, msw=1, label=nothing)\n    if show_data\n        for z in zs[1:max_T+1]\n            dx = cos(z) * 0.5\n            dy = sin(z) * 0.5\n            plot!([0., dx], [0., dy], color=\"red\", alpha=0.3, label=nothing)\n        end\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Let's check that the results are reasonable:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"overlay(unfold_render, unfold_pf_traces, same_data=true)","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We now empirically investigate the scaling behavior of ","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"the inference program that uses the Julia for loop (particle_filter),","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"and ","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"the equivalent inference program that uses Unfold","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"(unfold_particle_filter). ","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"We will use a synthetic long vector of z data, and we will investigate how the running time depends on the number of observations.","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"fake_zs = rand(1000);\n\nfunction timing_experiment(num_observations_list::Vector{Int}, num_particles::Int, num_samples::Int)\n    times = Vector{Float64}()\n    times_unfold = Vector{Float64}()\n    for num_observations in num_observations_list\n        println(\"evaluating inference programs for num_observations: $num_observations\")\n        tstart = time_ns()\n        traces = particle_filter(num_particles, fake_zs[1:num_observations], num_samples)\n        push!(times, (time_ns() - tstart) / 1e9)\n        \n        tstart = time_ns()\n        traces = unfold_particle_filter(num_particles, fake_zs[1:num_observations], num_samples)\n        push!(times_unfold, (time_ns() - tstart) / 1e9)\n        \n    end\n    (times, times_unfold)\nend;\n\nnum_observations_list = [1, 3, 10, 30, 50, 100, 150, 200, 500]\n(times, times_unfold) = timing_experiment(num_observations_list, 100, 20);\nnothing # hide","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"Notice that the running time of the inference program without unfold appears to be quadratic in the number of observations, whereas the inference program that uses unfold appears to scale linearly:","category":"page"},{"location":"tutorials/smc/","page":"Object Tracking with SMC","title":"Object Tracking with SMC","text":"plot(num_observations_list, times, color=\"blue\", \n    xlabel=\"# observations\", ylabel=\"running time (sec.)\", label=\"for loop\")\nplot!(num_observations_list, times_unfold, color=\"red\", label=\"unfold\")","category":"page"},{"location":"ref/inference/wake_sleep/#Wake-Sleep-Learning","page":"Wake-Sleep Learning","title":"Wake-Sleep Learning","text":"","category":"section"},{"location":"ref/inference/wake_sleep/","page":"Wake-Sleep Learning","title":"Wake-Sleep Learning","text":"Wake-sleep learning is algorithm that jointly learns a generative model, represented as a generative function p and an inference model, represented as an inference function q.","category":"page"},{"location":"ref/inference/wake_sleep/","page":"Wake-Sleep Learning","title":"Wake-Sleep Learning","text":"During the wake phase, p is trained on complete traces generated by running q on the observed data, which can be done using the `train! method. During the sleep phase, q is trained on data generated by simulating from p, which can be done using lecture! or lecture_batched!:","category":"page"},{"location":"ref/inference/wake_sleep/#Gen.lecture!","page":"Wake-Sleep Learning","title":"Gen.lecture!","text":"score = lecture!(\n    p::GenerativeFunction, p_args::Tuple,\n    q::GenerativeFunction, get_q_args::Function)\n\nSimulate a trace of p representing a training example, and use to update the gradients of the trainable parameters of q.\n\nUsed for training q via maximum expected conditional likelihood. Random choices will be mapped from p to q based on their address. getqargs maps a trace of p to an argument tuple of q. score is the conditional log likelihood (or an unbiased estimate of a lower bound on it, if not all of q's random choices are constrained, or if q uses non-addressable randomness).\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/wake_sleep/#Gen.lecture_batched!","page":"Wake-Sleep Learning","title":"Gen.lecture_batched!","text":"score = lecture_batched!(\n    p::GenerativeFunction, p_args::Tuple,\n    q::GenerativeFunction, get_q_args::Function)\n\nSimulate a batch of traces of p representing training samples, and use them to update the gradients of the trainable parameters of q.\n\nLike lecture! but q is batched, and must make random choices for training sample i under hierarchical address namespace i::Int (e.g. i => :z). getqargs maps a vector of traces of p to an argument tuple of q.\n\n\n\n\n\n","category":"function"},{"location":"how_to/custom_gradients/#custom_gradients_howto","page":"Custom Gradients","title":"Customizing Gradients","text":"","category":"section"},{"location":"how_to/custom_gradients/#Determistic-Functions-with-Custom-Gradients","page":"Custom Gradients","title":"Determistic Functions with Custom Gradients","text":"","category":"section"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"To add a custom gradient for a differentiable deterministic computation, define a concrete subtype of CustomGradientGF with the following methods:","category":"page"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"apply\ngradient\nhas_argument_grads","category":"page"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"For example, we can implement binary addition with a manually-defined gradient:","category":"page"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"struct MyPlus <: CustomGradientGF{Float64} end\n\nGen.apply(::MyPlus, args) = args[1] + args[2]\nGen.gradient(::MyPlus, args, retval, retgrad) = (retgrad, retgrad)\nGen.has_argument_grads(::MyPlus) = (true, true)","category":"page"},{"location":"how_to/custom_gradients/#Customizing-Parameter-Updates","page":"Custom Gradients","title":"Customizing Parameter Updates","text":"","category":"section"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"To add support for a new type of gradient-based parameter update, create a new parameter update configuration with the following methods defined for the types of generative functions that are to be supported.","category":"page"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"Gen.init_update_state\nGen.apply_update!","category":"page"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"As an example, the built-in update configuration, FixedStepGradientDescent, is implemented as follows:","category":"page"},{"location":"how_to/custom_gradients/","page":"Custom Gradients","title":"Custom Gradients","text":"struct FixedStepGradientDescent\n    step_size::Float64\nend\n\nmutable struct FixedStepGradientDescentBuiltinDSLState\n    step_size::Float64\n    gen_fn::Union{Gen.DynamicDSLFunction,Gen.StaticIRGenerativeFunction}\n    param_list::Vector\nend\n\nfunction Gen.init_update_state(conf::FixedStepGradientDescent,\n        gen_fn::Union{Gen.DynamicDSLFunction,Gen.StaticIRGenerativeFunction}, param_list::Vector)\n    FixedStepGradientDescentBuiltinDSLState(conf.step_size, gen_fn, param_list)\nend\n\nfunction Gen.apply_update!(state::FixedStepGradientDescentBuiltinDSLState)\n    for param_name in state.param_list\n        value = Gen.get_param(state.gen_fn, param_name)\n        grad = Gen.get_param_grad(state.gen_fn, param_name)\n        Gen.set_param!(state.gen_fn, param_name, value + grad * state.step_size)\n        Gen.zero_param_grad!(state.gen_fn, param_name)\n    end\nend","category":"page"},{"location":"how_to/extending_gen/#extending_gen_howto","page":"Extending Gen","title":"Extending Gen","text":"","category":"section"},{"location":"how_to/extending_gen/","page":"Extending Gen","title":"Extending Gen","text":"Gen is designed for extensibility. To implement behaviors that are not directly supported by the existing modeling languages, users can implement `black-box' generative functions that directly implement the generative function interface. These generative functions can then be invoked by generative functions defined using the built-in modeling language.","category":"page"},{"location":"how_to/extending_gen/","page":"Extending Gen","title":"Extending Gen","text":"The following how-tos describe various ways of extending Gen:","category":"page"},{"location":"how_to/extending_gen/","page":"Extending Gen","title":"Extending Gen","text":"Adding custom distributions\nCustom incremental computation of return values\nCustom gradient computations\nImplementing custom generative functions from scratch","category":"page"},{"location":"how_to/extending_gen/","page":"Extending Gen","title":"Extending Gen","text":"Gen can also be extended with entirely new modeling languages by implementing new generative function types, and constructors for these types that take models as input. This typically requires implementing the entire generative function interface, and is advanced usage of Gen.","category":"page"},{"location":"how_to/custom_incremental_computation/#custom_incremental_computation_howto","page":"Custom Incremental Computation","title":"Customizing Incremental Computation","text":"","category":"section"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"Iterative inference techniques like Markov Chain Monte Carlo and Sequential Monte Carlo involve repeatedly updating the execution traces of generative models.","category":"page"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"In some cases, the output of a deterministic computation within the model can be incrementally computed during each of these updates, instead of being computed from scratch.","category":"page"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"To add a custom incremental computation for a deterministic computation, define a concrete subtype of CustomUpdateGF with the following methods:","category":"page"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"apply_with_state\nupdate_with_state\nhas_argument_grads","category":"page"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"The second type parameter of CustomUpdateGF is the type of the state that may be used internally to facilitate incremental computation within update_with_state.","category":"page"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"For example, we can implement a function for computing the sum of a vector that efficiently computes the new sum when a small fraction of the vector elements change:","category":"page"},{"location":"how_to/custom_incremental_computation/","page":"Custom Incremental Computation","title":"Custom Incremental Computation","text":"struct MyState\n    prev_arr::Vector{Float64}\n    sum::Float64\nend\n\nstruct MySum <: CustomUpdateGF{Float64,MyState} end\n\nfunction Gen.apply_with_state(::MySum, args)\n    arr = args[1]\n    s = sum(arr)\n    state = MyState(arr, s)\n    (s, state)\nend\n\nfunction Gen.update_with_state(::MySum, state, args, argdiffs::Tuple{VectorDiff})\n    arr = args[1]\n    prev_sum = state.sum\n    retval = prev_sum\n    for i in keys(argdiffs[1].updated)\n        retval += (arr[i] - state.prev_arr[i])\n    end\n    prev_length = length(state.prev_arr)\n    new_length = length(arr)\n    for i=prev_length+1:new_length\n        retval += arr[i]\n    end\n    for i=new_length+1:prev_length\n        retval -= arr[i]\n    end\n    state = MyState(arr, retval)\n    (state, retval, UnknownChange())\nend\n\nGen.num_args(::MySum) = 1","category":"page"},{"location":"tutorials/scaling_with_sml/#scaling_with_sml_tutorial","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the Static Modeling Language","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/#Introduction","page":"Speeding Up Inference with the SML","title":"Introduction","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"For prototyping models and working with dynamic structures, Gen's Dynamic Modeling Language is a great (and the default) way of writing probabilistic programs in nearly pure Julia. However, better performance and scaling characteristics can be obtained using specialized modeling languages or modeling constructs. This tutorial introduces a more specialized modeling language known as the Static Modeling Language (SML) which is also built into Gen. The SML provides model speedups by carefully analyzing what work is necessary during inference.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"This tutorial will take a robust regression model with outliers and optimize the speed of inference using the SML.","category":"page"},{"location":"tutorials/scaling_with_sml/#A-Slow-Inference-Program","page":"Speeding Up Inference with the SML","title":"A Slow Inference Program","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"using Gen\nusing Plots\n\n@gen function model(xs::Vector{Float64})\n    slope ~ normal(0, 2)\n    intercept ~ normal(0, 2)\n    noise ~ gamma(1, 1)\n    prob_outlier ~ uniform(0, 1)\n    \n    n = length(xs)\n    ys = Vector{Float64}(undef, n)\n    \n    for i = 1:n\n        if ({:data => i => :is_outlier} ~ bernoulli(prob_outlier))\n            (mu, std) = (0., 10.)\n        else\n            (mu, std) = (xs[i] * slope + intercept, noise)\n        end\n        ys[i] = {:data => i => :y} ~ normal(mu, std)\n    end\n    ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We wrote a Markov chain Monte Carlo inference update for this model that performs updates on each of the 'global' parameters (noise, slope, intercept, and proboutlier), as well as the 'local' `isoutlier` variable associated with each data point. The update takes a trace as input, and returns the new trace as output. We reproduce this here:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"function block_resimulation_update(tr)\n    \n    # Block 1: Update the line's parameters\n    line_params = select(:noise, :slope, :intercept)\n    (tr, _) = mh(tr, line_params)\n    \n    # Blocks 2-N+1: Update the outlier classifications\n    (xs,) = get_args(tr)\n    n = length(xs)\n    for i=1:n\n        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n    end\n    \n    # Block N+2: Update the prob_outlier parameter\n    (tr, _) = mh(tr, select(:prob_outlier))\n    \n    # Return the updated trace\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We write a helper function that takes a vector of y-coordinates and populates a constraints choice map:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"function make_constraints(ys::Vector{Float64})\n    constraints = choicemap()\n    for i=1:length(ys)\n        constraints[:data => i => :y] = ys[i]\n    end\n    constraints\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Finally, we package this into an inference program that takes the data set of all x- and y-coordinates ,and returns a trace. We will be experimenting with different variants of the model, so we make the model an argument to this function:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"function block_resimulation_inference(model, xs, ys)\n    observations = make_constraints(ys)\n    (tr, _) = generate(model, (xs,), observations)\n    for iter=1:500\n        tr = block_resimulation_update(tr)\n    end\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Let's see how the running time of this inference program changes as we increase the number of data points. We don't expect the running time to depend too much on the actual values of the data points, so we just construct a random data set for each run:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"ns = [1, 3, 7, 10, 30, 70, 100]\ntimes = []\nlet # hide\nfor n in ns\n    xs = rand(n)\n    ys = rand(n)\n    start = time_ns()\n    tr = block_resimulation_inference(model, xs, ys)\n    push!(times, (time_ns() - start) / 1e9)\nend\nend # hide\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We now plot the running time versus the number of data points:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"plot(ns, times, xlabel=\"number of data points\", ylabel=\"running time (seconds)\", label=nothing)","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"The inference program seems to scale quadratically in the number of data points.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"To understand why, consider the block of code inside block_resimulation_update that loops over the data points:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"# Blocks 2-N+1: Update the outlier classifications\n(xs,) = get_args(tr)\nn = length(xs)\nfor i=1:n\n    (tr, _) = mh(tr, select(:data => i => :is_outlier))\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"The reason for the quadratic scaling is that the running time of the call to mh inside this loop also grows in proportion to the number of data points. This is because the updates to a trace of a model written the generic built-in modeling language always involve re-running the entire model generative function.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"However, it should be possible for the algorithm to scale linearly in the number of data points. Briefly, deciding whether to update a given is_outlier variable can be done without referencing the other data points. This is because each is_outiler variable is conditionally independent of the outlier variables and y-coordinates of the other data points, conditioned on the parameters.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We can make this conditional independence structure explicit using the Map generative function combinator. Combinators like map encapsulate common modeling patterns (e.g., a loop in which each iteration is making independent choices), and when you use them, Gen can take advantage of the restrictions they enforce to implement performance optimizations automatically during inference. The Map combinator, like the map function in a functional programming language, helps to execute the same generative code repeatedly. ","category":"page"},{"location":"tutorials/scaling_with_sml/#Rewriting-the-Program-with-Combinators","page":"Speeding Up Inference with the SML","title":"Rewriting the Program with Combinators","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"To use the map combinator to express the conditional independences in our model, we first write a generative function to generate the is_outlier variable and the y-coordinate for a single data point:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"@gen function generate_single_point(x::Float64, prob_outlier::Float64, noise::Float64,\n                                    slope::Float64, intercept::Float64)\n    is_outlier ~ bernoulli(prob_outlier)\n    mu  = is_outlier ? 0. : x * slope + intercept\n    std = is_outlier ? 10. : noise\n    y ~ normal(mu, std)\n    return y\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We then apply the Map, which is a Julia function, to this generative function, to obtain a new generative function:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"generate_all_points = Map(generate_single_point)\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"This new generative function has one argument for each argument of generate_single_point, except that these arguments are now vector-valued instead of scalar-valued. We can run the generative function on some fake data to test this:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"xs = Float64[0, 1, 2, 3, 4]\nprob_outliers = fill(0.5, 5)\nnoises = fill(0.2, 5)\nslopes = fill(0.7, 5)\nintercepts = fill(-2.0, 5)\ntrace = simulate(generate_all_points, (xs, prob_outliers, noises, slopes, intercepts));\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We see that the generate_all_points function has traced 5 calls to generate_single_point, under namespaces 1 through 5.  The Map combinator automatically adds these indices to the trace address.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"get_choices(trace)","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Now, let's replace the Julia for loop in our model with a call to this new function:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"@gen function model_with_map(xs::Vector{Float64})\n    slope ~ normal(0, 2)\n    intercept ~ normal(0, 2)\n    noise ~ gamma(1, 1)\n    prob_outlier ~ uniform(0, 1)\n    n = length(xs)\n    data ~ generate_all_points(xs, fill(prob_outlier, n), fill(noise, n), fill(slope, n), fill(intercept, n))\n    return data\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Note that this new model has the same address structure as our original model had, so our inference code will not need to change. For example, the 5th data point's y coordinate will be stored at the address :data => 5 => :y, just as before. (The :data comes from our data ~ ... invocation in the better_model definition, and the :y comes from generate_point; only the 5 has been inserted automatically by Map.)","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"trace = simulate(model_with_map, (xs,));\nget_choices(trace)","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Let's test the running time of the inference program, applied to this new model:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"with_map_times = []\nfor n in ns\n    xs = rand(n)\n    ys = rand(n)\n    start = time_ns()\n    tr = block_resimulation_inference(model_with_map, xs, ys)\n    push!(with_map_times, (time_ns() - start) / 1e9)\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We plot the results and compare them to the original model, which used the Julia for loop:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"plot(ns, times, label=\"original\", xlabel=\"number of data points\", ylabel=\"running time (seconds)\")\nplot!(ns, with_map_times, label=\"with map\")","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We see that the quadratic scaling did not improve. We can understand why we still have quadratic scaling, by examining the call to generate_single_point:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"data ~ generate_all_points(xs, fill(prob_outlier, n), fill(noise, n), fill(slope, n), fill(intercept, n))","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Even though the function generate_all_points knows that each of the calls to generate_single_point is conditionally independent, and even it knows that each update to is_outlier only involves a single application of generate_single_point, it does not know that none of its arguments change within an update to is_outlier. Therefore, it needs to visit each call to generate_single_point. The generic built-in modeling language does not provide this information the generative functions that it invokes.","category":"page"},{"location":"tutorials/scaling_with_sml/#Rewriting-in-the-Static-Modeling-Language","page":"Speeding Up Inference with the SML","title":"Rewriting in the Static Modeling Language","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"In order to provide generate_all_points with the knowledge that its arguments do not change during an update to the is_outlier variable, we need to write the top-level model generative function that calls generate_all_points in the Static Modeling Language, which is a restricted variant of the built-in modeling language that uses static analysis of the computation graph to generate specialized trace data structures and specialized implementations of trace operations. We indicate that a function is to be interpreted using the static language using the static annotation:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"@gen (static) function static_model_with_map(xs::Vector{Float64})\n    slope ~ normal(0, 2)\n    intercept ~ normal(0, 2)\n    noise ~ gamma(1, 1)\n    prob_outlier ~ uniform(0, 1)\n    n = length(xs)\n    data ~ generate_all_points(xs, fill(prob_outlier, n), fill(noise, n), fill(slope, n), fill(intercept, n))\n    return data\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"The static language has a number of restrictions that make it more amenable to static analysis than the unrestricted modeling language. For example, we cannot use Julia for loops, and the return value needs to explicitly use the return keyword, followed by a symbol (e.g. data). Also, each symbol used on the left-hand side of an assignment must be unique. A more complete list of restrictions is given in the documentation.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Below, we show the static dependency graph that Gen builds for this function. Arguments are shown as diamonds, Julia computations are shown as squares, random choices are shown as circles, and calls to other generative function are shown as stars. The call that produces the return value of the function is shaded in blue.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"<div style=\"text-align:center\">\n    <img src=\"../../assets/scaling_with_sml_graph.png\" alt=\"static dependency graph\" width=\"100%\"/>\n</div>","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Now, consider the update to the is_outlier variable:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"(tr, _) = mh(tr, select(:data => i => :is_outlier))","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Because this update only causes values under address :data to change, the static_model_with_map function can use the graph above to infer that none of the arguments to generate_all_point could have possibly changed. This will allow us to obtain the linear scaling we expected.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Now we can re-run the experiment with our model that combines the map combinator with the static language:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"static_with_map_times = []\nfor n in ns\n    xs = rand(n)\n    ys = rand(n)\n    start = time_ns()\n    tr = block_resimulation_inference(static_model_with_map, xs, ys)\n    push!(static_with_map_times, (time_ns() - start) / 1e9)\nend\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We compare the results to the results for the earlier models:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"plot(ns, times, label=\"original\", xlabel=\"number of data points\", ylabel=\"running time (seconds)\")\nplot!(ns, with_map_times, label=\"with map\")\nplot!(ns, static_with_map_times, label=\"with map and static outer fn\")","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We see that we now have the linear running time that we expected.","category":"page"},{"location":"tutorials/scaling_with_sml/#Benchmarking-the-Performance-Gain","page":"Speeding Up Inference with the SML","title":"Benchmarking the Performance Gain","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Note: the following section was drafted using an earlier version of Julia. As of Julia 1.7, the dynamic modeling language is fast enough in some cases that you may not see constant-factor performance gains by switching simple dynamic models, with few choices and no control flow, to use the static modeling language. Based on the experiment below, this model falls into that category.","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Note that in our latest model above, generate_single_point was still written in the dynamic modeling language. It is not necessary to write generate_single_point in the static language, but doing so might provide modest constant-factor performance improvements. Here we rewrite this function in the static language. The static modeling language does not support if statements, but does support ternary expressions (a ? b : c):","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"@gen (static) function static_generate_single_point(x::Float64, prob_outlier::Float64, noise::Float64,\n                                    slope::Float64, intercept::Float64)\n    is_outlier ~ bernoulli(prob_outlier)\n    mu = is_outlier ? 0. : x * slope + intercept\n    std = is_outlier ? 10. : noise\n    y ~ normal(mu, std)\n    return y\nend;\n\nstatic_generate_all_points = Map(static_generate_single_point);\n\n@gen (static) function fully_static_model_with_map(xs::Vector{Float64})\n    slope ~ normal(0, 2)\n    intercept ~ normal(0, 2)\n    noise ~ gamma(1, 1)\n    prob_outlier ~ uniform(0, 1)\n    n = length(xs)\n    data ~ static_generate_all_points(xs, fill(prob_outlier, n), fill(noise, n), fill(slope, n), fill(intercept, n))\n    return data\nend;\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Now, we re-run the experiment with our new model:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"fully_static_with_map_times = []\nlet # end\nfor n in ns\n    xs = rand(n)\n    ys = rand(n)\n    start = time_ns()\n    tr = block_resimulation_inference(fully_static_model_with_map, xs, ys)\n    push!(fully_static_with_map_times, (time_ns() - start) / 1e9)\nend\nend # hide\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"In earlier versions of Julia, we saw a modest improvement in running time, but here we see it makes little to no difference:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"plot(ns, times, label=\"original\", xlabel=\"number of data points\", ylabel=\"running time (seconds)\")\nplot!(ns, with_map_times, label=\"with map\")\nplot!(ns, static_with_map_times, label=\"with map and static outer fn\")\nplot!(ns, fully_static_with_map_times, label=\"with map and static outer and inner fns\")","category":"page"},{"location":"tutorials/scaling_with_sml/#Checking-the-Inference-Programs","page":"Speeding Up Inference with the SML","title":"Checking the Inference Programs","text":"","category":"section"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Before wrapping up, let's confirm that all of our models are giving good results:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Let's use a synthetic data set:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"true_inlier_noise = 0.5\ntrue_outlier_noise = 10.\nprob_outlier = 0.1\ntrue_slope = -1\ntrue_intercept = 2\nxs = collect(range(-5, stop=5, length=50))\nys = Float64[]\nfor (i, x) in enumerate(xs)\n    if rand() < prob_outlier\n        y = 0. + randn() * true_outlier_noise\n    else\n        y = true_slope * x + true_intercept + randn() * true_inlier_noise \n    end\n    push!(ys, y)\nend\nys[end-3] = 14\nys[end-5] = 13;\n\nscatter(xs, ys, xlim=(-7,7), ylim=(-7,15), label=nothing)","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"We write a trace rendering function that shows the inferred line on top of the observed data set:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"function render_trace(trace, title)\n    xs,  = get_args(trace)\n    xlim = [-5, 5]\n    slope = trace[:slope]\n    intercept = trace[:intercept]\n    plot(xlim, slope * xlim .+ intercept, color=\"black\", xlim=(-7,7), ylim=(-7,15), title=title, label=nothing)\n    ys = [trace[:data => i => :y] for i=1:length(xs)]\n    scatter!(xs, ys, label=nothing)\nend;\nnothing # hide","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"Finally, we run the experiment. We will visualize just one trace produced by applying our inference program to each of the four variants of our model:","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"tr = block_resimulation_inference(model, xs, ys)\nfig1 = render_trace(tr, \"model\")\n\ntr = block_resimulation_inference(model_with_map, xs, ys)\nfig2 = render_trace(tr, \"model with map\")\n\ntr = block_resimulation_inference(static_model_with_map, xs, ys)\nfig3 = render_trace(tr, \"static model with map\")\n\ntr = block_resimulation_inference(fully_static_model_with_map, xs, ys)\nfig4 = render_trace(tr, \"fully static model with map\")\n\nplot(fig1, fig2, fig3, fig4)","category":"page"},{"location":"tutorials/scaling_with_sml/","page":"Speeding Up Inference with the SML","title":"Speeding Up Inference with the SML","text":"It looks like inference in all the models seems to be working reasonably.","category":"page"},{"location":"ref/inference/pf/#particle_filtering","page":"Particle Filtering & SMC","title":"Particle Filtering and Sequential Monte Carlo","text":"","category":"section"},{"location":"ref/inference/pf/","page":"Particle Filtering & SMC","title":"Particle Filtering & SMC","text":"Gen.jl provides support for Sequential Monte Carlo (SMC) inference in the form of particle filtering. The state of a particle filter is a represented as a ParticleFilterState object.","category":"page"},{"location":"ref/inference/pf/#Gen.ParticleFilterState","page":"Particle Filtering & SMC","title":"Gen.ParticleFilterState","text":"ParticleFilterState{U}\n\nRepresents the state of a particle filter as a collection of weighted traces, where the type of each trace is U.\n\nFields\n\ntraces: A vector of traces, one for each particle.\nnew_traces: A preallocated vector for storing new traces.\nlog_weights: A vector of log importance weights for each trace.\nlog_ml_est: Estimate of the log marginal likelihood before the last resampling step.\nparents: The parent indices of each trace in traces.\n\nnote: Note\nThe fields above are an implementation detail that are subject to future changes.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/pf/#Particle-Filtering-Steps","page":"Particle Filtering & SMC","title":"Particle Filtering Steps","text":"","category":"section"},{"location":"ref/inference/pf/","page":"Particle Filtering & SMC","title":"Particle Filtering & SMC","text":"The basic steps of particle filtering are initialization (via initialize_particle_filter), updating (via particle_filter_step!), and resampling (via maybe_resample!). The latter two operations are applied to a ParticleFilterState, modifying it in place.","category":"page"},{"location":"ref/inference/pf/#Gen.initialize_particle_filter","page":"Particle Filtering & SMC","title":"Gen.initialize_particle_filter","text":"state = initialize_particle_filter(model::GenerativeFunction, model_args::Tuple,\n    observations::ChoiceMap, proposal::GenerativeFunction, proposal_args::Tuple,\n    num_particles::Int)\n\nInitialize the state of a particle filter using a custom proposal for the initial latent state.\n\n\n\n\n\nstate = initialize_particle_filter(model::GenerativeFunction, model_args::Tuple,\n    observations::ChoiceMap, num_particles::Int)\n\nInitialize the state of a particle filter, using the default proposal for the initial latent state.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#Gen.particle_filter_step!","page":"Particle Filtering & SMC","title":"Gen.particle_filter_step!","text":"(log_incremental_weights,) = particle_filter_step!(\n    state::ParticleFilterState, new_args::Tuple, argdiffs,\n    observations::ChoiceMap, proposal::GenerativeFunction, proposal_args::Tuple)\n\nPerform a particle filter update, where the model arguments are adjusted, new observations are added, and some combination of a custom proposal and the model's internal proposal is used for proposing new latent state.  That is, for each particle,\n\nThe proposal function proposal is evaluated with arguments Tuple(t_old, proposal_args...) (where t_old is the old model trace), and produces its own trace (call it proposal_trace); and\nThe old model trace is replaced by a new model trace (call it t_new).\n\nThe choicemap of t_new satisfies the following conditions:\n\nget_choices(t_old) is a subset of get_choices(t_new);\nobservations is a subset of get_choices(t_new);\nget_choices(proposal_trace) is a subset of get_choices(t_new).\n\nHere, when we say one choicemap a is a \"subset\" of another choicemap b, we mean that all keys that occur in a also occur in b, and the values at those addresses are equal.\n\nIt is an error if no trace t_new satisfying the above conditions exists in the support of the model (with the new arguments). If such a trace exists, then the random choices not determined by the above requirements are sampled using the internal proposal.\n\n\n\n\n\n(log_incremental_weights,) = particle_filter_step!(\n    state::ParticleFilterState, new_args::Tuple, argdiffs,\n    observations::ChoiceMap)\n\nPerform a particle filter update, where the model arguments are adjusted, new observations are added, and the default proposal is used for new latent state.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#Gen.maybe_resample!","page":"Particle Filtering & SMC","title":"Gen.maybe_resample!","text":"did_resample::Bool = maybe_resample!(state::ParticleFilterState;\n    ess_threshold::Float64=length(state.traces)/2, verbose=false)\n\nDo a resampling step if the effective sample size is below the given threshold. Return true if a resample thus occurred, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#Accessors","page":"Particle Filtering & SMC","title":"Accessors","text":"","category":"section"},{"location":"ref/inference/pf/","page":"Particle Filtering & SMC","title":"Particle Filtering & SMC","text":"The following accessor functions can be used to return information about a ParticleFilterState, or to sample traces from the distribution that the particle filter approximates.","category":"page"},{"location":"ref/inference/pf/#Gen.log_ml_estimate","page":"Particle Filtering & SMC","title":"Gen.log_ml_estimate","text":"estimate = log_ml_estimate(state::ParticleFilterState)\n\nReturn the particle filter's current estimate of the log marginal likelihood.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#Gen.get_traces","page":"Particle Filtering & SMC","title":"Gen.get_traces","text":"traces = get_traces(state::ParticleFilterState)\n\nReturn the vector of traces in the current state, one for each particle.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#Gen.get_log_weights","page":"Particle Filtering & SMC","title":"Gen.get_log_weights","text":"log_weights = get_log_weights(state::ParticleFilterState)\n\nReturn the vector of log weights for the current state, one for each particle.\n\nThe weights are not normalized, and are in log-space.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#Gen.sample_unweighted_traces","page":"Particle Filtering & SMC","title":"Gen.sample_unweighted_traces","text":"traces::Vector = sample_unweighted_traces(state::ParticleFilterState, num_samples::Int)\n\nSample a vector of num_samples traces from the weighted collection of traces in the given particle filter state.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/pf/#advanced-particle-filtering","page":"Particle Filtering & SMC","title":"Advanced Particle Filtering","text":"","category":"section"},{"location":"ref/inference/pf/","page":"Particle Filtering & SMC","title":"Particle Filtering & SMC","text":"For a richer set of particle filtering techniques, including support for stratified sampling, multiple resampling methods, MCMC rejuvenation moves, particle filter resizing, users are recommended to use the GenParticleFilters.jl extension library.","category":"page"},{"location":"ref/inference/pf/","page":"Particle Filtering & SMC","title":"Particle Filtering & SMC","text":"To use the generalization of standard SMC known as Sequential Monte Carlo with Probabilistic Program Proposals (SMCP³), use the API provided by GenSMCP3.jl, or implement an UpdatingTraceTranslator in GenParticleFilters.jl.","category":"page"},{"location":"ref/inference/pf/","page":"Particle Filtering & SMC","title":"Particle Filtering & SMC","text":"Even more advanced SMC techniques (such as divide-and-conquer SMC) are not currently supported by Gen.","category":"page"},{"location":"ref/modeling/dml/#dml","page":"Built-In Modeling Language","title":"Built-in Modeling Language","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Gen provides a built-in modeling language for defining generative functions, using a syntax that extends Julia's syntax for defining regular Julia functions. This language is also referred to as the Dynamic Modeling Language (DML).","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Generative functions in this modeling language are identified using the @gen keyword in front of a Julia function definition. Here is an example @gen function that samples two random choices:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo(prob::Float64=0.1)\n    z1 = @trace(bernoulli(prob), :a)\n    z2 = @trace(bernoulli(prob), :b)\n    return z1 || z2\nend","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"After running this code, foo is a Julia value of type DynamicDSLFunction:","category":"page"},{"location":"ref/modeling/dml/#Gen.DynamicDSLFunction","page":"Built-In Modeling Language","title":"Gen.DynamicDSLFunction","text":"DynamicDSLFunction{T} <: GenerativeFunction{T,DynamicDSLTrace}\n\nA generative function based on a shallowly embedding modeling language based on Julia functions.\n\nConstructed using the @gen keyword. Most methods in the generative function interface involve a end-to-end execution of the function.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Note that it is possible to provide default values for trailing positional arguments. However, keyword arguments are currently not supported.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"We can call the resulting generative function like we would a regular Julia function:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"retval::Bool = foo(0.5)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"We can also trace its execution:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"(trace, _) = generate(foo, (0.5,))","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Optional arguments can be left out of the above operations, and default values will be filled in automatically:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"julia> (trace, _) = generate(foo, ())\njulia> get_args(trace)\n(0.1,)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"See Generative Functions for the full set of operations supported by a generative function. Note that the built-in modeling language described in this section is only one of many ways of defining a generative function – generative functions can also be constructed using other embedded languages, or by directly implementing the methods of the generative function interface. However, the built-in modeling language is intended to being flexible enough cover a wide range of use cases. In the remainder of this section, we refer to generative functions defined using the built-in modeling language as @gen functions. Details about the implementation of @gen functions can be found in the Modeling Language Implementation section.","category":"page"},{"location":"ref/modeling/dml/#Annotations","page":"Built-In Modeling Language","title":"Annotations","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Annotations are a syntactic construct in the built-in modeling language that allows users to provide additional information about how @gen functions should be interpreted. Annotations are optional, and not necessary to understand the basics of Gen. There are two types of annotations – argument annotations and function annotations.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Argument annotations. In addition to type declarations on arguments like regular Julia functions, @gen functions also support additional annotations on arguments. Each argument can have the following different syntactic forms:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"y: No type declaration; no annotations.\ny::Float64: Type declaration; but no annotations.\n(grad)(y): No type declaration provided;, annotated with grad.\n(grad)(y::Float64): Type declaration provided; and annotated with grad.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Currently, the possible argument annotations are:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"grad (see Differentiable programming).","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Function annotations. The @gen function itself can also be optionally associated with zero or more annotations, which are separate from the per-argument annotations. Function-level annotations use the following different syntactic forms:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo(<args>) <body> end: No function annotations.\n@gen (grad) function foo(<args>) <body> end: The function has the grad annotation.\n@gen (grad,static) function foo(<args>) <body> end: The function has both the grad and static annotations.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Currently the possible function annotations are:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"grad (see Differentiable programming).\nstatic (see Static Modeling Language).\nnojuliacache (see Static Modeling Language).","category":"page"},{"location":"ref/modeling/dml/#Making-random-choices","page":"Built-In Modeling Language","title":"Making random choices","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Random choices are made by calling a probability distribution on some arguments:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"val::Bool = bernoulli(0.5)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"See Probability Distributions for the set of built-in probability distributions, and for information on implementing new probability distributions.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"In the body of a @gen function, wrapping a call to a random choice with an @trace expression associates the random choice with an address, and evaluates to the value of the random choice. The syntax is:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(<distribution>(<args>), <addr>)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Addresses can be any Julia value. Here, we give the Julia symbol address :z to a Bernoulli random choice.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"val::Bool = @trace(bernoulli(0.5), :z)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Not all random choices need to be given addresses. An address is required if the random choice will be observed, or will be referenced by a custom inference algorithm (e.g. if it will be proposed to by a custom proposal distribution).","category":"page"},{"location":"ref/modeling/dml/#Sample-space-and-support-of-random-choices","page":"Built-In Modeling Language","title":"Sample space and support of random choices","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Different probability distributions produce different types of values for their random choices. For example, the bernoulli distribution results in Bool values (either true or false), the normal distribution results in Real values that may be positive or negative, and the beta distribution result in Real values that are always in the unit interval (0, 1).","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Each Distribution is associated with two sets of values:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"The sample space of the distribution, which does not depend on the arguments.\nThe support of the distribution, which may depend on the arguments, and is the set of values that has nonzero probability (or probability density). It may be the entire sample space, or it may be a subset of the sample space.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"For example, the sample space of bernoulli is Bool and its support is either {true}, {false}, or {true, false}. The sample space of normal is Real and its support is the set of all values on the real line. The sample space of beta is Real and its support is the set of values in the interval (0, 1).","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Gen's built in modeling languages require that a address is associated with a fixed sample space. For example, it is not permitted to use a bernoulli distribution to sample at addresss :a in one execution, and a normal distribution to sample at address :a in a different execution, because their sample spaces differ (Bool vs Real):","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo()\n    if @trace(bernoulli(0.5), :branch)\n        @trace(bernoulli(0.5), :x)\n    else\n        @trace(normal(0, 1), :x)\n    end\nend","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"A generative function can be disciplined or not. In a disciplined generative function, the support of random choices at each address must be fixed. That is, for each address a there must exist a set S that is a subset of the sample space such that for all executions of the generative function, if a occurs as the address of a choice in the execution, then the support of that choice is exactly S. Violating this discipline will cause NaNs, errors, or undefined behavior in some inference programs. However, in many cases it is convenient to write an inference program that operates correctly and efficiently on some specialized class of undisciplined models. In these cases, authors who want their inference code to be reusable should consider documenting which kinds of undisciplined models their inference algorithms allow or expect to see.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"If the support of a random choice needs to change, a disciplined generative function can represent this by using a different address for each distinct value of the support. For example, consider the following generative function:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo()\n    n = @trace(categorical([0.5, 0.5]), :n) + 1\n    @trace(categorical(ones(n) / n), :x)\nend","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"The support of the random choice with address :x is either the set 1 2 or 1 2 3. Therefore, this random choice does not have constant support, and the generative function foo is not 'disciplined'. Specifically, this could result in undefined behavior for the following inference program:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"tr, _ = importance_resampling(foo, (), choicemap((:x, 3)))","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"It is recommended to write disciplined generative functions when possible.","category":"page"},{"location":"ref/modeling/dml/#Calling-generative-functions","page":"Built-In Modeling Language","title":"Calling generative functions","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen functions can invoke other generative functions in three ways:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Untraced call: If foo is a generative function, we can invoke foo from within the body of a @gen function using regular call syntax. The random choices made within the call are not given addresses in our trace, and are therefore untraced random choices (see Generative Function Interface for details on untraced random choices).","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"val = foo(0.5)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Traced call with a nested address namespace: We can include the traced random choices made by foo in the caller's trace, under a namespace, using @trace:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"val = @trace(foo(0.5), :x)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Now, all random choices made by foo are included in our trace, under the namespace :x. For example, if foo makes random choices at addresses :a and :b, these choices will have addresses :x => :a and :x => :b in the caller's trace.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Traced call with shared address namespace: We can include the traced random choices made by foo in the caller's trace using @trace:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"val = @trace(foo(0.5))","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Now, all random choices made by foo are included in our trace. The caller must guarantee that there are no address collisions. NOTE: This type of call can only be used when calling other @gen functions. Other types of generative functions cannot be called in this way.","category":"page"},{"location":"ref/modeling/dml/#Composite-addresses","page":"Built-In Modeling Language","title":"Composite addresses","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"In Julia, Pair values can be constructed using the => operator. For example, :a => :b is equivalent to Pair(:a, :b) and :a => :b => :c is equivalent to Pair(:a, Pair(:b, :c)). A Pair value (e.g. :a => :b => :c) can be passed as the address field in an @trace expression, provided that there is not also a random choice or generative function called with @trace at any prefix of the address.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Consider the following examples.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"This example is invalid because :a => :b is a prefix of :a => :b => :c:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :a => :b => :c)\n@trace(normal(0, 1), :a => :b)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"This example is invalid because :a is a prefix of :a => :b => :c:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :a => :b => :c)\n@trace(normal(0, 1), :a)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"This example is invalid because :a => :b is a prefix of :a => :b => :c:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :a => :b => :c)\n@trace(foo(0.5), :a => :b)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"This example is invalid because :a is a prefix of :a => :b:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :a)\n@trace(foo(0.5), :a => :b)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"This example is valid because :a => :b and :a => :c are not prefixes of one another:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :a => :b)\n@trace(normal(0, 1), :a => :c)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"This example is valid because :a => :b and :a => :c are not prefixes of one another:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :a => :b)\n@trace(foo(0.5), :a => :c)","category":"page"},{"location":"ref/modeling/dml/#Tilde-syntax","page":"Built-In Modeling Language","title":"Tilde syntax","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"As a short-hand for @trace expressions, the tilde operator ~ can also be used to make random choices and traced calls to generative functions. For example, the expression","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"{:x} ~ normal(0, 1)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"is equivalent to:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(normal(0, 1), :x)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"One can also conveniently assign random values to variables using the syntax:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"x ~ normal(0, 1)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"which is equivalent to:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"x = @trace(normal(0, 1), :x)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Finally, one can make traced calls using a shared address namespace with the syntax:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"{*} ~ foo(0.5)","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"which is equivalent to:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@trace(foo(0.5))","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Note that ~ is also defined in Base as a unary operator that performs the bitwise-not operation (see Base.:~). This use of ~ is also supported within @gen functions. However, uses of ~ as a binary infix operator within an @gen function will always be treated as equivalent to an @trace expression. If your module contains its own two-argument definition YourModule.:~(a, b) of the ~ function, calls to that function within @gen functions have to be in qualified prefix form, i.e., you have to write YourModule.:~(a, b) instead of a ~ b.","category":"page"},{"location":"ref/modeling/dml/#Return-value","page":"Built-In Modeling Language","title":"Return value","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Like regular Julia functions, @gen functions return either the expression used in a return keyword, or by evaluating the last expression in the function body. Note that the return value of a @gen function is different from a trace of @gen function, which contains the return value associated with an execution as well as the assignment to each random choice made during the execution. See Generative Function Interface for more information about traces.","category":"page"},{"location":"ref/modeling/dml/#trainable_parameters_modeling","page":"Built-In Modeling Language","title":"Trainable Parameters","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"A @gen function may begin with an optional block of trainable parameter declarations. The block consists of a sequence of statements, beginning with @param, that declare the name and Julia type for each trainable parameter. The function below has a single trainable parameter theta with type Float64:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo(prob::Float64)\n    @param theta::Float64\n    z1 = @trace(bernoulli(prob), :a)\n    z2 = @trace(bernoulli(theta), :b)\n    return z1 || z2\nend","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Trainable parameters obey the same scoping rules as Julia local variables defined at the beginning of the function body. The value of a trainable parameter is undefined until it is initialized using init_param!. In addition to the current value, each trainable parameter has a current gradient accumulator value. The gradient accumulator value has the same shape (e.g. array dimension) as the parameter value. It is initialized to all zeros, and is incremented by accumulate_param_gradients!.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"The following methods are exported for the trainable parameters of @gen functions:","category":"page"},{"location":"ref/modeling/dml/#Gen.init_param!","page":"Built-In Modeling Language","title":"Gen.init_param!","text":"init_param!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol, value)\n\nInitialize the the value of a named trainable parameter of a generative function.\n\nAlso generates the gradient accumulator for that parameter to zero(value).\n\nExample:\n\ninit_param!(foo, :theta, 0.6)\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.get_param","page":"Built-In Modeling Language","title":"Gen.get_param","text":"value = get_param(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol)\n\nGet the current value of a trainable parameter of the generative function.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.get_param_grad","page":"Built-In Modeling Language","title":"Gen.get_param_grad","text":"value = get_param_grad(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol)\n\nGet the current value of the gradient accumulator for a trainable parameter of the generative function.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.set_param_grad!","page":"Built-In Modeling Language","title":"Gen.set_param_grad!","text":"set_param_grad!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol, grad_value)\n\nSet the gradient accumlator for a trainable parameter of the generative function.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.set_param!","page":"Built-In Modeling Language","title":"Gen.set_param!","text":"set_param!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol, value)\n\nSet the value of a trainable parameter of the generative function.\n\nNOTE: Does not update the gradient accumulator value.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.zero_param_grad!","page":"Built-In Modeling Language","title":"Gen.zero_param_grad!","text":"zero_param_grad!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol)\n\nReset the gradient accumlator for a trainable parameter of the generative function to all zeros.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.accumulate_param_gradients_determ!","page":"Built-In Modeling Language","title":"Gen.accumulate_param_gradients_determ!","text":"arg_grads = accumulate_param_gradients_determ!(\n    gen_fn::CustomDetermGF, state, args, retgrad, scale_factor)\n\nIncrement gradient accumulators for parameters the gradient with respect to the arguments, optionally scaled, and return the gradient with respect to the arguments (not scaled).\n\nGiven the previous state and a gradient with respect to the return value _y J (retgrad), return the following gradient (arg_grads) with respect to the arguments x:\n\n_x J\n\nAlso increment the gradient accumulators for the trainable parameters Θ of the function by:\n\ns * _Θ J\n\nwhere s is scale_factor.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/#Gen.gradient_with_state","page":"Built-In Modeling Language","title":"Gen.gradient_with_state","text":"arg_grads = gradient_with_state(gen_fn::CustomDetermGF, state, args, retgrad)\n\nReturn the gradient tuple with respect to the arguments.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Trainable parameters are designed to be trained using gradient-based methods. This is discussed in the next section.","category":"page"},{"location":"ref/modeling/dml/#differentiable_modeling","page":"Built-In Modeling Language","title":"Differentiable Programming","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Given a trace of a @gen function, Gen supports automatic differentiation of the log probability (density) of all of the random choices made in the trace with respect to the following types of inputs:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"all or a subset of the arguments to the function.\nthe values of all or a subset of random choices.\nall or a subset of trainable parameters of the @gen function.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"We first discuss the semantics of these gradient computations, and then discuss what how to write and use Julia code in the body of a @gen function so that it can be automatically differentiated by the gradient computation.","category":"page"},{"location":"ref/modeling/dml/#Supported-gradient-computations","page":"Built-In Modeling Language","title":"Supported gradient computations","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Gradients with respect to arguments. A @gen function may have a fixed set of its arguments annotated with grad, which indicates that gradients with respect to that argument should be supported. For example, in the function below, we indicate that we want to support differentiation with respect to the y argument, but that we do not want to support differentiation with respect to the x argument.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo(x, (grad)(y))\n    if x > 5\n        @trace(normal(y, 1), :z)\n    else\n        @trace(normal(y, 10), :z)\n    end\nend","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"For the function foo above, when x > 5, the gradient with respect to y is the gradient of the log probability density of a normal distribution with standard deviation 1, with respect to its mean, evaluated at mean y. When x <= 5, we instead differentiate the log density of a normal distribution with standard deviation 10, relative to its mean.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Gradients with respect to values of random choices. The author of a @gen function also identifies a set of addresses of random choices with respect to which they wish to support gradients of the log probability (density). Gradients of the log probability (density) with respect to the values of random choices are used in gradient-based numerical optimization of random choices, as well as certain MCMC updates that require gradient information.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Gradients with respect to trainable parameters. The gradient of the log probability (density) with respect to the trainable parameters can also be computed using automatic differentiation. Currently, the log probability (density) must be a differentiable function of all trainable parameters.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Gradients of a function of the return value. Differentiable programming in Gen composes across function calls. If the return value of the @gen function is conditionally dependent on source elements including (i) any arguments annotated with grad or (ii) any random choices for which gradients are supported, or (ii) any trainable parameters, then the gradient computation requires a gradient of the an external function with respect to the return value in order to the compute the correct gradients. Thus, the function being differentiated always includes a term representing the log probability (density) of all random choices made by the function, but can be extended with a term that depends on the return value of the function. The author of a @gen function can indicate that the return value depends on the source elements (causing the gradient with respect to the return value is required for all gradient computations) by adding the grad annotation to the @gen function itself. For example, in the function below, the return value is conditionally dependent (and actually identical to) on the random value at address :z:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen function foo(x, (grad)(y))\n    if x > 5\n        return @trace(normal(y, 1), :z)\n    else\n        return @trace(normal(y, 10), :z)\n    end\nend","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"If the author of foo wished to support the computation of gradients with respect to the value of :z, they would need to add the grad annotation to foo using the following syntax:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"@gen (grad) function foo(x, (grad)(y))\n    if x > 5\n        return @trace(normal(y, 1), :z)\n    else\n        return @trace(normal(y, 10), :z)\n    end\nend","category":"page"},{"location":"ref/modeling/dml/#Writing-differentiable-code","page":"Built-In Modeling Language","title":"Writing differentiable code","text":"","category":"section"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"In order to compute the gradients described above, the code in the body of the @gen function needs to be differentiable. Code in the body of a @gen function consists of:","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Julia code\nMaking random choices\nCalling generative functions","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"We now discuss how to ensure that code of each of these forms is differentiable. Note that the procedures for differentiation of code described below are only performed during certain operations on @gen functions (choice_gradients and accumulate_param_gradients!).","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Julia code. Julia code used within a body of a @gen function is made differentiable using the ReverseDiff package, which implements  reverse-mode automatic differentiation. Specifically, values whose gradient is required (either values of arguments, random choices, or trainable parameters) are 'tracked' by boxing them into special values and storing the tracked value on a 'tape'. For example a Float64 value is boxed into a ReverseDiff.TrackedReal value. Methods (including e.g. arithmetic operators) are defined that operate on these tracked values and produce other tracked values as a result. As the computation proceeds all the values are placed onto the tape, with back-references to the parent operation and operands. Arithmetic operators, array and linear algebra functions, and common special numerical functions, as well as broadcasting, are automatically supported. See ReverseDiff for more details.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Making random choices. When making a random choice, each argument is either a tracked value or not. If the argument is a tracked value, then the probability distribution must support differentiation of the log probability (density) with respect to that argument. Otherwise, an error is thrown. The has_argument_grads function indicates which arguments support differentiation for a given distribution (see Probability Distributions). If the gradient is required for the value of a random choice, the distribution must support differentiation of the log probability (density) with respect to the value. This is indicated by the has_output_grad function.","category":"page"},{"location":"ref/modeling/dml/","page":"Built-In Modeling Language","title":"Built-In Modeling Language","text":"Calling generative functions. Like distributions, generative functions indicate which of their arguments support differentiation, using the has_argument_grads function. It is an error if a tracked value is passed as an argument of a generative function, when differentiation is not supported by the generative function for that argument. If a generative function gen_fn has accepts_output_grad(gen_fn) = true, then the return value of the generative function call will be tracked and will propagate further through the caller @gen function's computation.","category":"page"},{"location":"ref/inference/importance/#Importance-Sampling","page":"Importance Sampling","title":"Importance Sampling","text":"","category":"section"},{"location":"ref/inference/importance/#Gen.importance_sampling","page":"Importance Sampling","title":"Gen.importance_sampling","text":"(traces, log_norm_weights, lml_est) = importance_sampling(model::GenerativeFunction,\n    model_args::Tuple, observations::ChoiceMap, num_samples::Int; verbose=false)\n\n(traces, log_norm_weights, lml_est) = importance_sampling(model::GenerativeFunction,\n    model_args::Tuple, observations::ChoiceMap,\n    proposal::GenerativeFunction, proposal_args::Tuple,\n    num_samples::Int; verbose=false)\n\nRun importance sampling, returning a vector of traces with associated log weights.\n\nThe log-weights are normalized. Also return the estimate of the marginal likelihood of the observations (lml_est). The observations are addresses that must be sampled by the model in the given model arguments. The first variant uses the internal proposal distribution of the model. The second variant uses a custom proposal distribution defined by the given generative function. All addresses of random choices sampled by the proposal should also be sampled by the model function. Setting verbose=true prints a progress message every sample.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/importance/#Gen.importance_resampling","page":"Importance Sampling","title":"Gen.importance_resampling","text":"(trace, lml_est) = importance_resampling(model::GenerativeFunction,\n    model_args::Tuple, observations::ChoiceMap, num_samples::Int;\n    verbose=false)\n\n(traces, lml_est) = importance_resampling(model::GenerativeFunction,\n    model_args::Tuple, observations::ChoiceMap,\n    proposal::GenerativeFunction, proposal_args::Tuple,\n    num_samples::Int; verbose=false)\n\nRun sampling importance resampling, returning a single trace.\n\nUnlike importance_sampling, the memory used constant in the number of samples.\n\nSetting verbose=true prints a progress message every sample.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/change_hints/#Change-Hints","page":"Change Hints","title":"Change Hints","text":"","category":"section"},{"location":"ref/core/change_hints/","page":"Change Hints","title":"Change Hints","text":"Gen defines a system of change hints, or Diff types, in order to pass information to and from generative functions about whether their arguments and return values have changed (and how). ","category":"page"},{"location":"ref/core/change_hints/#Gen.Diff","page":"Change Hints","title":"Gen.Diff","text":"Diff\n\nAbstract supertype for information about a change to a value.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/change_hints/","page":"Change Hints","title":"Change Hints","text":"Change hints are used to support incremental computation in generative function combinators and the static modeling language.  The most important change hints are NoChange and UnknownChange, which respectively indicate that a value has not changed and that a value may have changed in an unknown way.","category":"page"},{"location":"ref/core/change_hints/#Gen.NoChange","page":"Change Hints","title":"Gen.NoChange","text":"NoChange\n\nSingleton to indicate the value did not change.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/change_hints/#Gen.UnknownChange","page":"Change Hints","title":"Gen.UnknownChange","text":"UnknownChange\n\nSingleton to indicate the change to the value is unknown or unprovided.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/change_hints/","page":"Change Hints","title":"Change Hints","text":"A number of other change hints are also implemented in Gen, such as IntDiff,  VectorDiff, and SetDiff and DictDiff, which support incremental computation for certain operations when applied to Diffed values.  These change hints are not documented, and are currently considered an  implementation detail.","category":"page"},{"location":"ref/core/change_hints/#Gen.Diffed","page":"Change Hints","title":"Gen.Diffed","text":"Diffed{V,DV <: Diff}\n\nContainer for a value and information about a change to its value.\n\n\n\n\n\n","category":"type"},{"location":"how_to/custom_gen_fns/#custom_gen_fns_howto","page":"Adding New Generative Functions","title":"Adding New Types of Generative Functions","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"We recommend the following steps for implementing a new type of generative function, and also looking at the implementation for the DynamicDSLFunction type as an example.","category":"page"},{"location":"how_to/custom_gen_fns/#Define-a-trace-data-type","page":"Adding New Generative Functions","title":"Define a trace data type","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"struct MyTraceType <: Trace\n    ..\nend","category":"page"},{"location":"how_to/custom_gen_fns/#Decide-the-return-type-for-the-generative-function","page":"Adding New Generative Functions","title":"Decide the return type for the generative function","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"Suppose our return type is Vector{Float64}.","category":"page"},{"location":"how_to/custom_gen_fns/#Define-a-data-type-for-your-generative-function","page":"Adding New Generative Functions","title":"Define a data type for your generative function","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"This should be a subtype of GenerativeFunction, with the appropriate type parameters.","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"struct MyGenerativeFunction <: GenerativeFunction{Vector{Float64},MyTraceType}\n..\nend","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"Note that your generative function may not need to have any fields. You can create a constructor for it, e.g.:","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"function MyGenerativeFunction(...)\n..\nend","category":"page"},{"location":"how_to/custom_gen_fns/#Decide-what-the-arguments-to-a-generative-function-should-be","page":"Adding New Generative Functions","title":"Decide what the arguments to a generative function should be","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"For example, our generative functions might take two arguments, a (of type Int) and b (of type Float64). Then, the argument tuple passed to e.g. generate will have two elements.","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"NOTE: Be careful to distinguish between arguments to the generative function itself, and arguments to the constructor of the generative function. For example, if you have a generative function type that is parametrized by, for example, modeling DSL code, this DSL code would be a parameter of the generative function constructor.","category":"page"},{"location":"how_to/custom_gen_fns/#Decide-what-the-traced-random-choices-(if-any)-will-be","page":"Adding New Generative Functions","title":"Decide what the traced random choices (if any) will be","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"Remember that each random choice is assigned a unique address in (possibly) hierarchical address space. You are free to design this address space as you wish, although you should document it for users of your generative function type.","category":"page"},{"location":"how_to/custom_gen_fns/#Implement-methods-of-the-Generative-Function-Interface","page":"Adding New Generative Functions","title":"Implement methods of the Generative Function Interface","text":"","category":"section"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"At minimum, you need to implement the following methods:","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"simulate\nhas_argument_grads\naccepts_output_grad\nget_args\nget_retval\nget_choices\nget_score\nget_gen_fn\nproject","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"If you want to use the generative function within models, you should implement:","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"generate","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"If you want to use MCMC on models that call your generative function, then implement:","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"update\nregenerate","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"If you want to use gradient-based inference techniques on models that call your generative function, then implement:","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"choice_gradients\nupdate","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"If your generative function has trainable parameters, then implement:","category":"page"},{"location":"how_to/custom_gen_fns/","page":"Adding New Generative Functions","title":"Adding New Generative Functions","text":"accumulate_param_gradients!","category":"page"},{"location":"how_to/custom_distributions/#custom_distributions_howto","page":"Adding New Distributions","title":"Adding New Distributions","text":"","category":"section"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"In addition to the built-in distributions, mixture distributions, and product distributions, Gen provides two primary ways of adding new distributions:","category":"page"},{"location":"how_to/custom_distributions/#dist_dsl_howto","page":"Adding New Distributions","title":"Defining New Distributions Inline with the @dist DSL","text":"","category":"section"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"The @dist DSL allows users to concisely define a distribution, as long as that distribution can be expressed as a certain type of deterministic transformation of an existing distribution:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"@dist name(arg1, arg2, ..., argN) = body","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"or","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"@dist function name(arg1, arg2, ..., argN)\n    body\nend","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"Here body is ordinary Julia code, with the constraint that body must contain exactly one random choice.  The resulting distribution is called name, parameterized by arg1, ..., argN, and represents a distribution over return values of body. ","category":"page"},{"location":"how_to/custom_distributions/#Common-Use-Cases","page":"Adding New Distributions","title":"Common Use Cases","text":"","category":"section"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"The @dist DSL makes it easy to implement labeled uniform or categorical distributions, instead of having to use integers to refer to categories:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"\"\"\"Labeled uniform distribution\"\"\"\n@dist labeled_uniform(labels) = labels[uniform_discrete(1, length(labels))]\n\n\"\"\"Labeled categorical distribution\"\"\"\n@dist labeled_categorical(labels, probs) = labels[categorical(probs)]","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"Note however that there is a slight overhead incurred by having to detect the  possibility of duplicate labels.","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"It is also possible to implement a distribution that takes a Boolean input  and flips it with some probability:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"\"Bit-flip distribution.\"\n@dist bit_flip(x::Bool, p::Float64) = bernoulli((1-x) * p + x * (1-p))","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"Finally, it is possible to distributions that are defined in terms of shifting,  scaling, exponentiation, or taking the logarithm of another distribution:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"\"Symmetric Binomial distribution.\"\n@dist sym_binom(mean::Int, scale::Int) = binom(2*scale, 0.5) - scale + mean\n\n\"Shifted geometric distribution.\"\n@dist shifted_geometric(p::Real, shift::Int) = geometric(p) + shift\n\n\"Log-normal distribution.\"\n@dist log_normal(mu::Real, sigma::Real) = exp(normal(mu, sigma))\n\n\"Gumbel distribution.\"\n@dist gumbel(mu::Real, beta::Real) = mu - beta * log(0.0 - log(uniform(0, 1)))","category":"page"},{"location":"how_to/custom_distributions/#Restrictions","page":"Adding New Distributions","title":"Restrictions","text":"","category":"section"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"There are a number of restrictions imposed by the @dist DSL, which are explained further in the reference docmumentation. Most importantly, only a limited set of deterministic transformations are currently supported (+, -, *, /, exp, log, getindex), and only one random choice can be used in the body of the definition.","category":"page"},{"location":"how_to/custom_distributions/#Defining-New-Distributions-From-Scratch","page":"Adding New Distributions","title":"Defining New Distributions From Scratch","text":"","category":"section"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"For distributions that cannot be expressed in the @dist DSL, users can define a custom distribution by defining an (ordinary Julia) subtype of Gen.Distribution and implementing the methods of the Distribution API.  This method requires more custom code than using the @dist DSL, but also affords more flexibility: arbitrary user-defined logic for sampling, PDF evaluation, etc.","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"Probability distributions are singleton types whose supertype is Distribution{T}, where T indicates the data type of the random sample.","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"abstract type Distribution{T} end","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"A new Distribution type must implement the following methods:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"random\nlogpdf\nlogpdf_grad\nhas_argument_grads\nhas_output_grad\nis_discrete","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"By convention, distributions have a global constant lower-case name for the singleton value. For example:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"struct Bernoulli <: Distribution{Bool} end\nconst bernoulli = Bernoulli()","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"Distribution values should also be callable, which is a syntactic sugar with the same behavior of calling random:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"bernoulli(0.5) # identical to random(bernoulli, 0.5) and random(Bernoulli(), 0.5)","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"For example, this can be done by adding a method definition for Bernoulli:","category":"page"},{"location":"how_to/custom_distributions/","page":"Adding New Distributions","title":"Adding New Distributions","text":"(::Bernoulli)(prob) = random(Bernoulli(), prob)","category":"page"},{"location":"ref/core/gfi/#gfi","page":"Generative Function Interface","title":"Generative Function Interface","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"One of the core abstractions in Gen is the generative function. The interface for interacting with generative functions is called the generative function interface (GFI) . Generative functions are used to represent a variety of different types of probabilistic computations including generative models, inference models, custom proposal distributions, and variational approximations.","category":"page"},{"location":"ref/core/gfi/#Introduction","page":"Generative Function Interface","title":"Introduction","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"There are various kinds of generative functions, which are represented by concrete subtypes of GenerativeFunction.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"For example, the Built-in Modeling Language allows generative functions to be constructed using Julia function definition syntax:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"using Gen # hide\n@gen function foo(a, b=0)\n    if @trace(bernoulli(0.5), :z)\n        return a + b + 1\n    else\n        return a + b\n    end\nend;","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Users can also extend Gen by implementing their own custom generative functions, which can be new modeling languages, or just specialized optimized implementations of a fragment of a specific model.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Generative functions behave like Julia functions in some respects. For example, we can call a generative function foo on arguments and get an output value using regular Julia call syntax:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"foo(2, 4)","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"However, generative functions are distinct from Julia functions because they support additional behaviors, described in the remainder of this section.","category":"page"},{"location":"ref/core/gfi/#Mathematical-concepts","page":"Generative Function Interface","title":"Mathematical concepts","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Generative functions represent computations that accept some arguments, may use randomness internally, return an output, and cannot mutate externally observable state. We represent the randomness used during an execution of a generative function as a choice map from unique addresses to values of random choices, denoted t  A to V where A is a finite (but not a priori bounded) address set and V is a set of possible values that random choices can take. In this section, we assume that random choices are discrete to simplify notation. We say that two choice maps t and s agree if they assign the same value for any address that is in both of their domains.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Generative functions may also use non-addressable randomness, which is not included in the map t. We denote non-addressable randomness by r. Untraced randomness is useful for example, when calling black box Julia code that implements a randomized algorithm.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The observable behavior of every generative function is defined by the following mathematical objects:","category":"page"},{"location":"ref/core/gfi/#Input-type","page":"Generative Function Interface","title":"Input type","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The set of valid argument tuples to the function, denoted X.","category":"page"},{"location":"ref/core/gfi/#Probability-distribution-family","page":"Generative Function Interface","title":"Probability distribution family","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"A family of probability distributions p(t r x) on maps t from random choice addresses to their values, and non-addressable randomness r, indexed by arguments x, for all x in X. Note that the distribution must be normalized:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"sum_t r p(t r x) = 1  textfor all  x in X","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"This corresponds to a requirement that the function terminate with probabability 1 for all valid arguments. We use p(t x) to denote the marginal distribution on the map t:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"p(t x) = sum_r p(t r x)","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"And we denote the conditional distribution on non-addressable randomness r, given the map t, as:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"p(r  t x) = p(t r x)  p(t x)","category":"page"},{"location":"ref/core/gfi/#Return-value-function","page":"Generative Function Interface","title":"Return value function","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"A (deterministic) function f that maps the tuple (x t) of the arguments and the choice map to the return value of the function (which we denote by y). Note that the return value cannot depend on the non-addressable randomness.","category":"page"},{"location":"ref/core/gfi/#Auxiliary-state","page":"Generative Function Interface","title":"Auxiliary state","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Generative functions may expose additional auxiliary state associated with an execution, besides the choice map and the return value. This auxiliary state is a function z = h(x t r) of the arguments, choice map, and non-addressable randomness. Like the choice map, the auxiliary state is indexed by addresses. We require that the addresses of auxiliary state are disjoint from the addresses in the choice map. Note that when a generative function is called within a model, the auxiliary state is not available to the caller. It is typically used by inference programs, for logging and for caching the results of deterministic computations that would otherwise need to be reconstructed.","category":"page"},{"location":"ref/core/gfi/#Internal-proposal-distribution-family","page":"Generative Function Interface","title":"Internal proposal distribution family","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"A family of probability distributions q(t x u) on maps t from random choice addresses to their values, indexed by tuples (x u) where u is a map from random choice addresses to values, and where x are the arguments to the function. It must satisfy the following conditions:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"sum_t q(t x u) = 1  textfor all  x in X u","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"p(t x)  0 text if and only if  q(t x u)  0 text for all  u text where  u text and  t text agree ","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"q(t x u)  0 text implies that  u text and  t text agree ","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"There is also a family of probability distributions q(r x t) on non-addressable randomness, that satisfies:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"q(r x t)  0 text if and only if  p(r  t x)  0","category":"page"},{"location":"ref/core/gfi/#Traces","page":"Generative Function Interface","title":"Traces","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"An execution trace (or just trace) is a record of an execution of a generative function. Traces are the primary data structures manipulated by Gen inference programs. There are various methods for producing, updating, and inspecting traces. Traces contain:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"the arguments to the generative function\nthe choice map\nthe return value\nauxiliary state\nother implementation-specific state that is not exposed to the caller or user of the generative function, but is used internally to facilitate e.g. incremental updates to executions and automatic differentiation\nany necessary record of the non-addressable randomness","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Different concrete types of generative functions use different data structures and different Julia types for their traces, but traces are subtypes of Trace.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The concrete trace type that a generative function uses is the second type parameter of the GenerativeFunction abstract type. For example, the trace type of DynamicDSLFunction is DynamicDSLTrace.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"A generative function can be executed to produce a trace of the execution using simulate:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"trace = simulate(foo, (a, b))","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"A traced execution that satisfies constraints on the choice map can be generated using generate:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"trace, weight = generate(foo, (a, b), choicemap((:z, false)))","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"There are various methods for inspecting traces, including:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"get_args (returns the arguments to the function)\nget_retval (returns the return value of the function)\nget_choices (returns the choice map)\nget_score (returns the log probability that the random choices took the values they did)\nget_gen_fn (returns a reference to the generative function)","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"You can also access the values in the choice map and the auxiliary state of the trace by passing the address to Base.getindex. For example, to retrieve the value of random choice at address :z:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"z = trace[:z]","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"When a generative function has default values specified for trailing arguments, those arguments can be left out when calling simulate, generate, and other functions provided by the generative function interface. The default values will automatically be filled in:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"trace = simulate(foo, (2,));\nget_args(trace)","category":"page"},{"location":"ref/core/gfi/#Updating-traces","page":"Generative Function Interface","title":"Updating traces","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"It is often important to incrementally modify the trace of a generative function (e.g. within MCMC, numerical optimization, sequential Monte Carlo, etc.). In Gen, traces are functional data structures, meaning they can be treated as immutable values. There are several methods that take a trace of a generative function as input and return a new trace of the generative function based on adjustments to the execution history of the function. We will illustrate these methods using the following generative function:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"@gen function bar()\n    val = @trace(bernoulli(0.3), :a)\n    if @trace(bernoulli(0.4), :b)\n        val = @trace(bernoulli(0.6), :c) && val\n    else\n        val = @trace(bernoulli(0.1), :d) && val\n    end\n    val = @trace(bernoulli(0.7), :e) && val\n    return val\nend","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Suppose we have a trace (trace) of bar with initial choices:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"trace, _ = generate(bar, (), choicemap(:a=>false, :b=>true, :c=>false, :e=>true)) # hide\nnothing # hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"get_choices(trace) # hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Note that address :d is not present because the branch in which :d is sampled was not taken because random choice :b had value true.","category":"page"},{"location":"ref/core/gfi/#Update","page":"Generative Function Interface","title":"Update","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The update method takes a trace and generates an adjusted trace that is consistent with given changes to the arguments to the function, and changes to the values of random choices made.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Example. Suppose we run update on the example trace, with the following constraints:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"choicemap(:b=>false, :d=>true) #hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"constraints = choicemap((:b, false), (:d, true))\n(new_trace, w, _, discard) = update(trace, (), (), constraints)","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Then get_choices(new_trace) will be:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"get_choices(new_trace)","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"and discard will be:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"discard","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Note that the discard contains both the previous values of addresses that were overwritten, and the values for addresses that were in the previous trace but are no longer in the new trace. The weight (w) is computed as:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"p(t x) = 07  04  04  07 = 00784\np(t x) = 07  06  01  07 = 00294\nw = log p(t x)p(t x) = log 0029400784 = log 0375","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Example. Suppose we run update on the example trace, with the following constraints, which do not contain a value for :d:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"choicemap(:b=>false) # hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"constraints = choicemap((:b, false))\n(new_trace, w, _, discard) = update(trace, (), (), constraints)","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Since b is constrained to false, the updated trace must now sample at address d (note address e remains fixed). There two possibilities for get_choices(new_trace):","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The first choicemap:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"choicemap(:a=>false, :b=>false, :d=>true, :e=>true) # hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"occurs with probability 0.1. The second:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"choicemap(:a=>false, :b=>false, :d=>false, :e=>true) # hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"occurs with probability 0.9. Also, discard will be:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"discard # hide","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"If the former case occurs and :d is assigned to true, then the weight (w) is computed as:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"p(t x) = 07  04  04  07 = 00784\np(t x) = 07  06  01  07 = 00294\nq(t x t + u) = 01\nw = log p(t x)(p(t x) q(t x t + u)) = log 00294(00784 cdot 01) = log (375)","category":"page"},{"location":"ref/core/gfi/#Regenerate","page":"Generative Function Interface","title":"Regenerate","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The regenerate method takes a trace and generates an adjusted trace that is consistent with a change to the arguments to the function, and also generates new values for selected random choices.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Example. Suppose we run regenerate on the example trace, with selection :a and :b:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"(new_trace, w, _) = regenerate(trace, (), (), select(:a, :b))","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Then, a new value for :a will be sampled from bernoulli(0.3), and a new value for :b will be sampled from bernoulli(0.4). If the new value for :b is true, then the previous value for :c (false) will be retained. If the new value for :b is false, then a new value for :d will be sampled from bernoulli(0.7). The previous value for :c will always be retained. Suppose the new value for :a is true, and the new value for :b is true. Then get_choices(new_trace) will be:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"│\n├── :a : true\n│\n├── :b : true\n│\n├── :c : false\n│\n└── :e : true","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The weight (w) is log 1 = 0.","category":"page"},{"location":"ref/core/gfi/#Argdiffs","page":"Generative Function Interface","title":"Argdiffs","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"In addition to the input trace, and other arguments that indicate how to adjust the trace, each of these methods also accepts an args argument and an argdiffs argument, both of which are tuples. The args argument contains the new arguments to the generative function, which may differ from the previous arguments to the generative function (which can be retrieved by applying get_args to the previous trace). In many cases, the adjustment to the execution specified by the other arguments to these methods is 'small' and only affects certain parts of the computation. Therefore, it is often possible to generate the new trace and the appropriate log probability ratios required for these methods without revisiting every state of the computation of the generative function.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"To enable this, the argdiffs argument provides additional information about the difference between each of the previous arguments to the generative function, and its new argument value. This argdiff information permits the implementation of the update method to avoid inspecting the entire argument data structure to identify which parts were updated. Note that the correctness of the argdiff is in general not verified by Gen–-passing incorrect argdiff information may result in incorrect behavior.","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The trace update methods for all generative functions above should accept at least the following types of argdiffs:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"NoChange\nUnknownChange","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Generative functions may also be able to process more specialized diff data types for each of their arguments, that allow more precise information about the different to be supplied.","category":"page"},{"location":"ref/core/gfi/#Retdiffs","page":"Generative Function Interface","title":"Retdiffs","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"To enable generative functions that invoke other functions to efficiently make use of incremental computation, the trace update methods of generative functions also return a retdiff value, which provides information about the difference in the return value of the previous trace an the return value of the new trace.","category":"page"},{"location":"ref/core/gfi/#Differentiable-Programming","page":"Generative Function Interface","title":"Differentiable Programming","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The trace of a generative function may support computation of gradients of its log probability with respect to some subset of (i) its arguments, (ii) values of random choice, and (iii) any of its trainable parameters (see below).","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"To compute gradients with respect to the arguments as well as certain selected random choices, use:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"choice_gradients","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"To compute gradients with respect to the arguments, and to increment a stateful gradient accumulator for the trainable parameters of the generative function, use:","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"accumulate_param_gradients!","category":"page"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"A generative function statically reports whether or not it is able to compute gradients with respect to each of its arguments, through the function has_argument_grads.","category":"page"},{"location":"ref/core/gfi/#Trainable-parameters","page":"Generative Function Interface","title":"Trainable parameters","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The trainable parameters of a generative function are (unlike arguments and random choices) state of the generative function itself, and are not contained in the trace. Generative functions that have trainable parameters maintain gradient accumulators for these parameters, which get incremented by the gradient induced by the given trace by a call to accumulate_param_gradients!. Users then use these accumulated gradients to update to the values of the trainable parameters.","category":"page"},{"location":"ref/core/gfi/#Return-value-gradient","page":"Generative Function Interface","title":"Return value gradient","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The set of elements (either arguments, random choices, or trainable parameters) for which gradients are available is called the gradient source set. If the return value of the function is conditionally dependent on any element in the gradient source set given the arguments and values of all other random choices, for all possible traces of the function, then the generative function requires a return value gradient to compute gradients with respect to elements of the gradient source set. This static property of the generative function is reported by accepts_output_grad.","category":"page"},{"location":"ref/core/gfi/#API","page":"Generative Function Interface","title":"API","text":"","category":"section"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The following GFI methods should be implemented for a Trace:","category":"page"},{"location":"ref/core/gfi/#Gen.Trace","page":"Generative Function Interface","title":"Gen.Trace","text":"Trace\n\nAbstract type for a trace of a generative function.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/gfi/#Gen.get_args","page":"Generative Function Interface","title":"Gen.get_args","text":"get_args(trace)\n\nReturn the argument tuple for a given execution.\n\nExample:\n\nargs::Tuple = get_args(trace)\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.get_retval","page":"Generative Function Interface","title":"Gen.get_retval","text":"get_retval(trace)\n\nReturn the return value of the given execution.\n\nExample for generative function with return type T:\n\nretval::T = get_retval(trace)\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.get_choices","page":"Generative Function Interface","title":"Gen.get_choices","text":"get_choices(trace)\n\nReturn a value implementing the assignment interface\n\nNote that the value of any non-addressed randomness is not externally accessible.\n\nExample:\n\nchoices::ChoiceMap = get_choices(trace)\nz_val = choices[:z]\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.get_score","page":"Generative Function Interface","title":"Gen.get_score","text":"get_score(trace)\n\nReturn:\n\nlog fracp(r t x)q(r x t)\n\nWhen there is no non-addressed randomness, this simplifies to the log probability log p(t x).\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.get_gen_fn","page":"Generative Function Interface","title":"Gen.get_gen_fn","text":"gen_fn::GenerativeFunction = get_gen_fn(trace)\n\nReturn the generative function that produced the given trace.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Base.getindex","page":"Generative Function Interface","title":"Base.getindex","text":"value = getindex(trace::Trace, addr)\n\nGet the value of the random choice, or auxiliary state (e.g. return value of inner function call), at address addr.\n\n\n\n\n\nretval = getindex(trace::Trace)\nretval = trace[]\n\nSynonym for get_retval.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"The following GFI methods should be implemented for a GenerativeFunction and its associated Trace datatype:","category":"page"},{"location":"ref/core/gfi/#Gen.GenerativeFunction","page":"Generative Function Interface","title":"Gen.GenerativeFunction","text":"GenerativeFunction{T,U <: Trace}\n\nAbstract type for a generative function with return value type T and trace type U.\n\n\n\n\n\n","category":"type"},{"location":"ref/core/gfi/#Gen.simulate","page":"Generative Function Interface","title":"Gen.simulate","text":"trace = simulate(gen_fn, args)\n\nExecute the generative function and return the trace.\n\nGiven arguments (args), sample (r t) sim p(cdot x) and return a trace with choice map t.\n\nIf gen_fn has optional trailing arguments (i.e., default values are provided), the optional arguments can be omitted from the args tuple. The generated trace  will have default values filled in.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.generate","page":"Generative Function Interface","title":"Gen.generate","text":"(trace::U, weight) = generate(gen_fn::GenerativeFunction{T,U}, args::Tuple)\n\nReturn a trace of a generative function.\n\n(trace::U, weight) = generate(gen_fn::GenerativeFunction{T,U}, args::Tuple,\n                                constraints::ChoiceMap)\n\nReturn a trace of a generative function that is consistent with the given constraints on the random choices.\n\nGiven arguments x (args) and assignment u (constraints) (which is empty for the first form), sample t sim q(cdot u x) and r sim q(cdot x t), and return the trace (x r t) (trace). Also return the weight (weight):\n\nlog fracp(r t x)q(t u x) q(r x t)\n\nIf gen_fn has optional trailing arguments (i.e., default values are provided), the optional arguments can be omitted from the args tuple. The generated trace  will have default values filled in.\n\nExample without constraints:\n\n(trace, weight) = generate(foo, (2, 4))\n\nExample with constraint that address :z takes value true.\n\n(trace, weight) = generate(foo, (2, 4), choicemap((:z, true))\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.update","page":"Generative Function Interface","title":"Gen.update","text":"(new_trace, weight, retdiff, discard) = update(trace, args::Tuple, argdiffs::Tuple,\n                                               constraints::ChoiceMap)\n\nUpdate a trace by changing the arguments and/or providing new values for some existing random choice(s) and values for some newly introduced random choice(s).\n\nGiven a previous trace (x r t) (trace), new arguments x (args), and a map u (constraints), return a new trace (x r t) (new_trace) that is consistent with u.  The values of choices in t are either copied from t or from u (with u taking precedence) or are sampled from the internal proposal distribution.  All choices in u must appear in t.  Also return an assignment v (discard) containing the choices in t that were overwritten by values from u, and any choices in t whose address does not appear in t. Sample t sim q(cdot x t + u), and r sim q(cdot x t), where t + u is the choice map obtained by merging t and u with u taking precedence for overlapping addresses.  Also return a weight (weight):\n\nlog fracp(r t x)q(r x t) q(t x t + u)\n- log fracp(r t x)q(r x t)\n\nNote that argdiffs is expected to be the same length as args. If the function that generated trace supports default values for trailing arguments, then these arguments can be omitted from args and argdiffs. Note that if the original trace was generated using non-default argument values, then for each optional argument that is omitted, the old value will be over-written by the default argument value in the updated trace.\n\n\n\n\n\n(new_trace, weight, retdiff, discard) = update(trace, constraints::ChoiceMap)\n\nShorthand variant of update which assumes the arguments are unchanged.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.regenerate","page":"Generative Function Interface","title":"Gen.regenerate","text":"(new_trace, weight, retdiff) = regenerate(trace, args::Tuple, argdiffs::Tuple,\n                                          selection::Selection)\n\nUpdate a trace by changing the arguments and/or randomly sampling new values for selected random choices using the internal proposal distribution family.\n\nGiven a previous trace (x r t) (trace), new arguments x (args), and a set of addresses A (selection), return a new trace (x t) (new_trace) such that t agrees with t on all addresses not in A (t and t may have different sets of addresses).  Let u denote the restriction of t to the complement of A.  Sample t sim Q(cdot u x) and sample r sim Q(cdot x t). Return the new trace (x r t) (new_trace) and the weight (weight):\n\nlog fracp(r t x)q(t u x) q(r x t)\n- log fracp(r t x)q(t u x) q(r x t)\n\nwhere u is the restriction of t to the complement of A.\n\nNote that argdiffs is expected to be the same length as args. If the function that generated trace supports default values for trailing arguments, then these arguments can be omitted from args and argdiffs. Note that if the original trace was generated using non-default argument values, then for each optional argument that is omitted, the old value will be over-written by the default argument value in the regenerated trace.\n\n\n\n\n\n(new_trace, weight, retdiff) = regenerate(trace, selection::Selection)\n\nShorthand variant of regenerate which assumes the arguments are unchanged.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.project","page":"Generative Function Interface","title":"Gen.project","text":"weight = project(trace::U, selection::Selection)\n\nEstimate the probability that the selected choices take the values they do in a trace.\n\nGiven a trace (x r t) (trace) and a set of addresses A (selection), let u denote the restriction of t to A. Return the weight (weight):\n\nlog fracp(r t x)q(t u x) q(r x t)\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.propose","page":"Generative Function Interface","title":"Gen.propose","text":"(choices, weight, retval) = propose(gen_fn::GenerativeFunction, args::Tuple)\n\nSample an assignment and compute the probability of proposing that assignment.\n\nGiven arguments (args), sample t sim p(cdot x) and r sim p(cdot x t), and return t (choices) and the weight (weight):\n\nlog fracp(r t x)q(r x t)\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.assess","page":"Generative Function Interface","title":"Gen.assess","text":"(weight, retval) = assess(gen_fn::GenerativeFunction, args::Tuple, choices::ChoiceMap)\n\nReturn the probability of proposing an assignment\n\nGiven arguments x (args) and an assignment t (choices) such that p(t x)  0, sample r sim q(cdot x t) and return the weight (weight):\n\nlog fracp(r t x)q(r x t)\n\nIt is an error if p(t x) = 0.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/","page":"Generative Function Interface","title":"Generative Function Interface","text":"Generative functions that support gradient computation with respect to arguments or trainable parameters should implement the following static properties:","category":"page"},{"location":"ref/core/gfi/#Gen.has_argument_grads","page":"Generative Function Interface","title":"Gen.has_argument_grads","text":"bools::Tuple = has_argument_grads(gen_fn::Union{GenerativeFunction,Distribution})\n\nReturn a tuple of booleans indicating whether a gradient is available for each of its arguments.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.accepts_output_grad","page":"Generative Function Interface","title":"Gen.accepts_output_grad","text":"req::Bool = accepts_output_grad(gen_fn::GenerativeFunction)\n\nReturn a boolean indicating whether the return value is dependent on any of the gradient source elements for any trace.\n\nThe gradient source elements are:\n\nAny argument whose position is true in has_argument_grads\nAny trainable parameter\nRandom choices made at a set of addresses that are selectable by choice_gradients.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.choice_gradients","page":"Generative Function Interface","title":"Gen.choice_gradients","text":"(arg_grads, choice_values, choice_grads) = choice_gradients(\n    trace, selection=EmptySelection(), retgrad=nothing)\n\nGiven a previous trace (x t) (trace) and a gradient with respect to the return value _y J (retgrad), return the following gradient (arg_grads) with respect to the arguments x:\n\n_x left( log P(t x) + J right)\n\nThe length of arg_grads will be equal to the number of arguments to the function that generated trace (including any optional trailing arguments). If an argument is not annotated with (grad), the corresponding value in arg_grads will be nothing.\n\nAlso given a set of addresses A (selection) that are continuous-valued random choices, return the folowing gradient (choice_grads) with respect to the values of these choices:\n\n_A left( log P(t x) + J right)\n\nThe gradient is represented as a choicemap whose value at (hierarchical) address addr is Jttextttaddr.\n\nAlso return the choicemap (choice_values) that is the restriction of t to A.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.accumulate_param_gradients!","page":"Generative Function Interface","title":"Gen.accumulate_param_gradients!","text":"arg_grads = accumulate_param_gradients!(trace, retgrad=nothing, scale_factor=1.)\n\nIncrement gradient accumulators for parameters by the gradient of the log-probability of the trace, optionally scaled, and return the gradient with respect to the arguments (not scaled).\n\nGiven a previous trace (x t) (trace) and a gradient with respect to the return value _y J (retgrad), return the following gradient (arg_grads) with respect to the arguments x:\n\n_x left( log P(t x) + J right)\n\nThe length of arg_grads will be equal to the number of arguments to the function that generated trace (including any optional trailing arguments). If an argument is not annotated with (grad), the corresponding value in arg_grads will be nothing.\n\nAlso increment the gradient accumulators for the trainable parameters Θ of the function by:\n\ns * _Θ left( log P(t x) + J right)\n\nwhere s is scale_factor.\n\n\n\n\n\n","category":"function"},{"location":"ref/core/gfi/#Gen.get_params","page":"Generative Function Interface","title":"Gen.get_params","text":"get_params(gen_fn::GenerativeFunction)\n\nReturn an iterable over the trainable parameters of the generative function.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/parameter_optimization/#Parameter-Optimization","page":"Parameter Optimization","title":"Parameter Optimization","text":"","category":"section"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"Gen provides support for gradient-based optimization of the trainable parameters of generative functions, e.g. for maximixum likelihood learning, expectation-maximization, or empirical Bayes.","category":"page"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"Trainable parameters of generative functions are initialized differently depending on the type of generative function. Trainable parameters of the built-in modeling language are initialized with init_param!.","category":"page"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"Gradient-based optimization of the trainable parameters of generative functions is based on interleaving two steps:","category":"page"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"Incrementing gradient accumulators for trainable parameters by calling accumulate_param_gradients! on one or more traces.\nUpdating the value of trainable parameters and resetting the gradient accumulators to zero, by calling apply! on a parameter update, as described below.","category":"page"},{"location":"ref/inference/parameter_optimization/#Parameter-update","page":"Parameter Optimization","title":"Parameter update","text":"","category":"section"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"A parameter update reads from the gradient accumulators for certain trainable parameters, updates the values of those parameters, and resets the gradient accumulators to zero.","category":"page"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"A paramter update is constructed by combining an update configuration with the set of trainable parameters to which the update should be applied:","category":"page"},{"location":"ref/inference/parameter_optimization/#Gen.ParamUpdate","page":"Parameter Optimization","title":"Gen.ParamUpdate","text":"update = ParamUpdate(conf, param_lists...)\n\nReturn an update configured by conf that applies to set of parameters defined by param_lists.\n\nEach element in param_lists value is is pair of a generative function and a vector of its parameter references.\n\nExample. To construct an update that applies a gradient descent update to the parameters :a and :b of generative function foo and the parameter :theta of generative function :bar:\n\nupdate = ParamUpdate(GradientDescent(0.001, 100), foo => [:a, :b], bar => [:theta])\n\n\n\nSyntactic sugar for the constructor form above.\n\nupdate = ParamUpdate(conf, gen_fn::GenerativeFunction)\n\nReturn an update configured by conf that applies to all trainable parameters owned by the given generative function.\n\nNote that trainable parameters not owned by the given generative function will not be updated, even if they are used during execution of the function.\n\nExample. If generative function foo has parameters :a and :b, to construct an update that applies a gradient descent update to the parameters :a and :b:\n\nupdate = ParamUpdate(GradientDescent(0.001, 100), foo)\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"The set of possible update configurations is described in Update configurations.An update is applied with:","category":"page"},{"location":"ref/inference/parameter_optimization/#Gen.apply!","page":"Parameter Optimization","title":"Gen.apply!","text":"apply!(update::ParamUpdate)\n\nPerform one step of the update.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/parameter_optimization/#update_configurations","page":"Parameter Optimization","title":"Update configurations","text":"","category":"section"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"Gen has built-in support for the following types of update configurations.","category":"page"},{"location":"ref/inference/parameter_optimization/#Gen.FixedStepGradientDescent","page":"Parameter Optimization","title":"Gen.FixedStepGradientDescent","text":"conf = FixedStepGradientDescent(step_size)\n\nConfiguration for stochastic gradient descent update with fixed step size.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/parameter_optimization/#Gen.GradientDescent","page":"Parameter Optimization","title":"Gen.GradientDescent","text":"conf = GradientDescent(step_size_init, step_size_beta)\n\nConfiguration for stochastic gradient descent update with step size given by (t::Int) -> step_size_init * (step_size_beta + 1) / (step_size_beta + t) where t is the iteration number.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/parameter_optimization/#Gen.ADAM","page":"Parameter Optimization","title":"Gen.ADAM","text":"conf = ADAM(learning_rate, beta1, beta2, epsilon)\n\nConfiguration for ADAM update.\n\n\n\n\n\n","category":"type"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"Custom update configurations should implement the following methods:","category":"page"},{"location":"ref/inference/parameter_optimization/#Gen.init_update_state","page":"Parameter Optimization","title":"Gen.init_update_state","text":"state = init_update_state(conf, gen_fn::GenerativeFunction, param_list::Vector)\n\nGet the initial state for a parameter update to the given parameters of the given generative function.\n\nparam_list is a vector of references to parameters of gen_fn. conf configures the update.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/parameter_optimization/#Gen.apply_update!","page":"Parameter Optimization","title":"Gen.apply_update!","text":"apply_update!(state)\n\nApply one parameter update, mutating the values of the trainable parameters, and possibly also the given state.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/parameter_optimization/#Training-generative-functions","page":"Parameter Optimization","title":"Training generative functions","text":"","category":"section"},{"location":"ref/inference/parameter_optimization/","page":"Parameter Optimization","title":"Parameter Optimization","text":"The train! method can be used to train the parameters of a generative function to maximize the likelihood of a dataset defined by a data_generator:","category":"page"},{"location":"ref/inference/parameter_optimization/#Gen.train!","page":"Parameter Optimization","title":"Gen.train!","text":"train!(gen_fn::GenerativeFunction, data_generator::Function,\n       update::ParamUpdate,\n       num_epoch, epoch_size, num_minibatch, minibatch_size; verbose::Bool=false)\n\nTrain the given generative function to maximize the expected conditional log probability (density) that gen_fn generates the assignment constraints given inputs, where the expectation is taken under the output distribution of data_generator.\n\nThe function data_generator is a function of no arguments that returns a tuple (inputs, constraints) where inputs is a Tuple of inputs (arguments) to gen_fn, and constraints is an ChoiceMap.\n\nconf configures the optimization algorithm used.\n\nparam_lists is a map from generative function to lists of its parameters. This is equivalent to minimizing the expected KL divergence from the conditional distribution constraints | inputs of the data generator to the distribution represented by the generative function, where the expectation is taken under the marginal distribution on inputs determined by the data generator.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/vi/#Variational-Inference","page":"Variational Inference","title":"Variational Inference","text":"","category":"section"},{"location":"ref/inference/vi/","page":"Variational Inference","title":"Variational Inference","text":"There are two procedures in the inference library for performing black box variational inference, including amortized variational inference. Each of these procedures can also train the model using stochastic gradient descent, as in a variational autoencoder.","category":"page"},{"location":"ref/inference/vi/#Gen.black_box_vi!","page":"Variational Inference","title":"Gen.black_box_vi!","text":"(elbo_estimate, traces, elbo_history) = black_box_vi!(\n    model::GenerativeFunction, model_args::Tuple,\n    [model_update::ParamUpdate,]\n    observations::ChoiceMap,\n    var_model::GenerativeFunction, var_model_args::Tuple,\n    var_model_update::ParamUpdate;\n    options...)\n\nFit the parameters of a variational model (var_model) to the posterior distribution implied by the given model and observations using stochastic gradient methods. Users may optionally specify a model_update to jointly update the parameters of model.\n\nAdditional arguments:\n\niters=1000: Number of iterations of gradient descent.\nsamples_per_iter=100: Number of samples from the variational and generative       model to accumulate gradients over before a single gradient step.\nverbose=false: If true, print information about the progress of fitting.\ncallback: Callback function that takes (iter, traces, elbo_estimate)       as input, where iter is the iteration number and traces are samples       from var_model for that iteration.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/vi/#Gen.black_box_vimco!","page":"Variational Inference","title":"Gen.black_box_vimco!","text":"(iwelbo_estimate, traces, iwelbo_history) = black_box_vimco!(\n    model::GenerativeFunction, model_args::Tuple,\n    [model_update::ParamUpdate,]\n    observations::ChoiceMap,\n    var_model::GenerativeFunction, var_model_args::Tuple,\n    var_model_update::ParamUpdate,\n    grad_est_samples::Int; options...)\n\nFit the parameters of a variational model (var_model) to the posterior distribution implied by the given model and observations using stochastic gradient methods applied to the Variational Inference with Monte Carlo Objectives (VIMCO) lower bound on the marginal likelihood. Users may optionally specify a model_update to jointly update the parameters of model.\n\nAdditional arguments:\n\ngrad_est_samples::Int: Number of samples for the VIMCO gradient estimate.\niters=1000: Number of iterations of gradient descent.\nsamples_per_iter=100: Number of samples from the variational and generative       model to accumulate gradients over before a single gradient step.\ngeometric=true: Whether to use the geometric or arithmetric baselines       described in Variational Inference with Monte Carlo       Objectives\nverbose=false: If true, print information about the progress of fitting.\ncallback: Callback function that takes (iter, traces, elbo_estimate)       as input, where iter is the iteration number and traces are samples       from var_model for that iteration.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/mcmc_map/#mcmc_map_tutorial","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"This tutorial introduces the basics of writing Markov chain Monte Carlo (MCMC) inference programs in Gen. We also briefly cover maximum a posteriori (MAP) inference, as another kind of iterative inference algorithm.","category":"page"},{"location":"tutorials/mcmc_map/#Linear-Regression-with-Outliers","page":"Basics of MCMC and MAP Inference","title":"Linear Regression with Outliers","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"As an example task, we consider a simple extension of the linear regression problem introduced in previous tutorials: linear regression with outliers. Suppose we have a dataset of points in the xy plane that is mostly explained by a linear relationship, but which also has several outliers. Our goal will be to automatically identify the outliers, and to find a linear relationship (a slope and intercept, as well as an inherent noise level) that explains rest of the points:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"<div style=\"text-align:center\">\n    <img src=\"../../assets/example-inference.png\" alt=\"See https://dspace.mit.edu/bitstream/handle/1721.1/119255/MIT-CSAIL-TR-2018-020.pdf, Figure 2(a)\" width=\"600\"/>\n</div>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"This is a simple inference problem. But it has two features that make it ideal for introducing concepts in modeling and inference. ","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"First, we want not only to estimate the slope and intercept of the line that best fits the data, but also to classify each point as an inlier or outlier; that is, there are a large number of latent variables of interest, enough to make importance sampling an unreliable method (absent a more involved custom proposal that does the heavy lifting). \nSecond, several of the parameters we're estimating (the slope and intercept) are continuous and amenable to gradient-based search techniques, which will allow us to explore Gen's optimization capabilities.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Let's get started!","category":"page"},{"location":"tutorials/mcmc_map/#Writing-the-Model","page":"Basics of MCMC and MAP Inference","title":"Writing the Model","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We begin, as usual, by writing a model: a generative function responsible (conceptually) for simulating a synthetic dataset.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Our model will take as input a vector of x coordinates, and produce as output corresponding y coordinates. ","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We will also use this opportunity to introduce some syntactic sugar. As described in Introduction to Modeling in Gen, random choices in Gen are given addresses using the syntax {addr} ~ distribution(...). But this can be a bit verbose, and often leads to code that looks like the following:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"x = {:x} ~ normal(0, 1)\nslope = {:slope} ~ normal(0, 1)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"In these examples, the variable name is duplicated as the address of the random choice. Because this is a common pattern, Gen provides syntactic sugar that makes it nicer to use:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# Desugars to \"x = {:x} ~ normal(0, 1)\"\nx ~ normal(0, 1)\n# Desugars to \"slope = {:slope} ~ normal(0, 1)\"\nslope ~ normal(0, 1)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Note that sometimes, it is still necessary to use the {...} form, for example in loops:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# INVALID:\nfor i=1:10\n    y ~ normal(0, 1) # The name :y will be used more than once!!\n    println(y)\nend\n\n# VALID:\nfor i=1:10\n    y = {(:y, i)} ~ normal(0, 1) # OK: the address is different each time.\n    println(y)\nend","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We'll use this new syntax for writing our model of linear regression with outliers. As we've seen before, the model generates parameters from a prior, and then simulates data based on those parameters:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"@gen function regression_with_outliers(xs::Vector{<:Real})\n    # First, generate some parameters of the model. We make these\n    # random choices, because later, we will want to infer them\n    # from data. The distributions we use here express our assumptions\n    # about the parameters: we think the slope and intercept won't be\n    # too far from 0; that the noise is relatively small; and that\n    # the proportion of the dataset that don't fit a linear relationship\n    # (outliers) could be anything between 0 and 1.\n    slope ~ normal(0, 2)\n    intercept ~ normal(0, 2)\n    noise ~ gamma(1, 1)\n    prob_outlier ~ uniform(0, 1)\n    \n    # Next, we generate the actual y coordinates.\n    n = length(xs)\n    ys = Float64[]\n    \n    for i = 1:n\n        # Decide whether this point is an outlier, and set\n        # mean and standard deviation accordingly\n        if ({:data => i => :is_outlier} ~ bernoulli(prob_outlier))\n            (mu, std) = (0., 10.)\n        else\n            (mu, std) = (xs[i] * slope + intercept, noise)\n        end\n        # Sample a y value for this point\n        push!(ys, {:data => i => :y} ~ normal(mu, std))\n    end\n    ys\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/#Visualizing-the-Model","page":"Basics of MCMC and MAP Inference","title":"Visualizing the Model","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Let's visualize what our model is doing by drawing some samples from the prior. We'll use the following helper functions.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"<details> <summary>Helper functions for visualization</summary>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function serialize_trace(trace)\n    (xs,) = Gen.get_args(trace)\n    Dict(:slope => trace[:slope],\n         :intercept => trace[:intercept],\n         :inlier_std => trace[:noise],\n         :points => zip(xs, [trace[:data => i => :y] for i in 1:length(xs)]),\n         :outliers => [trace[:data => i => :is_outlier] for i in 1:length(xs)])\nend\n\n\nfunction visualize_trace(trace::Trace; title=\"\")\n    trace = serialize_trace(trace)\n\n    outliers = [pt for (pt, outlier) in zip(trace[:points], trace[:outliers]) if outlier]\n    inliers =  [pt for (pt, outlier) in zip(trace[:points], trace[:outliers]) if !outlier]\n    Plots.scatter(map(first, inliers), map(last, inliers), markercolor=\"blue\", label=nothing, xlims=[-5, 5], ylims=[-20, 20], title=title) \n    Plots.scatter!(map(first, outliers), map(last, outliers), markercolor=\"red\", label=nothing)\n\n    inferred_line(x) = trace[:slope] * x + trace[:intercept]\n    left_x = -5\n    left_y  = inferred_line(left_x)\n    right_x = 5\n    right_y = inferred_line(right_x)\n    Plots.plot!([left_x, right_x], [left_y, right_y], color=\"black\", label=nothing)\n\n    # Inlier noise\n    inlier_std = trace[:inlier_std]\n    noise_points = [(left_x, left_y + inlier_std),\n                    (right_x, right_y + inlier_std),\n                    (right_x, right_y - inlier_std),\n                    (left_x, left_y - inlier_std)]\n    Plots.plot!(Shape(map(first, noise_points), map(last, noise_points)), color=\"black\", alpha=0.2, label=nothing)\n    Plots.plot!(Shape([-5, 5, 5, -5], [10, 10, -10, -10]), color=\"black\", label=nothing, alpha=0.08)\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"</details><br>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We'll use these functions to visualize samples from our model.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# Generate nine traces and visualize them\nxs     = collect(range(-5, stop=5, length=20))\ntraces = [Gen.simulate(regression_with_outliers, (xs,)) for i in 1:9]\nPlots.plot([visualize_trace(t) for t in traces]...)","category":"page"},{"location":"tutorials/mcmc_map/#Legend:","page":"Basics of MCMC and MAP Inference","title":"Legend:","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"red points: outliers;\nblue points: inliers (i.e. regular data);\ndark grey shading: noise associated with inliers; and\nlight grey shading: noise associated with outliers.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Note that an outlier can occur anywhere — including close to the line — and that our model is capable of generating datasets in which the vast majority of points are outliers.","category":"page"},{"location":"tutorials/mcmc_map/#The-Limits-of-Importance-Sampling","page":"Basics of MCMC and MAP Inference","title":"The Limits of Importance Sampling","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"To motivate the need for more complex inference algorithms, let's begin by using the simple importance sampling method from the Introduction to Modeling tutorial, and thinking about where it fails.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"First, let us create a synthetic dataset to do inference about.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function make_synthetic_dataset(n)\n    Random.seed!(1)\n    prob_outlier = 0.2\n    true_inlier_noise = 0.5\n    true_outlier_noise = 5.0\n    true_slope = -1\n    true_intercept = 2\n    xs = collect(range(-5, stop=5, length=n))\n    ys = Float64[]\n    for (i, x) in enumerate(xs)\n        if rand() < prob_outlier\n            y = randn() * true_outlier_noise\n        else\n            y = true_slope * x + true_intercept + randn() * true_inlier_noise\n        end\n        push!(ys, y)\n    end\n    (xs, ys)\nend\n    \n(xs, ys) = make_synthetic_dataset(20)\nPlots.scatter(xs, ys, color=\"black\", xlabel=\"X\", ylabel=\"Y\", \n              label=nothing, title=\"Observations - regular data and outliers\")","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We will to express our observations as a ChoiceMap that constrains the values of certain random choices to equal their observed values. Here, we want to constrain the values of the choices with address :data => i => :y (that is, the sampled y coordinates) to equal the observed y values. Let's write a helper function that takes in a vector of y values and creates a ChoiceMap that we can use to constrain our model:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function make_constraints(ys::Vector{Float64})\n    constraints = Gen.choicemap()\n    for i=1:length(ys)\n        constraints[:data => i => :y] = ys[i]\n    end\n    constraints\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We can apply it to our dataset's vector of ys to make a set of constraints for doing inference:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"observations = make_constraints(ys)\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Now, we use the library function importance_resampling to draw approximate posterior samples given those observations:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function logmeanexp(scores)\n    logsumexp(scores) - log(length(scores))\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"traces    = [first(Gen.importance_resampling(regression_with_outliers, (xs,), observations, 2000)) for i in 1:9]\nlog_probs = [get_score(t) for t in traces]\nprintln(\"Average log probability: $(logmeanexp(log_probs))\")\nPlots.plot([visualize_trace(t) for t in traces]...)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We see here that importance resampling hasn't completely failed: it generally finds a reasonable position for the line. But the details are off: there is little logic to the outlier classification, and the inferred noise around the line is too wide. The problem is that there are just too many variables to get right, and so sampling everything in one go is highly unlikely to produce a perfect hit.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"In the remainder of this tutorial, we'll explore techniques for finding the right solution iteratively, beginning with an initial guess and making many small changes, until we achieve a reasonable posterior sample.","category":"page"},{"location":"tutorials/mcmc_map/#MCMC-Part-1:-Block-Resimulation","page":"Basics of MCMC and MAP Inference","title":"MCMC Part 1: Block Resimulation","text":"","category":"section"},{"location":"tutorials/mcmc_map/#What-is-MCMC?","page":"Basics of MCMC and MAP Inference","title":"What is MCMC?","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Markov Chain Monte Carlo (\"MCMC\") methods are a powerful family of algorithms for iteratively producing approximate samples from a distribution (when applied to Bayesian inference problems, the posterior distribution of unknown (hidden) model variables given data).","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"There is a rich theory behind MCMC methods (see this paper for an introduction), but we focus on applying MCMC in Gen, introducing  theoretical ideas only when necessary for understanding. As we will see, Gen provides abstractions that hide and automate much of the math necessary for implementing MCMC algorithms correctly.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"The general shape of an MCMC algorithm is as follows. We begin by sampling an intial setting of all unobserved variables; in Gen, we produce an initial trace consistent with (but not necessarily probable given) our observations. Then, in a long-running loop, we make small, stochastic changes to the trace; in order for the algorithm to be asymptotically correct, these stochastic updates must satisfy certain probabilistic properties.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"One common way of ensuring that the updates do satisfy those properties is to compute a Metropolis-Hastings acceptance ratio. Essentially, after proposing a change to a trace, we add an \"accept or reject\" step that stochastically decides whether to commit the update or to revert it. This is an over-simplification, but generally speaking, this step ensures we are more likely to accept changes that make our trace fit the observed data better, and to reject ones that make our current trace worse. The algorithm also tries not to go down dead ends: it is more likely to take an exploratory step into a low-probability region if it knows it can easily get back to where it came from.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Gen's metropolis_hastings function automatically adds this \"accept/reject\" check (including the correct computation of the probability of acceptance or rejection), so that inference programmers need only think about what sorts of updates might be useful to propose. Starting in this section, we'll look at several design patterns for MCMC updates, and how to apply them in Gen.","category":"page"},{"location":"tutorials/mcmc_map/#Block-Resimulation","page":"Basics of MCMC and MAP Inference","title":"Block Resimulation","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"One of the simplest strategies we can use is called Resimulation MH, and it works as follows.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We begin, as in most iterative inference algorithms, by sampling an initial trace from our model using the generate API function, fixing the  observed choices to their observed values.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# Gen's `generate` function accepts a model, a tuple of arguments to the model,\n# and a `ChoiceMap` representing observations (or constraints to satisfy). It returns\n# a complete trace consistent with the observations, and an importance weight.  \n# In this call, we ignore the weight returned.\n(tr, _) = generate(regression_with_outliers, (xs,), observations)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Then, in each iteration of our program, we propose changes to all our model's variables in \"blocks,\" by erasing a set of variables from our current trace and resimulating them from the model. After resimulating each block of choices, we perform an accept/reject step, deciding whether the proposed changes are worth making.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# Pseudocode\nfor iter=1:500\n    tr = maybe_update_block_1(tr)\n    tr = maybe_update_block_2(tr)\n    ...\n    tr = maybe_update_block_n(tr)\nend","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"The main design choice in designing a Block Resimulation MH algorithm is how to block the choices together for resimulation. At one extreme, we could put each random choice the model makes in its own block. At the other, we could put all variables into a single block (a strategy sometimes called \"independent\" MH, and which bears a strong similarity to importance resampling, as it involves repeatedly generating completely new traces and deciding whether to keep them or not). Usually, the right thing to do is somewhere in between.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"For the regression problem, here is one possible blocking of choices:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Block 1: slope, intercept, and noise. These parameters determine the linear relationship; resimulating them is like picking a new line. We know from our importance sampling experiment above that before too long, we're bound to sample something close to the right line.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Blocks 2 through N+1: Each is_outlier, in its own block. One problem we saw with importance sampling in this problem was that it tried to sample every outlier classification at once, when in reality the chances of a single sample that correctly classifies all the points are very low. Here, we can choose to resimulate each is_outlier choice separately, and for each one, decide whether to use the resimulated value or not.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Block N+2: prob_outlier. Finally, we can propose a new prob_outlier value; in general, we can expect to accept the proposal when it is in line  with the current hypothesized proportion of is_outlier choices that are  set to true.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Resimulating a block of variables is the simplest form of update that Gen's metropolis_hastings operator (or mh for short) supports. When supplied with a current trace and a selection of trace addresses to resimulate, mh performs the resimulation and the appropriate accept/reject check, then returns a possibly updated trace, along with a Boolean indicating whether the  update was accepted or not. A selection is created using the select method. So a single update of the scheme we proposed above would look like this:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# Perform a single block resimulation update of a trace.\nfunction block_resimulation_update(tr)\n    # Block 1: Update the line's parameters\n    line_params = select(:noise, :slope, :intercept)\n    (tr, _) = mh(tr, line_params)\n    \n    # Blocks 2-N+1: Update the outlier classifications\n    (xs,) = get_args(tr)\n    n = length(xs)\n    for i=1:n\n        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n    end\n    \n    # Block N+2: Update the prob_outlier parameter\n    (tr, _) = mh(tr, select(:prob_outlier))\n    \n    # Return the updated trace\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"All that's left is to (a) obtain an initial trace, and then (b) run that update in a loop for as long as we'd like:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function block_resimulation_inference(xs, ys, observations)\n    observations = make_constraints(ys)\n    (tr, _) = generate(regression_with_outliers, (xs,), observations)\n    for iter=1:500\n        tr = block_resimulation_update(tr)\n    end\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Let's test it out:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"scores = Vector{Float64}(undef, 10)\nfor i=1:10\n    @time tr = block_resimulation_inference(xs, ys, observations)\n    scores[i] = get_score(tr)\nend\nprintln(\"Log probability: \", logmeanexp(scores))","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We note that this is significantly better than importance sampling, even if we run importance sampling for about the same amount of (wall-clock) time per sample:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"scores = Vector{Float64}(undef, 10)\nfor i=1:10\n    @time (tr, _) = importance_resampling(regression_with_outliers, (xs,), observations, 17000)\n    scores[i] = get_score(tr)\nend\nprintln(\"Log probability: \", logmeanexp(scores))","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"It's one thing to see a log probability increase; it's better to understand what the inference algorithm is actually doing, and to see why it's doing better.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"A great tool for debugging and improving MCMC algorithms is visualization. We can use Plots.@animate to produce an animated visualization:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"t, = generate(regression_with_outliers, (xs,), observations)\n\nviz = Plots.@animate for i in 1:500\n    global t\n    t = block_resimulation_update(t)\n    visualize_trace(t; title=\"Iteration $i/500\")\nend\ngif(viz)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We can see that although the algorithm keeps changing the inferences of which points are inliers and outliers,  it has a harder time refining the continuous parameters. We address this challenge next.","category":"page"},{"location":"tutorials/mcmc_map/#MCMC-Part-2:-Gaussian-Drift-MH","page":"Basics of MCMC and MAP Inference","title":"MCMC Part 2: Gaussian Drift MH","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"So far, we've seen one form of incremental trace update:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"(tr, did_accept) = mh(tr, select(:address1, :address2, ...))","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"This update is incremental in that it only proposes changes to part of a trace (the selected addresses). But when computing what changes to propose, it ignores the current state completely and resimulates all-new values from the model.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"That wholesale resimulation of values is often not the best way to search for improvements. To that end, Gen also offers a more general flavor of MH:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"(tr, did_accept) = mh(tr, custom_proposal, custom_proposal_args)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"A \"custom proposal\" is just what it sounds like: whereas before, we were using the default resimulation proposal to come up with new values for the selected addresses, we can now pass in a generative function that samples proposed values however it wants.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"For example, here is a custom proposal that takes in a current trace, and proposes a new slope and intercept by randomly perturbing the existing values:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"@gen function line_proposal(current_trace)\n    slope ~ normal(current_trace[:slope], 0.5)\n    intercept ~ normal(current_trace[:intercept], 0.5)\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"This is often called a \"Gaussian drift\" proposal, because it essentially amounts to proposing steps of a random walk. (What makes it different from a random walk is that we will still use an MH accept/reject step to make sure we don't wander into areas of very low probability.)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"To use the proposal, we write:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"(tr, did_accept) = mh(tr, line_proposal, ())","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Two things to note:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We no longer need to pass a selection of addresses. Instead, Gen assumes that whichever addresses are sampled by the proposal (in this case, :slope and :intercept) are being proposed to.\nThe argument list to the proposal is an empty tuple, (). The line_proposal generative function does expect an argument, the previous trace, but this is supplied automatically to all MH custom proposals (a proposal generative function for use with mh must take as its first argument the current trace of the model).","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Let's swap it into our update:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function gaussian_drift_update(tr)\n    # Gaussian drift on line params\n    (tr, _) = mh(tr, line_proposal, ())\n    \n    # Block resimulation: Update the outlier classifications\n    (xs,) = get_args(tr)\n    n = length(xs)\n    for i=1:n\n        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n    end\n    \n    # Block resimulation: Update the prob_outlier parameter\n    (tr, w) = mh(tr, select(:prob_outlier))\n    (tr, w) = mh(tr, select(:noise))\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"If we compare the Gaussian Drift proposal visually with our old algorithm, we can see the new behavior:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"tr1, = generate(regression_with_outliers, (xs,), observations)\ntr2 = tr1\n\nviz = Plots.@animate for i in 1:300\n    global tr1, tr2\n    tr1 = gaussian_drift_update(tr1)\n    tr2 = block_resimulation_update(tr2)\n    Plots.plot(visualize_trace(tr1; title=\"Drift Kernel (Iter $i)\"), \n               visualize_trace(tr2; title=\"Resim Kernel (Iter $i)\"))\nend\ngif(viz)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/#Exercise:-Analyzing-the-algorithms","page":"Basics of MCMC and MAP Inference","title":"Exercise: Analyzing the algorithms","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Run the cell above several times. Compare the two algorithms with respect to the following:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"How fast do they find a relatively good line?\nDoes one of them tend to get stuck more than the other? Under what conditions? Why?","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"A more quantitative comparison demonstrates that our change has improved our inference quality:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function gaussian_drift_inference(xs, observations)\n    (tr, _) = generate(regression_with_outliers, (xs,), observations)\n    for iter=1:500\n        tr = gaussian_drift_update(tr)\n    end\n    tr\nend\n\nscores = Vector{Float64}(undef, 10)\nfor i=1:10\n    @time tr = gaussian_drift_inference(xs, observations)\n    scores[i] = get_score(tr)\nend\nprintln(\"Log probability: \", logmeanexp(scores))","category":"page"},{"location":"tutorials/mcmc_map/#MCMC-Part-3:-Heuristic-Guidance","page":"Basics of MCMC and MAP Inference","title":"MCMC Part 3: Heuristic Guidance","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"In this section, we'll look at another strategy for improving MCMC inference: using arbitrary heuristics to make smarter proposals. In particular, we'll use a method called \"Random Sample Consensus\" (or RANSAC) to quickly find promising settings of the slope and intercept parameters.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"RANSAC works as follows:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We repeatedly choose a small random subset of the points, say, of size 3.\nWe do least-squares linear regression to find a line of best fit for those points.\nWe count how many points (from the entire set) are near the line we found.\nAfter a suitable number of iterations (say, 10), we return the line that had the highest score.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Here's our implementation of the algorithm in Julia:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"import StatsBase\n\nstruct RANSACParams\n    \"\"\"the number of random subsets to try\"\"\"\n    iters::Int\n\n    \"\"\"the number of points to use to construct a hypothesis\"\"\"\n    subset_size::Int\n\n    \"\"\"the error threshold below which a datum is considered an inlier\"\"\"\n    eps::Float64\n    \n    function RANSACParams(iters, subset_size, eps)\n        if iters < 1\n            error(\"iters < 1\")\n        end\n        new(iters, subset_size, eps)\n    end\nend\n\nfunction ransac(xs::Vector{Float64}, ys::Vector{Float64}, params::RANSACParams)\n    best_num_inliers::Int = -1\n    best_slope::Float64 = NaN\n    best_intercept::Float64 = NaN\n    for i=1:params.iters\n        # select a random subset of points\n        rand_ind = StatsBase.sample(1:length(xs), params.subset_size, replace=false)\n        subset_xs = xs[rand_ind]\n        subset_ys = ys[rand_ind]\n        \n        # estimate slope and intercept using least squares\n        A = hcat(subset_xs, ones(length(subset_xs)))\n        slope, intercept = A \\ subset_ys # use backslash operator for least sq soln\n        \n        ypred = intercept .+ slope * xs\n\n        # count the number of inliers for this (slope, intercept) hypothesis\n        inliers = abs.(ys - ypred) .< params.eps\n        num_inliers = sum(inliers)\n\n        if num_inliers > best_num_inliers\n            best_slope, best_intercept = slope, intercept\n            best_num_inliers = num_inliers\n        end\n    end\n\n    # return the hypothesis that resulted in the most inliers\n    (best_slope, best_intercept)\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We can now wrap it in a Gen proposal that calls out to RANSAC, then samples a slope and intercept near the one it proposed.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"@gen function ransac_proposal(prev_trace, xs, ys)\n    (slope_guess, intercept_guess) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n    slope ~ normal(slope_guess, 0.1)\n    intercept ~ normal(intercept_guess, 1.0)\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"(Notice that although ransac makes random choices, they are not addressed (and they happen outside of a Gen generative function), so Gen cannot reason about them. This is OK (see [1]). Writing proposals that have traced internal randomness (i.e., that make traced random choices that are not directly used in the proposal) can lead to better inference, but requires the use of a more complex version of Gen's mh operator, which is beyond the scope of this tutorial.)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"[1] Using probabilistic programs as proposals, Marco F. Cusumano-Towner, Vikash K. Mansinghka, 2018.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"One iteration of our update algorithm will now look like this:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function ransac_update(tr)\n    # Use RANSAC to (potentially) jump to a better line\n    # from wherever we are\n    (tr, _) = mh(tr, ransac_proposal, (xs, ys))\n    \n    # Spend a while refining the parameters, using Gaussian drift\n    # to tune the slope and intercept, and resimulation for the noise\n    # and outliers.\n    for j=1:20\n        (tr, _) = mh(tr, select(:prob_outlier))\n        (tr, _) = mh(tr, select(:noise))\n        (tr, _) = mh(tr, line_proposal, ())\n        # Reclassify outliers\n        for i=1:length(get_args(tr)[1])\n            (tr, _) = mh(tr, select(:data => i => :is_outlier))\n        end\n    end\n    tr\nend","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We can now run our main loop for just 5 iterations, and achieve pretty good results. (Of course, since we do 20 inner loop iterations in ransac_update, this is really closer to 100 iterations.) The running time is significantly less than before, without a real dip in quality:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function ransac_inference(xs, ys, observations)\n    (slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n    slope_intercept_init = choicemap()\n    slope_intercept_init[:slope] = slope\n    slope_intercept_init[:intercept] = intercept\n    (tr, _) = generate(regression_with_outliers, (xs,), merge(observations, slope_intercept_init))\n    for iter=1:5\n        tr = ransac_update(tr)\n    end\n    tr\nend\n\nscores = Vector{Float64}(undef, 10)\nfor i=1:10\n    @time tr = ransac_inference(xs, ys, observations)\n    scores[i] = get_score(tr)\nend\nprintln(\"Log probability: \", logmeanexp(scores))","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Let's visualize the algorithm:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"(slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\nslope_intercept_init = choicemap()\nslope_intercept_init[:slope] = slope\nslope_intercept_init[:intercept] = intercept\n(tr, _) = generate(regression_with_outliers, (xs,), merge(observations, slope_intercept_init))\n\nviz = Plots.@animate for i in 1:100\n    global tr\n\n    if i % 20 == 0\n        (tr, _) = mh(tr, ransac_proposal, (xs, ys))\n    end\n\n    # Spend a while refining the parameters, using Gaussian drift\n    # to tune the slope and intercept, and resimulation for the noise\n    # and outliers.\n    (tr, _) = mh(tr, select(:prob_outlier))\n    (tr, _) = mh(tr, select(:noise))\n    (tr, _) = mh(tr, line_proposal, ())\n    \n    # Reclassify outliers\n    for i=1:length(get_args(tr)[1])\n        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n    end\n\n    visualize_trace(tr; title=\"Iteration $i\")\nend\ngif(viz)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/#Exercise","page":"Basics of MCMC and MAP Inference","title":"Exercise","text":"","category":"section"},{"location":"tutorials/mcmc_map/#Improving-the-heuristic","page":"Basics of MCMC and MAP Inference","title":"Improving the heuristic","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Currently, the RANSAC heuristic does not use the current trace's information at all. Try changing it to use the current state as follows: Instead of a constant eps parameter that controls whether a point is considered an inlier, make this decision based on the currently hypothesized noise level.  Specifically, set eps to be equal to the noise parameter of the trace.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Examine whether this improves inference.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"# Modify the function below (which currently is just a copy of `ransac_proposal`) \n# as described above so that implements a RANSAC proposal with inlier \n# status decided by the noise parameter of the previous trace\n# (do not modify the return value, which is unneccessary for a proposal, \n# but used for testing)\n\n@gen function ransac_proposal_noise_based(prev_trace, xs, ys)\n    params = RANSACParams(10, 3, 1.)\n    (slope_guess, intercept_guess) = ransac(xs, ys, params)\n    slope ~ normal(slope_guess, 0.1)\n    intercept ~ normal(intercept_guess, 1.0)\n    return params, slope, intercept # (return values just for testing)\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"<details> <summary>Solution</summary>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"@gen function ransac_proposal_noise_based(prev_trace, xs, ys)\n    eps = prev_trace[:noise]\n    params = RANSACParams(10, 3, eps)\n    (slope_guess, intercept_guess) = ransac(xs, ys, params)\n    slope ~ normal(slope_guess, 0.1)\n    intercept ~ normal(intercept_guess, 1.0)\n    return params, slope, intercept # (return values just for testing)\nend","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"</details>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"The code below runs the RANSAC inference as above, but using ransac_proposal_noise_based.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function ransac_update_noise_based(tr)\n    # Use RANSAC to (potentially) jump to a better line\n    (tr, _) = mh(tr, ransac_proposal_noise_based, (xs, ys))\n    # Refining the parameters\n    for j=1:20\n        (tr, _) = mh(tr, select(:prob_outlier))\n        (tr, _) = mh(tr, select(:noise))\n        (tr, _) = mh(tr, line_proposal, ())\n        # Reclassify outliers\n        for i=1:length(get_args(tr)[1])\n            (tr, _) = mh(tr, select(:data => i => :is_outlier))\n        end\n    end\n    tr\nend\nfunction ransac_inference_noise_based(xs, ys, observations)\n    # Use an initial epsilon value of 1.\n    (slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n    slope_intercept_init = choicemap()\n    slope_intercept_init[:slope] = slope\n    slope_intercept_init[:intercept] = intercept\n    (tr, _) = generate(regression_with_outliers, (xs,), merge(observations, slope_intercept_init))\n    for iter=1:5\n        tr = ransac_update_noise_based(tr)\n    end\n    tr\nend\n\nscores = Vector{Float64}(undef, 10)\nfor i=1:10\n    @time tr = ransac_inference_noise_based(xs, ys, observations)\n    scores[i] = get_score(tr)\nend\nprintln(\"Log probability: \", logmeanexp(scores))","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/#Exercise-2","page":"Basics of MCMC and MAP Inference","title":"Exercise","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Implement a heuristic-based proposal that selects the points that are currently classified as inliers, finds the line of best fit for this  subset of points, and adds some noise.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Hint: you can get the result for linear regression using least squares approximation by solving a linear system using Julia's backslash operator, \\ (as is done in the ransac function, above). ","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"We provide some starter code. You can test your solution by modifying the plotting code above.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"@gen function inlier_heuristic_proposal(prev_trace, xs, ys)\n    # Put your code below, ensure that you compute values for\n    # inlier_slope, inlier_intercept and delete the two placeholders\n    # below.\n     \n    inlier_slope = 10000. # <delete -- placeholders>\n    inlier_intercept = 10000. # <delete -- placeholder>\n    \n    \n    # Make a noisy proposal.\n    slope     ~ normal(inlier_slope, 0.5)\n    intercept ~ normal(inlier_intercept, 0.5)\n    # We return values here for testing; normally, proposals don't have to return values.\n    return inlier_slope, inlier_intercept\nend\n\nfunction inlier_heuristic_update(tr)\n    # Use inlier heuristics to (potentially) jump to a better line\n    # from wherever we are.\n    (tr, _) = mh(tr, inlier_heuristic_proposal, (xs, ys))    \n    # Spend a while refining the parameters, using Gaussian drift\n    # to tune the slope and intercept, and resimulation for the noise\n    # and outliers.\n    for j=1:20\n        (tr, _) = mh(tr, select(:prob_outlier))\n        (tr, _) = mh(tr, select(:noise))\n        (tr, _) = mh(tr, line_proposal, ())\n        # Reclassify outliers\n        for i=1:length(get_args(tr)[1])\n            (tr, _) = mh(tr, select(:data => i => :is_outlier))\n        end\n    end\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"tr, = Gen.generate(regression_with_outliers, (xs,), observations)\nviz = @animate for i in 1:50\n    global tr\n    tr = inlier_heuristic_update(tr)\n    visualize_trace(tr; title=\"Iteration $i\")\nend\ngif(viz)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"<details> <summary>Solution</summary>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"@gen function inlier_heuristic_proposal(prev_trace, xs, ys)\n    # get_indeces for inliers.\n    inlier_indeces = filter(\n        i -> !prev_trace[:data => i => :is_outlier], \n        1:length(xs)\n    )\n    xs_inlier = xs[inlier_indeces]\n    ys_inlier = ys[inlier_indeces]\n    # estimate slope and intercept using least squares.\n    A = hcat(xs_inlier, ones(length(xs_inlier)))\n    inlier_slope, inlier_intercept = A \\ ys_inlier\n    \n    # Make a noisy proposal.\n    slope     ~ normal(inlier_slope, 0.5)\n    intercept ~ normal(inlier_intercept, 0.5)\n    # We return values here for testing; normally, proposals don't have to return values.\n    return inlier_slope, inlier_intercept\nend;\n\nfunction inlier_heuristic_update(tr)\n    # Use inlier heuristics to (potentially) jump to a better line\n    # from wherever we are.\n    (tr, _) = mh(tr, inlier_heuristic_proposal, (xs, ys))    \n    # Spend a while refining the parameters, using Gaussian drift\n    # to tune the slope and intercept, and resimulation for the noise\n    # and outliers.\n    for j=1:20\n        (tr, _) = mh(tr, select(:prob_outlier))\n        (tr, _) = mh(tr, select(:noise))\n        (tr, _) = mh(tr, line_proposal, ())\n        # Reclassify outliers\n        for i=1:length(get_args(tr)[1])\n            (tr, _) = mh(tr, select(:data => i => :is_outlier))\n        end\n    end\n    tr\nend","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"</details>","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/#Exercise:-Initialization","page":"Basics of MCMC and MAP Inference","title":"Exercise: Initialization","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"In our inference program above, when generating an initial trace on which to iterate, we initialize the slope and intercept to values proposed by RANSAC. If we don't do this, the performance decreases sharply, despite the fact that we still propose new slope/intercept pairs from RANSAC once the loop starts. Why is this?","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/#MAP-Optimization","page":"Basics of MCMC and MAP Inference","title":"MAP Optimization","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Everything we've done so far has been within the MCMC framework. But sometimes you're not interested in getting posterior samples—sometimes you just want a single likely explanation for your data. Gen also provides tools for maximum a posteriori estimation (\"MAP estimation\"), the problem of finding a trace that maximizes the posterior probability under the model given observations.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"For example, let's say we wanted to take a trace and assign each point's is_outlier score to the most likely possibility. We can do this by iterating over both possible traces, scoring them, and choosing the one with the higher score. We can do this using Gen's update function, which allows us to manually update a trace to satisfy some constraints:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function is_outlier_map_update(tr)\n    (xs,) = get_args(tr)\n    for i=1:length(xs)\n        constraints = choicemap(:prob_outlier => 0.1)\n        constraints[:data => i => :is_outlier] = false\n        (trace1,) = update(tr, (xs,), (NoChange(),), constraints)\n        constraints[:data => i => :is_outlier] = true\n        (trace2,) = update(tr, (xs,), (NoChange(),), constraints)\n        tr = (get_score(trace1) > get_score(trace2)) ? trace1 : trace2\n    end\n    tr\nend\nnothing # hide","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"For continuous parameters, we can use Gen's map_optimize function, which uses automatic differentiation to shift the selected parameters in the direction that causes the probability of the trace to increase most sharply:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"tr = map_optimize(tr, select(:slope, :intercept), max_step_size=1., min_step_size=1e-5)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Putting these updates together, we can write an inference program that uses our RANSAC algorithm from above to get an initial trace, then tunes it using optimization:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"using StatsBase: mean\n\n(slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\nslope_intercept_init = choicemap()\nslope_intercept_init[:slope] = slope\nslope_intercept_init[:intercept] = intercept\n(tr,) = generate(regression_with_outliers, (xs,), merge(observations, slope_intercept_init))\n\n\nransac_score, final_score = 0, 0\nviz = Plots.@animate for i in 1:35\n    global tr, ransac_score\n    if i < 6\n        tr = ransac_update(tr)\n    else\n        tr = map_optimize(tr, select(:slope, :intercept), max_step_size=1., min_step_size=1e-5)\n        tr = map_optimize(tr, select(:noise), max_step_size=1e-2, min_step_size=1e-5)\n        tr = is_outlier_map_update(tr)\n        optimal_prob_outlier = mean([tr[:data => i => :is_outlier] for i in 1:length(xs)])\n        optimal_prob_outlier = min(0.5, max(0.05, optimal_prob_outlier))\n        tr, = update(tr, (xs,), (NoChange(),), choicemap(:prob_outlier => optimal_prob_outlier))\n    end\n    \n    if i == 5\n        ransac_score = get_score(tr)\n    end\n    \n    visualize_trace(tr; title=\"Iteration $i $(i < 6 ? \"(RANSAC init)\" : \"(MAP optimization)\")\")\nend\nfinal_score = get_score(tr)\n\nprintln(\"Score after ransac: $(ransac_score). Final score: $(final_score).\")\ngif(viz)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Below, we evaluate the algorithm and we see that it gets our best scores yet, which is what it's meant to do:","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function map_inference(xs, ys, observations)\n    (slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n    slope_intercept_init = choicemap()\n    slope_intercept_init[:slope] = slope\n    slope_intercept_init[:intercept] = intercept\n    (tr, _) = generate(regression_with_outliers, (xs,), merge(observations, slope_intercept_init))\n    for iter=1:5\n        tr = ransac_update(tr)\n    end\n    \n    for iter = 1:20\n        # Take a single gradient step on the line parameters.\n        tr = map_optimize(tr, select(:slope, :intercept), max_step_size=1., min_step_size=1e-5)\n        tr = map_optimize(tr, select(:noise), max_step_size=1e-2, min_step_size=1e-5)\n        \n        # Choose the most likely classification of outliers.\n        tr = is_outlier_map_update(tr)\n        \n        # Update the prob outlier\n        choices = get_choices(tr)\n        optimal_prob_outlier = count(i -> choices[:data => i => :is_outlier], 1:length(xs)) / length(xs)\n        optimal_prob_outlier = min(0.5, max(0.05, optimal_prob_outlier))\n        (tr, _) = update(tr, (xs,), (NoChange(),), choicemap(:prob_outlier => optimal_prob_outlier))        \n    end\n    tr\nend\n\nscores = Vector{Float64}(undef, 10)\nfor i=1:10\n    @time tr = map_inference(xs,ys,observations)\n    scores[i] = get_score(tr)\nend\nprintln(logmeanexp(scores))","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"This doesn't necessarily mean that it's \"better,\" though. It finds the most probable explanation of the data, which is a different problem from the one we tackled with MCMC inference. There, the goal was to sample from the posterior, which allows us to better characterize our uncertainty. Using MCMC, there might be a borderline point that is sometimes classified as an outlier and sometimes not, reflecting our uncertainty; with MAP optimization, we will always be shown the most probable answer.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Below we generate a dataset for which there are two distinct possible explanations (the grey lines) under our model regression_with_outliers. ","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"function make_bimodal_dataset(n)\n    Random.seed!(4) \n    prob_outlier = 0.2\n    true_inlier_noise = 0.5\n    true_outlier_noise = 5.0\n    true_slope1 = 1\n    true_intercept1 = 0\n    true_slope2 = -2/3\n    true_intercept2 = 0\n    xs = collect(range(-5, stop=5, length=n))\n    ys = Float64[]\n    for (i, x) in enumerate(xs)\n        if rand() < prob_outlier\n            y = randn() * true_outlier_noise\n        else\n            if rand((true,false))\n                y = true_slope1 * x + true_intercept1 + randn() * true_inlier_noise\n            else\n                y = true_slope2 * x + true_intercept2 + randn() * true_inlier_noise\n            end\n        end\n        push!(ys, y)\n    end\n    xs,ys,true_slope1,true_slope2,true_intercept1,true_intercept2\nend\n\n(xs, ys_bimodal, m1,m2,b1,b2) = make_bimodal_dataset(20)\nobservations_bimodal = make_constraints(ys_bimodal)\n\nPlots.scatter(xs, ys_bimodal, color=\"black\", xlabel=\"X\", ylabel=\"Y\", label=nothing, title=\"Bimodal data\")\nPlots.plot!(xs,m1.*xs.+b1, color=\"blue\", label=nothing)\nPlots.plot!(xs,m2.*xs.+b2, color=\"green\", label=nothing)","category":"page"},{"location":"tutorials/mcmc_map/#Exercise-3","page":"Basics of MCMC and MAP Inference","title":"Exercise","text":"","category":"section"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"For this dataset, the code below will run (i) Metropolis hastings with a Gaussian Drift proposal and (ii) MAP optimization, using implementations from above. Make sure you understand what it is doing. Do both algorithms explore both modes (i.e. both possible explanations)?  Play with running the algorithms multiple times.  ","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"If one or both algorithms doesn't then explain in a few sentences why you think this is.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"(slope, intercept) = ransac(xs, ys_bimodal, RANSACParams(10, 3, 1.))\nslope_intercept_init = choicemap()\nslope_intercept_init[:slope] = slope\nslope_intercept_init[:intercept] = intercept\n(tr,) = generate(\n    regression_with_outliers, (xs,), \n    merge(observations_bimodal, slope_intercept_init))\n\ntr_drift = tr\ntr_map   = tr\n\nviz = Plots.@animate for i in 1:305\n    global tr_map, tr_drift\n    if i < 6\n        tr_drift = ransac_update(tr)\n        tr_map   = tr_drift\n    else\n        # Take a single gradient step on the line parameters.\n        tr_map = map_optimize(tr_map, select(:slope, :intercept), max_step_size=1., min_step_size=1e-5)\n        tr_map = map_optimize(tr_map, select(:noise), max_step_size=1e-2, min_step_size=1e-5)\n        # Choose the most likely classification of outliers.\n        tr_map = is_outlier_map_update(tr_map)\n        # Update the prob outlier\n        optimal_prob_outlier = mean([tr_map[:data => i => :is_outlier] for i in 1:length(xs)])\n        optimal_prob_outlier = min(0.5, max(0.05, optimal_prob_outlier))\n        tr_map, = update(tr_map, (xs,), (NoChange(),), choicemap(:prob_outlier => optimal_prob_outlier))\n    \n        # Gaussian drift update:\n        tr_drift = gaussian_drift_update(tr_drift)\n    end\n    \n    Plots.plot(visualize_trace(tr_drift; title=\"Drift (Iter $i)\"), visualize_trace(tr_map; title=\"MAP (Iter $i)\"))\nend\n\ndrift_final_score = get_score(tr_drift)\nmap_final_score = get_score(tr_map)\nprintln(\"i.   MH Gaussian drift score $(drift_final_score)\")\nprintln(\"ii.  MAP final score: $(final_score).\")\n\ngif(viz)","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"The above was good for an overall qualitative examination, but let's also  examine a little more quantitatively how often the two proposals explore the two modes, by running multiple times and keeping track of how often the slope is positive/negative for each, for a few different initializations.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Warning: the following cell may take a few minutes to run.","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"total_runs = 25\n\nfor (index, value) in enumerate([(1, 0), (-1, 0), ransac(xs, ys_bimodal, RANSACParams(10, 3, 1.))])\n    n_pos_drift = n_neg_drift = n_pos_map = n_neg_map = 0\n    \n    for i=1:total_runs\n        pos_drift = neg_drift = pos_map = neg_map = false\n\n        #### RANSAC for initializing\n        (slope, intercept) = value # ransac(xs, ys_bimodal, RANSACParams(10, 3, 1.))\n        slope_intercept_init = choicemap()\n        slope_intercept_init[:slope] = slope\n        slope_intercept_init[:intercept] = intercept\n        (tr,) = generate(\n            regression_with_outliers, (xs,), \n            merge(observations_bimodal, slope_intercept_init))\n        for iter=1:5\n            tr = ransac_update(tr)\n        end\n        ransac_score = get_score(tr)\n        tr_drift = tr # version of the trace for the Gaussian drift algorithm\n        tr_map = tr   # version of the trace for the MAP optimization\n\n        #### Refine the parameters according to each of the algorithms\n        for iter = 1:300\n            # MAP optimiztion:\n            # Take a single gradient step on the line parameters.\n            tr_map = map_optimize(tr_map, select(:slope, :intercept), max_step_size=1., min_step_size=1e-5)\n            tr_map = map_optimize(tr_map, select(:noise), max_step_size=1e-2, min_step_size=1e-5)\n            # Choose the most likely classification of outliers.\n            tr_map = is_outlier_map_update(tr_map)\n            # Update the prob outlier\n            optimal_prob_outlier = count(i -> tr_map[:data => i => :is_outlier], 1:length(xs)) / length(xs)\n            optimal_prob_outlier = min(0.5, max(0.05, optimal_prob_outlier))\n            (tr_map, _) = update(tr_map, (xs,), (NoChange(),), choicemap(:prob_outlier => optimal_prob_outlier))\n\n            # Gaussian drift update:\n            tr_drift = gaussian_drift_update(tr_drift)\n\n            if tr_drift[:slope] > 0\n                pos_drift = true\n            elseif tr_drift[:slope] < 0\n                neg_drift = true\n            end\n            if tr_map[:slope] > 0\n                pos_map = true  \n            elseif tr_map[:slope] < 0\n                neg_map = true\n            end\n        end\n\n        if pos_drift\n            n_pos_drift += 1\n        end\n        if neg_drift\n            n_neg_drift += 1\n        end\n        if pos_map\n            n_pos_map += 1\n        end\n        if neg_map\n            n_neg_map += 1\n        end\n    end\n    (slope, intercept) = value\n    println(\"\\n\\nWITH INITIAL SLOPE $(slope) AND INTERCEPT $(intercept)\")\n    println(\"TOTAL RUNS EACH: $(total_runs)\")\n    println(\"\\n       times neg. slope    times pos. slope\")\n    println(\"\\ndrift: $(n_neg_drift)                  $(n_pos_drift)\")\n    println(\"\\nMAP:   $(n_neg_map)                    $(n_pos_map)\")\nend","category":"page"},{"location":"tutorials/mcmc_map/","page":"Basics of MCMC and MAP Inference","title":"Basics of MCMC and MAP Inference","text":"Although this experiment is imperfect, we can broadly see that the drift kernel often explores both modes within a single run, whereas this is rarer for the MAP kernel (in 25 runs, the MAP kernel visits on average 1.08 of the 2 modes, whereas the drift kernel visits 1.6).","category":"page"},{"location":"tutorials/learning_gen_fns/#learning_gen_fns_tutorial","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Learning and inference are closely related concepts, and the distinction between the two is not always clear. Often, learning refers to inferring long-lived unobserved quantities that will be reused across many problem instances (like a dynamics model for an entity that we are trying to track), whereas inference refers to inferring shorter-lived quantities (like a specific trajectory of a specific entity). Learning is the way to use data to automatically generate models of the world, or to automatically fill in unknown parameters in hand-coded models. These resulting models are then used in various inference tasks.","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"There are many variants of the learning task–we could be training the weights of a neural network, estimating a handful of parameters in a structured and hand-coded model, or we could be learning the structure or architecture of a model. Also, we could do Bayesian learning in which we seek a probability distribution on possible models, or we could seek just the best model, as measured by e.g. maximum likelihood. This section focuses on maximum likelihood learning of the Trainable parameters of a generative function. These are numerical quantities that are part of the generative function's state, with respect to which generative functions are able to report gradients of their (log) probability density function of their density function. Trainable parameters are different from random choices–random choices are per-trace and trainable parameters are a property of the generative function (which is associated with many traces). Also, unlike random choices, trainable parameters do not have a prior distribution.","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"There are two settings in which we might learn these parameters using maximum likelihood. If our observed data contains values for all of the random choices made by the generative function, this is called learning from complete data, and is a relatively straightforward task. If our observed data is missing values for some random choices (either because the value happened to be missing, or because it was too expensive to acquire it, or because it is an inherently unmeasurable quantity), this is called learning from incomplete data, and is a substantially harder task. Gen provides programming primitives and design patterns for both tasks. In both cases, the models we are learning can be either generative or discriminative.","category":"page"},{"location":"tutorials/learning_gen_fns/#Learning-from-Complete-Data","page":"Learning Generative Functions","title":"Learning from Complete Data","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"This section discusses maximizing the log likelihood of observed data over the space of trainable parameters, when all of the random variables are observed. In Gen, the likelihood of complete data is simply the joint probability (density) of a trace, and maximum likelihood with complete data amounts to maximizing the sum of log joint probabilities of a collection of traces t_i for i = 1ldots N with respect to the trainable parameters of the generative function, which are denoted theta.","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"max_theta sum_i=1^N log p(t_i x theta)","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"For example, here is a simple generative model that we might want to learn:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"@gen function model()\n    @param x_mu::Float64\n    @param a::Float64\n    @param b::Float64\n    x = @trace(normal(x_mu, 1.), :x)\n    @trace(normal(a * x + b, 1.), :y)\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"There are three components to theta for this generative function: (x_mu, a, b).","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Note that maximum likelihood can be used to learn generative and discriminative models, but for discriminative models, the arguments to the generative function will be different for each training example:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"max_theta sum_i=1^N log p(t_i x_i theta)","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Here is a minimal discriminative model:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"@gen function disc_model(x::Float64)\n    @param a::Float64\n    @param b::Float64\n    @trace(normal(a * x + b, 1.), :y)\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Let's suppose we are training the generative model. The first step is to initialize the values of the trainable parameters, which for generative functions constructed using the built-in modeling languages, we do with init_param!:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"init_param!(model, :a, 0.)\ninit_param!(model, :b, 0.)","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Each trace in the collection contains the observed data from an independent draw from our model. We can populate each trace with its observed data using generate:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"traces = []\nfor observations in data\n    trace, = generate(model, model_args, observations)\n    push!(traces, trace)\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"For the complete data case, we assume that all random choices in the model are constrained by the observations choice map (we will analyze the case when not all random choices are constrained in the next section). We can evaluate the objective function by summing the result of get_score over our collection of traces:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"objective = sum([get_score(trace) for trace in traces])","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"We can compute the gradient of this objective function with respect to the trainable parameters using accumulate_param_gradients!:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"for trace in traces\n    accumulate_param_gradients!(trace)\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Finally, we can construct and gradient-based update with ParamUpdate and apply it with apply!. We can put this all together into a function:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"function train_model(data::Vector{ChoiceMap})\n    init_param!(model, :theta, 0.1)\n    traces = []\n    for observations in data\n        trace, = generate(model, model_args, observations)\n        push!(traces, trace)\n    end\n    update = ParamUpdate(FixedStepGradientDescent(0.001), model)\n    for iter=1:max_iter\n        objective = sum([get_score(trace) for trace in traces])\n        println(\"objective: $objective\")\n        for trace in traces\n            accumulate_param_gradients!(trace)\n        end\n        apply!(update)\n    end\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Note that using the same primitives (generate and accumulate_param_gradients!), you can compose various more sophisticated learning algorithms involving e.g. stochastic gradient descent and minibatches, and more sophisticated stochastic gradient optimizers like ADAM. For example, train! trains a generative function from complete data with minibatches.","category":"page"},{"location":"tutorials/learning_gen_fns/#Learning-from-Incomplete-Data","page":"Learning Generative Functions","title":"Learning from Incomplete Data","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"When there are random variables in our model whose value is not observed in our data set, then doing maximum learning is significantly more difficult. Specifically, maximum likelihood is aiming to maximize the marginal likelihood of the observed data, which is an integral or sum over the values of the unobserved random variables. Let's denote the observed variables as y and the hidden variables as z:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"sum_i=1^N log p(y_i x theta) = sum_i=1^N log left( sum_z_i p(z_i y_i x theta)right)","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"It is often intractable to evaluate this quantity for specific values of the parameters, let alone maximize it. Most techniques for learning models from incomplete data, from the EM algorithm to variational autoencoders address this problem by starting with some initial theta = theta_0 and iterating between two steps:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Doing inference about the hidden variables z_i given the observed variables y_i, for the model with the current values of theta, which produces some completions of the hidden variables z_i or some representation of the posterior distribution on these hidden variables. This step does not update the parameters theta.\nOptimize the parameters theta to maximize the data of the complete log likelihood, as in the setting of complete data. This step does not involve inference about the hidden variables z_i.","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Various algorithms can be understood as examples of this general pattern, although they differ in several details including (i) how they represent the results of inferences, (ii) how they perform the inference step, (iii) whether they try to solve each of the inference and parameter-optimization problems incrementally or not, and (iv) their formal theoretical justification and analysis:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Expectation maximization (EM) [1], including incremental variants [2]\nMonte Carlo EM [3] and online variants [4]\nVariational EM\nThe wake-sleep algorithm [5] and reweighted wake-sleep algorithms [6]\nVariational autoencoders [7]","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"In Gen, the results of inference are typically represented as a collection of traces of the model, which include values for the latent variables. The section Learning from Complete Data describes how to perform the parameter update step given a collection of such traces. In the remainder of this section, we describe various learning algorithms, organized by the inference approach they take to obtain traces.","category":"page"},{"location":"tutorials/learning_gen_fns/#Monte-Carlo-EM","page":"Learning Generative Functions","title":"Monte Carlo EM","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Monte Carlo EM is a broad class of algorithms that use Monte Carlo sampling within the inference step to generate the set of traces that is used for the learning step. There are many variants possible, based on which Monte Carlo inference algorithm is used. For example:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"function train_model(data::Vector{ChoiceMap})\n    init_param!(model, :theta, 0.1)\n    update = ParamUpdate(FixedStepGradientDescent(0.001), model)\n    for iter=1:max_iter\n        traces = do_monte_carlo_inference(data)\n        for trace in traces\n            accumulate_param_gradients!(trace)\n        end\n        apply!(update)\n    end\nend\n\nfunction do_monte_carlo_inference(data)\n    num_traces = 1000\n    (traces, log_weights, _) = importance_sampling(model, (), data, num_samples)\n    weights = exp.(log_weights)\n    [traces[categorical(weights)] for _=1:num_samples]\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Note that it is also possible to use a weighted collection of traces directly without resampling:","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"function train_model(data::Vector{ChoiceMap})\n    init_param!(model, :theta, 0.1)\n    update = ParamUpdate(FixedStepGradientDescent(0.001), model)\n    for iter=1:max_iter\n        traces, weights = do_monte_carlo_inference_with_weights(data)\n        for (trace, weight) in zip(traces, weights)\n            accumulate_param_gradients!(trace, nothing, weight)\n        end\n        apply!(update)\n    end\nend","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"MCMC and other algorithms can be used for inference as well.","category":"page"},{"location":"tutorials/learning_gen_fns/#Online-Monte-Carlo-EM","page":"Learning Generative Functions","title":"Online Monte Carlo EM","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"The Monte Carlo EM example performed inference from scratch within each iteration. However, if the change tothe parameters during each iteration is small, it is likely that the traces from the previous iteration can be reused. There are various ways of reusing traces: We can use the traces obtained for the previous traces to initialize MCMC for the new parameters. We can reweight the traces based on the change to their importance weights [4].","category":"page"},{"location":"tutorials/learning_gen_fns/#Wake-sleep-algorithm","page":"Learning Generative Functions","title":"Wake-sleep algorithm","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"The wake-sleep algorithm [5] is an approach to training generative models that uses an inference network, a neural network that takes in the values of observed random variables and returns parameters of a probability distribution on latent variables. We call the conditional probability distribution on the latent variables, given the observed variables, the inference model. In Gen, both the generative model and the inference model are represented as generative functions. The wake-sleep algorithm trains the inference model as it trains the generative model. At each iteration, during the wake phase, the generative model is trained on complete traces generated by running the current version of the inference on the observed data. At each iteration, during the sleep phase, the inference model is trained on data generated by simulating from the current generative model. The lecture! or lecture_batched! methods can be used for the sleep phase training.","category":"page"},{"location":"tutorials/learning_gen_fns/#Reweighted-wake-sleep-algorithm","page":"Learning Generative Functions","title":"Reweighted wake-sleep algorithm","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"The reweighted wake-sleep algorithm [6] is an extension of the wake-sleep algorithm, where during the wake phase, for each observation, a collection of latent completions are taken by simulating from the inference model multiple times. Then, each of these is weighted by an importance weight. This extension can be implemented with importance_sampling.","category":"page"},{"location":"tutorials/learning_gen_fns/#Variational-inference","page":"Learning Generative Functions","title":"Variational inference","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Variational inference can be used to for the inference step. Here, the parameters of the variational approximation, represented as a generative function, are fit to the posterior during the inference step. black_box_vi! or black_box_vimco! can be used to fit the variational approximation. Then, the traces of the model can be obtained by simulating from the variational approximation and merging the resulting choice maps with the observed data.","category":"page"},{"location":"tutorials/learning_gen_fns/#Amortized-variational-inference-(VAEs)","page":"Learning Generative Functions","title":"Amortized variational inference (VAEs)","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"Instead of fitting the variational approximation from scratch for each observation, it is possible to fit an inference model instead, that takes as input the observation, and generates a distribution on latent variables as output (as in the wake sleep algorithm). When we train the variational approximation by minimizing the evidence lower bound (ELBO) this is called amortized variational inference. Variational autencoders are an example. It is possible to perform amortized variational inference using black_box_vi! or black_box_vimco!.","category":"page"},{"location":"tutorials/learning_gen_fns/#References","page":"Learning Generative Functions","title":"References","text":"","category":"section"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[1] Dempster, Arthur P., Nan M. Laird, and Donald B. Rubin. \"Maximum likelihood from incomplete data via the EM algorithm.\" Journal of the Royal Statistical Society: Series B (Methodological) 39.1 (1977): 1-22. Link","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[2] Neal, Radford M., and Geoffrey E. Hinton. \"A view of the EM algorithm that justifies incremental, sparse, and other variants.\" Learning in graphical models. Springer, Dordrecht, 1998. 355-368. Link","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[3] Wei, Greg CG, and Martin A. Tanner. \"A Monte Carlo implementation of the EM algorithm and the poor man's data augmentation algorithms.\" Journal of the American statistical Association 85.411 (1990): 699-704. Link","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[4] Levine, Richard A., and George Casella. \"Implementations of the Monte Carlo EM algorithm.\" Journal of Computational and Graphical Statistics 10.3 (2001): 422-439. Link","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[5] Hinton, Geoffrey E., et al. \"The\" wake-sleep\" algorithm for unsupervised neural networks.\" Science 268.5214 (1995): 1158-1161. Link","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[6] Jorg Bornschein and Yoshua Bengio. Reweighted wake sleep. ICLR 2015. Link","category":"page"},{"location":"tutorials/learning_gen_fns/","page":"Learning Generative Functions","title":"Learning Generative Functions","text":"[7] Diederik P. Kingma, Max Welling: Auto-Encoding Variational Bayes. ICLR 2014 Link","category":"page"},{"location":"ref/modeling/distributions/#distributions","page":"Probability Distributions","title":"Probability Distributions","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Gen provides a library of built-in probability distributions, and four ways of constructing custom distributions, each of which are explained below:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"The HeterogeneousMixture and HomogeneousMixture constructors for distributions that are mixtures of other distributions.\nThe ProductDistribution constructor for  distributions that are products of other distributions.\nThe @dist constructor, for a distribution that can be expressed as a simple deterministic transformation (technically, a pushforward) of an existing distribution.\nAn API for defining arbitrary custom distributions in plain Julia code.","category":"page"},{"location":"ref/modeling/distributions/#Built-In-Distributions","page":"Probability Distributions","title":"Built-In Distributions","text":"","category":"section"},{"location":"ref/modeling/distributions/#Gen.bernoulli","page":"Probability Distributions","title":"Gen.bernoulli","text":"bernoulli(prob_true::Real)\n\nSamples a Bool value which is true with given probability\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.beta","page":"Probability Distributions","title":"Gen.beta","text":"beta(alpha::Real, beta::Real)\n\nSample a Float64 from a beta distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.beta_uniform","page":"Probability Distributions","title":"Gen.beta_uniform","text":"beta_uniform(theta::Real, alpha::Real, beta::Real)\n\nSamples a Float64 value from a mixture of a uniform distribution on [0, 1] with probability 1-theta and a beta distribution with parameters alpha and beta with probability theta.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.binom","page":"Probability Distributions","title":"Gen.binom","text":"binom(n::Integer, p::Real)\n\nSample an Int from the Binomial distribution with parameters n (number of trials) and p (probability of success in each trial).\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.categorical","page":"Probability Distributions","title":"Gen.categorical","text":"categorical(probs::AbstractArray{U, 1}) where {U <: Real}\n\nGiven a vector of probabilities probs where sum(probs) = 1, sample an Int i from the set {1, 2, .., length(probs)} with probability probs[i].\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.cauchy","page":"Probability Distributions","title":"Gen.cauchy","text":"cauchy(x0::Real, gamma::Real)\n\nSample a Float64 value from a Cauchy distribution with location x0 and scale gamma.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.dirichlet","page":"Probability Distributions","title":"Gen.dirichlet","text":"dirichlet(alpha::Vector{Float64})\n\nSample a simplex Vector{Float64} from a Dirichlet distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.exponential","page":"Probability Distributions","title":"Gen.exponential","text":"exponential(rate::Real)\n\nSample a Float64 from the exponential distribution with rate parameter rate.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.gamma","page":"Probability Distributions","title":"Gen.gamma","text":"gamma(shape::Real, scale::Real)\n\nSample a Float64 from a gamma distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.geometric","page":"Probability Distributions","title":"Gen.geometric","text":"geometric(p::Real)\n\nSample an Int from the Geometric distribution with parameter p.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.inv_gamma","page":"Probability Distributions","title":"Gen.inv_gamma","text":"inv_gamma(shape::Real, scale::Real)\n\nSample a Float64 from a inverse gamma distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.laplace","page":"Probability Distributions","title":"Gen.laplace","text":"laplace(loc::Real, scale::Real)\n\nSample a Float64 from a laplace distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.mvnormal","page":"Probability Distributions","title":"Gen.mvnormal","text":"mvnormal(mu::AbstractVector{T}, cov::AbstractMatrix{U}} where {T<:Real,U<:Real}\n\nSamples a Vector{Float64} value from a multivariate normal distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.neg_binom","page":"Probability Distributions","title":"Gen.neg_binom","text":"neg_binom(r::Real, p::Real)\n\nSample an Int from a Negative Binomial distribution. Returns the number of failures before the rth success in a sequence of independent Bernoulli trials. r is the number of successes (which may be fractional) and p is the probability of success per trial.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.normal","page":"Probability Distributions","title":"Gen.normal","text":"normal(mu::Real, std::Real)\n\nSamples a Float64 value from a normal distribution.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.piecewise_uniform","page":"Probability Distributions","title":"Gen.piecewise_uniform","text":"piecewise_uniform(bounds, probs)\n\nSamples a Float64 value from a piecewise uniform continuous distribution.\n\nThere are n bins where n = length(probs) and n + 1 = length(bounds). Bounds must satisfy bounds[i] < bounds[i+1] for all i. The probability density at x is zero if x <= bounds[1] or x >= bounds[end] and is otherwise probs[bin] / (bounds[bin] - bounds[bin+1]) where bounds[bin] < x <= bounds[bin+1].\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.poisson","page":"Probability Distributions","title":"Gen.poisson","text":"poisson(lambda::Real)\n\nSample an Int from the Poisson distribution with rate lambda.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.uniform","page":"Probability Distributions","title":"Gen.uniform","text":"uniform(low::Real, high::Real)\n\nSample a Float64 from the uniform distribution on the interval [low, high].\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.uniform_discrete","page":"Probability Distributions","title":"Gen.uniform_discrete","text":"uniform_discrete(low::Integer, high::Integer)\n\nSample an Int from the uniform distribution on the set {low, low + 1, ..., high-1, high}.\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Gen.broadcasted_normal","page":"Probability Distributions","title":"Gen.broadcasted_normal","text":"broadcasted_normal(mu::AbstractArray{<:Real, N1},\n                   std::AbstractArray{<:Real, N2}) where {N1, N2}\n\nSamples an Array{Float64, max(N1, N2)} of shape Broadcast.broadcast_shapes(size(mu), size(std)) where each element is independently normally distributed.  This is equivalent to (a reshape of) a multivariate normal with diagonal covariance matrix, but its implementation is more efficient than that of the more general mvnormal for this case.\n\nThe shapes of mu and std must be broadcast-compatible.\n\nIf all args are 0-dimensional arrays, then sampling via broadcasted_normal(...) returns a Float64 rather than properly returning an Array{Float64, 0}.  This is consistent with Julia's own inconsistency on the matter:\n\njulia> typeof(ones())\nArray{Float64,0}\n\njulia> typeof(ones() .* ones())\nFloat64\n\n\n\n\n\n","category":"constant"},{"location":"ref/modeling/distributions/#Mixture-Distribution-Constructors","page":"Probability Distributions","title":"Mixture Distribution Constructors","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"There are two built-in constructors for defining mixture distributions:","category":"page"},{"location":"ref/modeling/distributions/#Gen.HomogeneousMixture","page":"Probability Distributions","title":"Gen.HomogeneousMixture","text":"HomogeneousMixture(distribution::Distribution, dims::Vector{Int})\n\nDefine a new distribution that is a mixture of some number of instances of single base distributions.\n\nThe first argument defines the base distribution of each component in the mixture.\n\nThe second argument must have length equal to the number of arguments taken by the base distribution.  A value of 0 at a position in the vector an indicates that the corresponding argument to the base distribution is a scalar, and integer values of i for i >= 1 indicate that the corresponding argument is an i-dimensional array.\n\nExample:\n\nmixture_of_normals = HomogeneousMixture(normal, [0, 0])\n\nThe resulting distribution (e.g. mixture_of_normals above) can then be used like the built-in distribution values like normal. The distribution takes n+1 arguments where n is the number of arguments taken by the base distribution. The first argument to the distribution is a vector of non-negative mixture weights, which must sum to 1.0. The remaining arguments to the distribution correspond to the arguments of the base distribution, but have a different type: If an argument to the base distribution is a scalar of type T, then the corresponding argument to the mixture distribution is a Vector{T}, where each element of this vector is the argument to the corresponding mixture component. If an argument to the base distribution is an Array{T,N} for some N, then the corresponding argument to the mixture distribution is of the form arr::Array{T,N+1}, where each slice of the array of the form arr[:,:,...,i] is the argument for the ith mixture component.\n\nExample:\n\nmixture_of_normals = HomogeneousMixture(normal, [0, 0])\nmixture_of_mvnormals = HomogeneousMixture(mvnormal, [1, 2])\n\n@gen function foo()\n    # mixture of two normal distributions\n    # with means -1.0 and 1.0\n    # and standard deviations 0.1 and 10.0\n    # the first normal distribution has weight 0.4; the second has weight 0.6\n    x ~ mixture_of_normals([0.4, 0.6], [-1.0, 1.0], [0.1, 10.0])\n\n    # mixture of two multivariate normal distributions\n    # with means: [0.0, 0.0] and [1.0, 1.0]\n    # and covariance matrices: [1.0 0.0; 0.0 1.0] and [10.0 0.0; 0.0 10.0]\n    # the first multivariate normal distribution has weight 0.4;\n    # the second has weight 0.6\n    means = [0.0 1.0; 0.0 1.0] # or, cat([0.0, 0.0], [1.0, 1.0], dims=2)\n    covs = cat([1.0 0.0; 0.0 1.0], [10.0 0.0; 0.0 10.0], dims=3)\n    y ~ mixture_of_mvnormals([0.4, 0.6], means, covs)\nend\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/distributions/#Gen.HeterogeneousMixture","page":"Probability Distributions","title":"Gen.HeterogeneousMixture","text":"HeterogeneousMixture(distributions::Vector{Distribution{T}}) where {T}\n\nDefine a new distribution that is a mixture of a given list of base distributions.\n\nThe argument is the vector of base distributions, one for each mixture component.\n\nNote that the base distributions must have the same output type.\n\nExample:\n\nuniform_beta_mixture = HeterogeneousMixture([uniform, beta])\n\nThe resulting mixture distribution takes n+1 arguments, where n is the sum of the number of arguments taken by each distribution in the list. The first argument to the mixture distribution is a vector of non-negative mixture weights, which must sum to 1.0. The remaining arguments are the arguments to each mixture component distribution, in order in which the distributions are passed into the constructor.\n\nExample:\n\n@gen function foo()\n    # mixure of a uniform distribution on the interval [`lower`, `upper`]\n    # and a beta distribution with alpha parameter `a` and beta parameter `b`\n    # the uniform as weight 0.4 and the beta has weight 0.6\n    x ~ uniform_beta_mixture([0.4, 0.6], lower, upper, a, b)\nend\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/distributions/#Product-Distribution-Constructors","page":"Probability Distributions","title":"Product Distribution Constructors","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"There is a built-in constructor for defining product distributions:","category":"page"},{"location":"ref/modeling/distributions/#Gen.ProductDistribution","page":"Probability Distributions","title":"Gen.ProductDistribution","text":"ProductDistribution(distributions::Vararg{<:Distribution})\n\nDefine new distribution that is the product of the given nonempty list of distributions having a common type.\n\nThe arguments comprise the list of base distributions.\n\nExample:\n\nnormal_strip = ProductDistribution(uniform, normal)\n\nThe resulting product distribution takes n arguments, where n is the sum of the numbers of arguments taken by each distribution in the list. These arguments are the arguments to each component distribution, in the order in which the distributions are passed to the constructor.\n\nExample:\n\n@gen function unit_strip_and_near_seven()\n    x ~ flip_and_number(0.0, 0.1, 7.0, 0.01)\nend\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/distributions/#dist_dsl","page":"Probability Distributions","title":"The @dist DSL","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"The @dist DSL allows the user to concisely define a distribution, as long as that distribution can be expressed as a certain type of deterministic transformation of an existing distribution.  The syntax of the @dist DSL, as well as the class of permitted deterministic transformations, are explained below.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@dist name(arg1, arg2, ..., argN) = body","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"or","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@dist function name(arg1, arg2, ..., argN)\n    body\nend","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Here body is ordinary Julia code, with the constraint that body must contain exactly one random choice.  The value of the @dist expression is then a Gen.Distribution object called name, parameterized by arg1, ..., argN, representing the distribution over return values of body. Arguments are optionally typed.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"This DSL is designed to address the issue that sometimes, values stored in the trace do not correspond to the most natural physical elements of the model state space, making inference programming and querying more taxing than necessary. For example, suppose we have a model of classes at a school, where the number of students is random, with mean 10, but always at least 3. Rather than writing the model as","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@gen function class_model()\n   n_students = @trace(poisson(7), :n_students_minus_3) + 3\n   ...\nend","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"and thinking about the random variable :n_students_minus_3, you can use the @dist DSL to instead write","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@dist student_distr(mean, min) = poisson(mean-min) + min\n\n@gen function class_model()\n   n_students = @trace(student_distr(10, 3), :n_students)\n   ...\nend","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"and think about the more natural random variable :n_students.  This leads to more natural inference programs, which can constrain and propose directly to the :n_students trace address.","category":"page"},{"location":"ref/modeling/distributions/#Permitted-constructs-for-the-body-of-a-@dist","page":"Probability Distributions","title":"Permitted constructs for the body of a @dist","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"It is not possible for @dist to work on any arbitrary body.  We now describe which constructs are permitted inside the body of a @dist expression.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"We can think of the body of an @dist function as containing ordinary Julia code, except that in addition to being described by their ordinary Julia types, each expression also belongs to one of three \"type spaces.\" These are:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"CONST: Constants, whose value is known at the time this @dist expression is evaluated.\nARG: Arguments and (deterministic, differentiable) functions of arguments. All expressions representing non-random values that depend on distribution arguments are ARG expressions.\nRND: Random variables. All expressions whose runtime values may differ across multiple calls to this distribution (with the same arguments) are RND expressions.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Importantly, Julia control flow constructs generally expect CONST values: the condition of an if or the range of a for loop cannot be ARG or RND.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"The body expression as a whole must be a RND expression, representing a random variable. The behavior of the @dist definition is then to define a new distribution (with name name) that samples and evaluates the logpdf of the random variable represented by the body expression.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Expressions are typed compositionally, with the following typing rules:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Literals and free variables are CONSTs. Literals and symbols that appear free in the @dist body are of type CONST.\nArguments are ARGs. Symbols bound as arguments in the @dist declaration have type ARG in its body.\nDrawing from a distribution gives RND. If d is a distribution, and x_i are of type ARG or CONST, d(x_1, x_2, ...) is of type RND.\nFunctions of CONSTs are CONSTs. If f is a deterministic function and x_i are all of type CONST, f(x_1, x_2, ...) is of type CONST.\nFunctions of CONSTs and ARGs are ARGs. If f is a differentiable function, and each x_i is either a CONST or a scalar ARG (with at least one x_i being an ARG), then f(x_1, x_2, ...) is of type ARG.\nFunctions of CONSTs, ARGs, and RNDs are RNDs. If f is one of a special set of deterministic functions we've defined (+, -, *, /, exp, log, getindex), and exactly one of its arguments x_i is of type RND, then f(x_1, x_2, ...) is of type RND.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"One way to think about this, without all the rules, is that CONST values are \"contaminated\" by interaction with ARG values (becoming ARGs themselves), and both CONST and ARG are \"contaminated\" by interaction with RND. Thinking of the body as an AST, the journey from leaf node to root node always involves transitions in the direction of CONST -> ARG -> RND, never in reverse.","category":"page"},{"location":"ref/modeling/distributions/#Restrictions","page":"Probability Distributions","title":"Restrictions","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Users may not reassign to arguments (like x in the above example), and may not apply functions with side effects. Names bound to expressions of type RND must be used only once. e.g., let x = normal(0, 1) in x + x is not allowed.","category":"page"},{"location":"ref/modeling/distributions/#Examples","page":"Probability Distributions","title":"Examples","text":"","category":"section"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Let's walk through some examples.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@dist f(x) = exp(normal(x, 1))","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"We can annotate with types:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"1 :: CONST\t\t  (by rule 1)\nx :: ARG \t\t  (by rule 2)\nnormal(x, 1) :: RND \t  (by rule 3)\nexp(normal(x, 1)) :: RND  (by rule 6)","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Here's another:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@dist function labeled_cat(labels, probs)\n\tindex = categorical(probs)\n\tlabels[index]\nend","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"And the types:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"probs :: ARG \t\t\t(by rule 2)\ncategorical(probs) :: RND \t(by rule 3)\nindex :: RND \t\t\t(Julia assignment)\nlabels :: ARG \t\t\t(by rule 2)\nlabels[index] :: RND \t\t(by rule 6, f == getindex)","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Note that getindex is designed to work on anything indexible, not just vectors. So, for example, it also works with Dicts.","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"Another one (not as realistic, but it uses all the rules):","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"@dist function weird(x)\n  log(normal(exp(x), exp(x))) + (x * (2 + 3))\nend","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"And the types:","category":"page"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"2, 3 :: CONST \t\t\t\t\t\t(by rule 1)\n2 + 3 :: CONST \t\t\t\t\t\t(by rule 4)\nx :: ARG \t\t\t\t\t\t(by rule 2)\nx * (2 + 3) :: ARG \t\t\t\t\t(by rule 5)\nexp(x) :: ARG \t\t\t\t\t\t(by rule 5)\nnormal(exp(x), exp(x)) :: RND \t\t\t\t(by rule 3)\nlog(normal(exp(x), exp(x))) :: RND \t\t\t(by rule 6)\nlog(normal(exp(x), exp(x))) + (x * (2 + 3)) :: RND \t(by rule 6)","category":"page"},{"location":"ref/modeling/distributions/#API","page":"Probability Distributions","title":"API","text":"","category":"section"},{"location":"ref/modeling/distributions/#Gen.random","page":"Probability Distributions","title":"Gen.random","text":"val::T = random(dist::Distribution{T}, args...)\n\nSample a random choice from the given distribution with the given arguments.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/distributions/#Gen.logpdf","page":"Probability Distributions","title":"Gen.logpdf","text":"lpdf = logpdf(dist::Distribution{T}, value::T, args...)\n\nEvaluate the log probability (density) of the value.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/distributions/#Gen.logpdf_grad","page":"Probability Distributions","title":"Gen.logpdf_grad","text":"grads::Tuple = logpdf_grad(dist::Distribution{T}, value::T, args...)\n\nCompute the gradient of the logpdf with respect to the value, and each of the arguments.\n\nIf has_output_grad returns false, then the first element of the returned tuple is nothing. Otherwise, the first element of the tuple is the gradient with respect to the value. If the return value of has_argument_grads has a false value for at position i, then the i+1th element of the returned tuple has value nothing. Otherwise, this element contains the gradient with respect to the ith argument.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/distributions/#Gen.has_output_grad","page":"Probability Distributions","title":"Gen.has_output_grad","text":"has::Bool = has_output_grad(dist::Distribution)\n\nReturn true if the distribution computes the gradient of the logpdf with respect to the value of the random choice.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/distributions/#Gen.is_discrete","page":"Probability Distributions","title":"Gen.is_discrete","text":"discrete::Bool = is_discrete(::Distribution)\n\nReturn true if the distribution is discrete, false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/distributions/","page":"Probability Distributions","title":"Probability Distributions","text":"The has_argument_grads function is also part of the distribution API.","category":"page"},{"location":"ref/inference/map/#MAP-Optimization","page":"MAP Optimization","title":"MAP Optimization","text":"","category":"section"},{"location":"ref/inference/map/","page":"MAP Optimization","title":"MAP Optimization","text":"In contrast to parameter optimization, which optimizes parameters of a generative function that are not associated with any prior distribution, maximum a posteriori (MAP)  optimization can be used to maximize the posterior probability of a selection of traced random variables:","category":"page"},{"location":"ref/inference/map/#Gen.map_optimize","page":"MAP Optimization","title":"Gen.map_optimize","text":"new_trace = map_optimize(trace, selection::Selection,\n    max_step_size=0.1, tau=0.5, min_step_size=1e-16, verbose=false)\n\nPerform backtracking gradient ascent to optimize the log probability of the trace over selected continuous choices. Selected random choices must have support on the entire real line.\n\n\n\n\n\n","category":"function"},{"location":"ref/inference/map/","page":"MAP Optimization","title":"MAP Optimization","text":"To use map_optimize, a trace of a generative function should be first created using the generate method with the appropriate observations. Users may also implement more complex optimization algorithms beyond backtracking gradient ascent by using the gradients returned by choice_gradients. Note that if the selected random variables have bounded support over the real line, errors may occur during gradient-based optimization.","category":"page"},{"location":"tutorials/vi/#vi_tutorial","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"","category":"section"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Variational inference (VI) involves optimizing the parameters of a variational family to maximize a lower bound on the marginal likelihood called the ELBO. In Gen, variational families are represented as generative functions, and variational inference typically involves optimizing the trainable parameters of generative functions.","category":"page"},{"location":"tutorials/vi/#A-Simple-Example-of-VI","page":"Variational Inference in Gen","title":"A Simple Example of VI","text":"","category":"section"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Let's begin with a simple example that illustrates how to use Gen's black_box_vi! function to perform variational inference. In variational inference, we have a target distribution P(x) that we wish to approximate with some variational distribution Q(x phi) with trainable parameters phi.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"In many cases, this target distribution is a posterior distribution P(x  y) given a fixed set of observations y. But in this example, we assume we know P(x) exactly, and optimize phi so that Q(x phi) fits P(x).","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"We first define the target distribution P(x) as a normal distribution with  with a mean of -1 and a standard deviation of exp(0.5):","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"@gen function target()\n    x ~ normal(-1, exp(0.5))\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"We now define a variational family, also known as a guide, as a generative function Q(x phi) parameterized by a set of trainable parameters phi. This requires (i) picking the functional form of the variational distribution (e.g. normal, Cauchy, etc.), (ii) choosing how the distribution is parameterized.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Our target distribution is normal, so we make our variational family normally distributed as well. We also define two variational parameters, x_mu and x_log_std, which are the mean and log standard deviation of our variational distribution.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"@gen function approx()\n    @param x_mu::Float64\n    @param x_log_std::Float64\n    x ~ normal(x_mu, exp(x_log_std))\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Since x_mu and x_log_std are not fixed to particular values, this generative function defines a family of distributions, not just one. Note that we intentionally chose to parameterize the distribution by the log standard deviation x_log_std, so that every parameter has full support over the real line, and we can perform unconstrained optimization of the parameters.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"To perform variational inference, we need to initialize the variational parameters to their starting values:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"init_param!(approx, :x_mu, 0.0)\ninit_param!(approx, :x_log_std, 0.0)\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Now we can use the black_box_vi! function to perform variational inference using GradientDescent to update the variational parameters.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"observations = choicemap()\nparam_update = ParamUpdate(GradientDescent(1., 1000), approx)\nblack_box_vi!(target, (), observations, approx, (), param_update;\n              iters=200, samples_per_iter=100, verbose=false)\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"We can now inspect the resulting variational parameters, and see if we have recovered the parameters of the target distribution:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"x_mu = get_param(approx, :x_mu)\nx_log_std = get_param(approx, :x_log_std)\n@show x_mu x_log_std;\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"As expected, we have recovered the parameters of the target distribution.","category":"page"},{"location":"tutorials/vi/#Posterior-Inference-with-VI","page":"Variational Inference in Gen","title":"Posterior Inference with VI","text":"","category":"section"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"In the above example, we used a target distribution P(x) that we had full knowledge about. When performing posterior inference, however, we typically only have the ability to sample from a generative model x y sim P(x) P(y  x), and to evaluate the joint probability P(x y), but not the ability to evaluate or sample from the posterior P(x  y) for a fixed obesrvation y.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Variational inference can address this by approximating P(x  y) with Q(x phi), allowing us to sample and evaluate Q(x phi) instead. This is done by maximizing a quantity known as the evidence lower bound or ELBO, which is a lower bound on the log marginal likelihood log P(y) of the observations y. The ELBO can be written in multiple equivalent forms:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"beginaligned\noperatornameELBO(phi y)\n= mathbbE_x sim Q(x phi)leftlog fracP(x y)Q(x phi)right \n= mathbbE_x sim Q(x phi)log P(x y) + operatornameHQ(x phi) \n= log P(y) - operatornameKLQ(x phi)  P(x  y)\nendaligned","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Here, operatornameHQ(x phi) is the entropy of the variational distribution Q(x phi), and operatornameKLQ(x phi)  P(x  y) is the Kullback-Leibler divergence between the variational distribution Q(x phi) and the target distribution P(x  y). From the third line, we can see that the ELBO is a lower bound on log P(y), and that maximizing the ELBO is equivalent to minimizing the KL divergence between Q(x phi) and P(x  y).","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Let's test this for a generative model P(x y) where it is possible (with a bit of work) to analytically calculate the posterior P(y  x):","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"@gen function model(n::Int)\n    x ~ normal(0, 1)\n    for i in 1:n\n        {(:y, i)} ~ normal(x, 0.5)\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"In this normal-normal model, an unknown mean x is sampled from a operatornameNormal(0 1) prior. Then we draw n datapoints y_1n from a normal distribution centered around x with a standard deviation of 0.5. Our task is to infer the posterior distribution over x given that we have observed y_1n. We'll reuse the same variational family as before:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"@gen function approx()\n    @param x_mu::Float64\n    @param x_log_std::Float64\n    x ~ normal(x_mu, exp(x_log_std))\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Suppose we observe n = 6 datapoints y_16 with the following values:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"ys = [3.12, 2.25, 2.21, 1.55, 2.15, 1.06]\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"It is possible to show analytically that the posterior P(x  y_1n) is normally distributed with mean mu_n = frac4n1 + 4n bar y and standard deviation sigma_n = frac1sqrt1 + 4n, where bar y is the mean of y_1n:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"n = length(ys)\nx_mu_expected = 4*n / (1 + 4*n) * (sum(ys) / n)\nx_std_expected = 1/(sqrt((1 + 4*n)))\n@show x_mu_expected x_std_expected;\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Let's see whether variational inference can reproduce these values. We first construct a choicemap of our observations:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"observations = choicemap()\nfor (i, y) in enumerate(ys)\n    observations[(:y, i)] = y\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Next, we configure our GradientDescent optimizer. Since this is a more complicated optimization proplem, we use a smaller initial step size of 0.01:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"step_size_init = 0.01\nstep_size_beta = 1000\nupdate_config = GradientDescent(step_size_init, step_size_beta)\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"We then initialize the parameters of our variational approximation, and pass our model, observations, and variational family to black_box_vi!. ","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"init_param!(approx, :x_mu, 0.0)\ninit_param!(approx, :x_log_std, 0.0)\nparam_update = ParamUpdate(update_config, approx);\nelbo_est, _, elbo_history =\n    black_box_vi!(model, (n,), observations, approx, (), param_update;\n                  iters=500, samples_per_iter=200, verbose=false);\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"As expected, the ELBO estimate increases over time, eventually converging to a value around -9.9:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"for t in [1; 50:50:500]\n    println(\"iter $(lpad(t, 3)): elbo est. = $(elbo_history[t])\")\nend\nprintln(\"final elbo est. = $elbo_est\")","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Inspecting the resulting variational parameters, we find that they are reasonable approximations to the parameters of the true posterior:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"x_mu_approx = get_param(approx, :x_mu)\nΔx_mu = x_mu_approx - x_mu_expected\n\nx_log_std_approx = get_param(approx, :x_log_std)\nx_std_approx = exp(x_log_std_approx)\nΔx_std = x_std_approx - x_std_expected\n\n@show (x_mu_approx, Δx_mu) (x_std_approx, Δx_std);\nnothing # hide","category":"page"},{"location":"tutorials/vi/#Amortized-Variational-Inference","page":"Variational Inference in Gen","title":"Amortized Variational Inference","text":"","category":"section"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"In standard variational inference, we have to optimize the variational parameters phi for each new inference problem. Depending on how difficult the optimization problem is, this may be costly.","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"As an alternative, we can perform amortized variational inference: Instead of optimizing phi for each set of observations y that we encounter, we learn a function f_varphi(y) that outputs a set of distribution parameters phi_y for each y, and optimize the parameters of the function varphi. We do this over a dataset of K independently distributed observation sets Y = y^1  y^K, maximizing the expected ELBO over this dataset:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"beginaligned\noperatornameA-ELBO(varphi Y)\n= frac1K sum_k=1^K operatornameELBO(varphi y^k) \n= frac1K leftlog P(Y) - sum_k=1^K operatornameKLQ(x f_varphi(y^k))  P(x  y^k) right\nendaligned","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"We will perform amortized VI over the same generative model we defined earlier:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"@gen function model(n::Int)\n    x ~ normal(0, 1)\n    for i in 1:n\n        {(:y, i)} ~ normal(x, 0.5)\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Since amortized VI is performed over a dataset of K observation sets y^1  y^K, where each y^k has n datapoints (y^k_1  y^k_n) , we need to nest model within a Map combinator that repeats model K times:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"mapped_model = Map(model)\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Let's generate a synthetic dataset of K = 10 observation sets, each with n = 6 datapoints:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"# Simulate 10 observation sets of length 6\nK, n = 10, 6\nmapped_trace = simulate(mapped_model, (fill(n, K),))\nobservations = get_choices(mapped_trace)\n\n# Select just the `y` values, excluding the generated `x` values\nsel = select((k => (:y, i) for i in 1:n for k in 1:K)...)\nobservations = get_selected(observations, sel)\nall_ys = [[observations[k => (:y, i)] for i in 1:n] for k in 1:K]\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Now let's define our amortized approximation, which takes in an observation set ys, and computes the parameters of a normal distribution over x as a function of ys:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"@gen function amortized_approx(ys)\n    @param x_mu_bias::Float64\n    @param x_mu_coeff::Float64\n    @param x_log_std::Float64\n    x_mu = x_mu_bias + x_mu_coeff * sum(ys)\n    x ~ normal(x_mu, exp(x_log_std))\n    return (x_mu, x_log_std)\nend\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Similar to our model, we need to wrap this variational approximation in a Map combinator:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"mapped_approx = Map(amortized_approx)\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"In our choice of function f_varphi(y), we exploit the fact that the posterior mean x_mu should depend on the sum of the values in ys, along with the knowledge that x_log_std does not depend on ys. We could have chosen a more complex function, such as full-rank linear regression, or a neural network, but this would make optimization more difficult. Given this choice of function, the optimal parameters varphi^* can be computed analytically:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"n = 6\n\nx_mu_bias_optimal = 0.0\nx_mu_coeff_optimal = 4 / (1 + 4*n)\n\nx_std_optimal = 1/(sqrt((1 + 4*n)))\nx_log_std_optimal = log(x_std_optimal)\n\n@show x_mu_bias_optimal x_mu_coeff_optimal x_log_std_optimal;\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"We can now fit our variational approximation via black_box_vi!: We initialize the variational parameters, then configure our parameter update to update the parameters of amortized_approx:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"# Configure parameter update to optimize the parameters of `amortized_approx`\nstep_size_init = 1e-4\nstep_size_beta = 1000\nupdate_config = GradientDescent(step_size_init, step_size_beta)\n\n# Initialize the amortized variational parameters, then the parameter update\ninit_param!(amortized_approx, :x_mu_bias, 0.0);\ninit_param!(amortized_approx, :x_mu_coeff, 0.0);\ninit_param!(amortized_approx, :x_log_std, 0.0);\nparam_update = ParamUpdate(update_config, amortized_approx);\n\n# Run amortized black-box variational inference over the synthetic observations\nmapped_model_args = (fill(n, K), )\nmapped_approx_args = (all_ys, )\nelbo_est, _, elbo_history =\n    black_box_vi!(mapped_model, mapped_model_args, observations,\n                  mapped_approx, mapped_approx_args, param_update;\n                  iters=500, samples_per_iter=100, verbose=false);\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Once again, the ELBO estimate increases and eventually converges:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"for t in [1; 50:50:500]\n    println(\"iter $(lpad(t, 3)): elbo est. = $(elbo_history[t])\")\nend\nprintln(\"final elbo est. = $elbo_est\")","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Our amortized variational parameters varphi are also fairly close to their optimal values varphi^*:","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"x_mu_bias = get_param(amortized_approx, :x_mu_bias)\nΔx_mu_bias = x_mu_bias - x_mu_bias_optimal\n\nx_mu_coeff = get_param(amortized_approx, :x_mu_coeff)\nΔx_mu_coeff = x_mu_coeff - x_mu_coeff_optimal\n\nx_log_std = get_param(amortized_approx, :x_log_std)\nΔx_log_std = x_log_std - x_log_std_optimal\n\n@show (x_mu_bias, Δx_mu_bias) (x_mu_coeff, Δx_mu_coeff) (x_log_std, Δx_log_std);\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"If we now call amortized_approx with our observation set ys from the previous section, we should get something close to what standard variational inference produced by optimizing the paramaters of approx directly: ","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"x_mu_amortized, x_log_std_amortized = amortized_approx(ys)\nx_std_amortized = exp(x_log_std_amortized)\n\n@show x_mu_amortized x_std_amortized;\n@show x_mu_approx x_std_approx;\n@show x_mu_expected x_std_expected;\nnothing # hide","category":"page"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"Both amortized VI and standard VI produce parameter estimates that are reasonably close to the paramters of the true posterior.","category":"page"},{"location":"tutorials/vi/#Reparametrization-Trick","page":"Variational Inference in Gen","title":"Reparametrization Trick","text":"","category":"section"},{"location":"tutorials/vi/","page":"Variational Inference in Gen","title":"Variational Inference in Gen","text":"To use the reparametrization trick to reduce the variance of gradient estimators, users currently need to write two versions of their variational family, one that is reparametrized and one that is not. Gen.jl does not currently include inference library support for this. We plan to add automated support for reparametrization and other variance reduction techniques in the future.","category":"page"},{"location":"ref/modeling/combinators/#combinators","page":"Combinators","title":"Generative Function Combinators","text":"","category":"section"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"Generative function combinators are Julia functions that take one or more generative functions as input and return a new generative function. Generative function combinators are used to express patterns of repeated computation that appear frequently in generative models. Some generative function combinators are similar to higher order functions from functional programming languages. However, generative function combinators are not 'higher order generative functions', because they are not themselves generative functions (they are regular Julia functions).","category":"page"},{"location":"ref/modeling/combinators/#Map-combinator","page":"Combinators","title":"Map combinator","text":"","category":"section"},{"location":"ref/modeling/combinators/#Gen.Map","page":"Combinators","title":"Gen.Map","text":"gen_fn = Map(kernel::GenerativeFunction)\n\nReturn a new generative function that applies the kernel independently for a vector of inputs.\n\nThe returned generative function has one argument with type Vector{X} for each argument of the input generative function with type X. The length of each argument, which must be the same for each argument, determines the number of times the input generative function is called (N). Each call to the input function is made under address namespace i for i=1..N. The return value of the returned function has type FunctionalCollections.PersistentVector{Y} where Y is the type of the return value of the input function. The map combinator is similar to the 'map' higher order function in functional programming, except that the map combinator returns a new generative function that must then be separately applied.\n\nIf kernel has optional trailing arguments, the corresponding Vector arguments can be omitted from calls to Map(kernel).\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"In the schematic below, the kernel is denoted mathcalG_mathrmk.","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"<div style=\"text-align:center\">\n    <img src=\"../../../assets/map_combinator.png\" alt=\"schematic of map combinator\" width=\"50%\"/>\n</div>","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"For example, consider the following generative function, which makes one random choice at address :z:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"@gen function foo(x1::Float64, x2::Float64)\n    y = @trace(normal(x1 + x2, 1.0), :z)\n    return y\nend","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"We apply the map combinator to produce a new generative function bar:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"bar = Map(foo)","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"We can then obtain a trace of bar:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"(trace, _) = generate(bar, ([0.0, 0.5], [0.5, 1.0]))","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"This causes foo to be invoked twice, once with arguments (0.0, 0.5) in address namespace 1 and once with arguments (0.5, 1.0) in address namespace 2. If the resulting trace has random choices:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"│\n├── 1\n│   │\n│   └── :z : -0.5757913836706721\n│\n└── 2\n    │\n    └── :z : 0.7357177113395333","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"then the return value is:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"FunctionalCollections.PersistentVector{Any}[-0.575791, 0.735718]","category":"page"},{"location":"ref/modeling/combinators/#Unfold-combinator","page":"Combinators","title":"Unfold combinator","text":"","category":"section"},{"location":"ref/modeling/combinators/#Gen.Unfold","page":"Combinators","title":"Gen.Unfold","text":"gen_fn = Unfold(kernel::GenerativeFunction)\n\nReturn a new generative function that applies the kernel in sequence, passing the return value of one application as an input to the next.\n\nThe kernel accepts the following arguments:\n\nThe first argument is the Int index indicating the position in the sequence (starting from 1).\nThe second argument is the state.\nThe kernel may have additional arguments after the state.\n\nThe return type of the kernel must be the same type as the state.\n\nThe returned generative function accepts the following arguments:\n\nThe number of times (N) to apply the kernel.\nThe initial state.\nThe rest of the arguments (not including the state) that will be passed to each kernel application.\n\nThe return type of the returned generative function is FunctionalCollections.PersistentVector{T} where T is the return type of the kernel.\n\nIf kernel has optional trailing arguments, the corresponding arguments can be omitted from calls to Unfold(kernel).\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"In the schematic below, the kernel is denoted mathcalG_mathrmk. The initial state is denoted y_0, the number of applications is n, and the remaining arguments to the kernel not including the state, are z.","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"<div style=\"text-align:center\">\n    <img src=\"../../../assets/unfold_combinator.png\" alt=\"schematic of unfold combinator\" width=\"70%\"/>\n</div>","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"For example, consider the following kernel, with state type Bool, which makes one random choice at address :z:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"@gen function foo(t::Int, y_prev::Bool, z1::Float64, z2::Float64)\n    y = @trace(bernoulli(y_prev ? z1 : z2), :y)\n    return y\nend","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"We apply the map combinator to produce a new generative function bar:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"bar = Unfold(foo)","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"We can then obtain a trace of bar:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"(trace, _) = generate(bar, (5, false, 0.05, 0.95))","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"This causes foo to be invoked five times. The resulting trace may contain the following random choices:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"│\n├── 1\n│   │\n│   └── :y : true\n│\n├── 2\n│   │\n│   └── :y : false\n│\n├── 3\n│   │\n│   └── :y : true\n│\n├── 4\n│   │\n│   └── :y : false\n│\n└── 5\n    │\n    └── :y : true\n","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"then the return value is:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"FunctionalCollections.PersistentVector{Any}[true, false, true, false, true]","category":"page"},{"location":"ref/modeling/combinators/#Recurse-combinator","page":"Combinators","title":"Recurse combinator","text":"","category":"section"},{"location":"ref/modeling/combinators/#Gen.Recurse","page":"Combinators","title":"Gen.Recurse","text":"Recurse(production_kernel, aggregation_kernel, max_branch,\n     ::Type{U}, ::Type{V}, ::Type{W})\n\nConstructor for recurse production and aggregation function.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"<div style=\"text-align:center\">\n    <img src=\"../../../assets/recurse_combinator.png\" alt=\"schematic of recurse combinatokr\" width=\"70%\"/>\n</div>","category":"page"},{"location":"ref/modeling/combinators/#Switch-combinator","page":"Combinators","title":"Switch combinator","text":"","category":"section"},{"location":"ref/modeling/combinators/#Gen.Switch","page":"Combinators","title":"Gen.Switch","text":"gen_fn = Switch(gen_fns::GenerativeFunction...)\n\nReturns a new generative function that accepts an argument tuple of type Tuple{Int, ...} where the first index indicates which branch to call.\n\ngen_fn = Switch(d::Dict{T, Int}, gen_fns::GenerativeFunction...) where T\n\nReturns a new generative function that accepts an argument tuple of type Tuple{Int, ...} or an argument tuple of type Tuple{T, ...} where the first index either indicates which branch to call, or indicates an index into d which maps to the selected branch. This form is meant for convenience - it allows the programmer to use d like if-else or case statements.\n\nSwitch is designed to allow for the expression of patterns of if-else control flow. gen_fns must satisfy a few requirements:\n\nEach gen_fn in gen_fns must accept the same argument types.\nEach gen_fn in gen_fns must return the same return type.\n\nOtherwise, each gen_fn can come from different modeling languages, possess different traces, etc.\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"<div style=\"text-align:center\">\n    <img src=\"../../../assets/switch_combinator.png\" alt=\"schematic of switch combinator\" width=\"100%\"/>\n</div>","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"Consider the following constructions:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"@gen function bang((grad)(x::Float64), (grad)(y::Float64))\n    std::Float64 = 3.0\n    z = @trace(normal(x + y, std), :z)\n    return z\nend\n\n@gen function fuzz((grad)(x::Float64), (grad)(y::Float64))\n    std::Float64 = 3.0\n    z = @trace(normal(x + 2 * y, std), :z)\n    return z\nend\n\nsc = Switch(bang, fuzz)","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"This creates a new generative function sc. We can then obtain the trace of sc:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"(trace, _) = simulate(sc, (2, 5.0, 3.0))","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"The resulting trace contains the subtrace from the branch with index 2 - in this case, a call to fuzz:","category":"page"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"│\n└── :z : 13.552870875213735","category":"page"},{"location":"ref/modeling/combinators/#Design-and-Implementation","page":"Combinators","title":"Design and Implementation","text":"","category":"section"},{"location":"ref/modeling/combinators/","page":"Combinators","title":"Combinators","text":"Internally, the Combinators use custom trace types such as Gen.VectorTrace, and are implemented using the following methods:","category":"page"},{"location":"ref/modeling/combinators/#Gen.VectorTrace","page":"Combinators","title":"Gen.VectorTrace","text":"VectorTrace <: Trace\n\nU is the type of the subtrace, R is the return value type for the kernel\n\n\n\n\n\n","category":"type"},{"location":"ref/modeling/combinators/#Gen.process_all_new!","page":"Combinators","title":"Gen.process_all_new!","text":"Process all new applications.\n\n\n\n\n\nProcess all new applications.\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/combinators/#Gen.update_recurse_merge","page":"Combinators","title":"Gen.update_recurse_merge","text":"update_recurse_merge(prev_choices::ChoiceMap, choices::ChoiceMap)\n\nReturns choices that are in constraints, merged with all choices in the previous trace that do not have the same address as some choice in the constraints.\"\n\n\n\n\n\n","category":"function"},{"location":"ref/modeling/combinators/#Gen.update_discard","page":"Combinators","title":"Gen.update_discard","text":"update_discard(prev_choices::ChoiceMap, choices::ChoiceMap, new_choices::ChoiceMap)\n\nReturns choices from previous trace that:\n\nhave an address which does not appear in the new trace.\nhave an address which does appear in the constraints.\n\n\n\n\n\n","category":"function"},{"location":"tutorials/getting_started/#getting_started","page":"Getting Started","title":"Getting Started: Linear Regression","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Let's write a short Gen program that does Bayesian linear regression - that is, given a set of observation points in the xy-plane, we want to find a line that fits them \"well\". What does \"well\" mean in Bayesian linear regression? Well one way of interpreting this is by proposing a line that makes the data highly likely - as in a high probability of occuring. ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"First, we need to define a generative model that describes how we believe the points were generated.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"mu sim N(02)\nb sim N(010)\nepsilon_i sim N(01)\ny_i  x_i sim mu x_i + b + epsilon_i","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"This model first randomly samples a slope mu and an intercept b from normal distributions to define the line y=mx+b. Next each x-coordinate is evaluated and perturbed with a little noise. Now let's write this as a probabilistic program.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"The description of the line is a mathematical one, but we can write it using normal code constructs. The generative model is a Julia function with a tilde (~) operator for sampling. Observe that the function below looks almost the same as the generative model.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"using Gen\n\n@gen function my_model(xs::Vector{Float64})\n    slope ~ normal(0, 2)\n    intercept ~ normal(0, 10)\n    for (i, x) in enumerate(xs)\n        {\"y-$i\"} ~ normal(slope * x + intercept, 1)\n    end\nend\nnothing # hide","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Second, we write an inference program that implements an algorithm for manipulating the execution traces of the model. Inference programs are regular Julia code, and make use of Gen's standard inference library.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"The inference program below takes in a data set, and runs an iterative MCMC algorithm to fit slope and intercept parameters:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"function my_inference_program(xs::Vector{Float64}, ys::Vector{Float64}, num_iters::Int)\n    # Create a set of constraints fixing the \n    # y coordinates to the observed y values\n    constraints = choicemap()\n    for (i, y) in enumerate(ys)\n        constraints[\"y-$i\"] = y\n    end\n    \n    # Run the model, constrained by `constraints`,\n    # to get an initial execution trace\n    (trace, _) = generate(my_model, (xs,), constraints)\n    \n    # Iteratively update the slope then the intercept,\n    # using Gen's metropolis_hastings operator.\n    for _=1:num_iters\n        (trace, _) = metropolis_hastings(trace, select(:slope))\n        (trace, _) = metropolis_hastings(trace, select(:intercept))\n    end\n    \n    # From the final trace, read out the slope and\n    # the intercept.\n    choices = get_choices(trace)\n    return (choices[:slope], choices[:intercept])\nend\nnothing # hide","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Finally, we run the inference program on some data, and get the results:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"xs = [1., 2., 3., 4., 5., 6., 7., 8., 9., 10.]\nys = [8.23, 5.87, 3.99, 2.59, 0.23, -0.66, -3.53, -6.91, -7.24, -9.90]\n(slope, intercept) = my_inference_program(xs, ys, 1000)\nprintln(\"slope: $slope, intercept: $intercept\")","category":"page"},{"location":"#Gen.jl","page":"Gen.jl","title":"Gen.jl","text":"","category":"section"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"A general-purpose probabilistic programming system with programmable inference, embedded in Julia.","category":"page"},{"location":"#Features","page":"Gen.jl","title":"Features","text":"","category":"section"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"Multi-paradigm Bayesian inference via Sequential Monte Carlo, variational inference, MCMC, and more.\nGradient-based training of generative models via parameter optimization, wake-sleep learning, etc.\nAn expressive and intuitive modeling language for writing and composing probabilistic programs.\nInference algorithms are programmable: Write custom proposals, variational families, MCMC kernels or SMC updates without worrying about the math.\nSupport for Bayesian structure learning via involutive MCMC and SMCP³.\nSpecialized modeling constructs that speed-up inference by supporting incremental computation.\nWell-defined APIs for implementing custom generative models, distributions, gradients, etc.","category":"page"},{"location":"#Installation","page":"Gen.jl","title":"Installation","text":"","category":"section"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"The Gen package can be installed with the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and then run:","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"add Gen","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"To install the latest development version, you may instead run:","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"add https://github.com/probcomp/Gen.jl.git","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"Gen can now be used in the Julia REPL, or at the top of a script:","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"using Gen","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"To test the installation locally, you can run the tests with:","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"using Pkg; Pkg.test(\"Gen\")","category":"page"},{"location":"#Tutorials","page":"Gen.jl","title":"Tutorials","text":"","category":"section"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"Learn how to use Gen by following these tutorials:","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"Pages = [\n    \"tutorials/getting_started.md\",\n    \"tutorials/modeling_in_gen.md\",\n    \"tutorials/mcmc_map.md\",\n    \"tutorials/enumerative.md\",\n    \"tutorials/smc.md\",\n    \"tutorials/vi.md\",\n    \"tutorials/scaling_with_sml.md\",\n    \"tutorials/learning_gen_fns.md\"\n]\nDepth = 1","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"More tutorials can also be found on our website. Additional examples of Gen usage can be found in GenExamples.jl.","category":"page"},{"location":"#Questions-and-Contributions","page":"Gen.jl","title":"Questions and Contributions","text":"","category":"section"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"If you have questions about using Gen.jl, feel free to open a discussion on GitHub. If you encounter a bug, please open an issue. We also welcome bug fixes and feature additions as pull requests. Please refer to our contribution guidelines for more details.","category":"page"},{"location":"#Supporting-and-Citing","page":"Gen.jl","title":"Supporting and Citing","text":"","category":"section"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"Gen.jl is part of ongoing research at the MIT Probabilistic Computing Project. If you use Gen for your work, please consider citing us:","category":"page"},{"location":"","page":"Gen.jl","title":"Gen.jl","text":"Gen: A General-Purpose Probabilistic Programming System with Programmable Inference. Cusumano-Towner, M. F.; Saad, F. A.; Lew, A.; and Mansinghka, V. K. In Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI ‘19). (pdf) (bibtex)","category":"page"}]
}
