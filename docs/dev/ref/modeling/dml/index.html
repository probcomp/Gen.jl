<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Built-In Modeling Language · Gen.jl</title><meta name="title" content="Built-In Modeling Language · Gen.jl"/><meta property="og:title" content="Built-In Modeling Language · Gen.jl"/><meta property="twitter:title" content="Built-In Modeling Language · Gen.jl"/><meta name="description" content="Documentation for Gen.jl."/><meta property="og:description" content="Documentation for Gen.jl."/><meta property="twitter:description" content="Documentation for Gen.jl."/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">Gen.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Gen.jl</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../tutorials/getting_started/">Getting Started</a></li><li><a class="tocitem" href="../../../tutorials/modeling_in_gen/">Introduction to Modeling in Gen</a></li><li><a class="tocitem" href="../../../tutorials/mcmc_map/">Basics of MCMC and MAP Inference</a></li><li><a class="tocitem" href="../../../tutorials/enumerative/">Debugging Models with Enumeration</a></li><li><a class="tocitem" href="../../../tutorials/smc/">Object Tracking with SMC</a></li><li><a class="tocitem" href="../../../tutorials/vi/">Variational Inference in Gen</a></li><li><a class="tocitem" href="../../../tutorials/learning_gen_fns/">Learning Generative Functions</a></li><li><a class="tocitem" href="../../../tutorials/scaling_with_sml/">Speeding Up Inference with the SML</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">How-to Guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../how_to/extending_gen/">Extending Gen</a></li><li><a class="tocitem" href="../../../how_to/custom_distributions/">Adding New Distributions</a></li><li><a class="tocitem" href="../../../how_to/custom_gen_fns/">Adding New Generative Functions</a></li><li><a class="tocitem" href="../../../how_to/custom_gradients/">Custom Gradients</a></li><li><a class="tocitem" href="../../../how_to/custom_incremental_computation/">Custom Incremental Computation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox" checked/><label class="tocitem" for="menuitem-4"><span class="docs-label">Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Core Interfaces</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../core/gfi/">Generative Function Interface</a></li><li><a class="tocitem" href="../../core/choice_maps/">Choice Maps</a></li><li><a class="tocitem" href="../../core/selections/">Selections</a></li><li><a class="tocitem" href="../../core/change_hints/">Change Hints</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox" checked/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Modeling Library</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Built-In Modeling Language</a><ul class="internal"><li><a class="tocitem" href="#Annotations"><span>Annotations</span></a></li><li><a class="tocitem" href="#Making-random-choices"><span>Making random choices</span></a></li><li><a class="tocitem" href="#Calling-generative-functions"><span>Calling generative functions</span></a></li><li><a class="tocitem" href="#Composite-addresses"><span>Composite addresses</span></a></li><li><a class="tocitem" href="#Tilde-syntax"><span>Tilde syntax</span></a></li><li><a class="tocitem" href="#Return-value"><span>Return value</span></a></li><li><a class="tocitem" href="#trainable_parameters_modeling"><span>Trainable Parameters</span></a></li><li><a class="tocitem" href="#differentiable_modeling"><span>Differentiable Programming</span></a></li></ul></li><li><a class="tocitem" href="../sml/">Static Modeling Language</a></li><li><a class="tocitem" href="../distributions/">Probability Distributions</a></li><li><a class="tocitem" href="../combinators/">Combinators</a></li><li><a class="tocitem" href="../custom_gen_fns/">Custom Generative Functions</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Inference Library</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../inference/enumerative/">Enumerative Inference</a></li><li><a class="tocitem" href="../../inference/importance/">Importance Sampling</a></li><li><a class="tocitem" href="../../inference/mcmc/">Markov Chain Monte Carlo</a></li><li><a class="tocitem" href="../../inference/pf/">Particle Filtering &amp; SMC</a></li><li><a class="tocitem" href="../../inference/trace_translators/">Trace Translators</a></li><li><a class="tocitem" href="../../inference/parameter_optimization/">Parameter Optimization</a></li><li><a class="tocitem" href="../../inference/map/">MAP Optimization</a></li><li><a class="tocitem" href="../../inference/vi/">Variational Inference</a></li><li><a class="tocitem" href="../../inference/wake_sleep/">Wake-Sleep Learning</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Internals</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../internals/language_implementation/">Modeling Language Implementation</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Reference</a></li><li><a class="is-disabled">Modeling Library</a></li><li class="is-active"><a href>Built-In Modeling Language</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Built-In Modeling Language</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/probcomp/Gen.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/probcomp/Gen.jl/blob/master/docs/src/ref/modeling/dml.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="dml"><a class="docs-heading-anchor" href="#dml">Built-in Modeling Language</a><a id="dml-1"></a><a class="docs-heading-anchor-permalink" href="#dml" title="Permalink"></a></h1><p>Gen provides a built-in modeling language for defining generative functions, using a syntax that extends Julia&#39;s syntax for defining regular Julia functions. This language is also referred to as the <strong>Dynamic Modeling Language (DML)</strong>.</p><p>Generative functions in this modeling language are identified using the <code>@gen</code> keyword in front of a Julia function definition. Here is an example <code>@gen</code> function that samples two random choices:</p><pre><code class="language-julia hljs">@gen function foo(prob::Float64=0.1)
    z1 = @trace(bernoulli(prob), :a)
    z2 = @trace(bernoulli(prob), :b)
    return z1 || z2
end</code></pre><p>After running this code, <code>foo</code> is a Julia value of type <a href="#Gen.DynamicDSLFunction"><code>DynamicDSLFunction</code></a>:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.DynamicDSLFunction" href="#Gen.DynamicDSLFunction"><code>Gen.DynamicDSLFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">DynamicDSLFunction{T} &lt;: GenerativeFunction{T,DynamicDSLTrace}</code></pre><p>A generative function based on a shallowly embedding modeling language based on Julia functions.</p><p>Constructed using the <code>@gen</code> keyword. Most methods in the generative function interface involve a end-to-end execution of the function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/dynamic/dynamic.jl#L3-L10">source</a></section></article><p>Note that it is possible to provide default values for trailing positional arguments. However, keyword arguments are currently <em>not</em> supported.</p><p>We can call the resulting generative function like we would a regular Julia function:</p><pre><code class="language-julia hljs">retval::Bool = foo(0.5)</code></pre><p>We can also trace its execution:</p><pre><code class="language-julia hljs">(trace, _) = generate(foo, (0.5,))</code></pre><p>Optional arguments can be left out of the above operations, and default values will be filled in automatically:</p><pre><code class="language-julia hljs">julia&gt; (trace, _) = generate(foo, ())
julia&gt; get_args(trace)
(0.1,)</code></pre><p>See <a href="../../core/gfi/#gfi">Generative Functions</a> for the full set of operations supported by a generative function. Note that the built-in modeling language described in this section is only one of many ways of defining a generative function – generative functions can also be constructed using other embedded languages, or by directly implementing the methods of the generative function interface. However, the built-in modeling language is intended to being flexible enough cover a wide range of use cases. In the remainder of this section, we refer to generative functions defined using the built-in modeling language as <code>@gen</code> functions. Details about the implementation of <code>@gen</code> functions can be found in the <a href="../../internals/language_implementation/#language-implementation">Modeling Language Implementation</a> section.</p><h2 id="Annotations"><a class="docs-heading-anchor" href="#Annotations">Annotations</a><a id="Annotations-1"></a><a class="docs-heading-anchor-permalink" href="#Annotations" title="Permalink"></a></h2><p>Annotations are a syntactic construct in the built-in modeling language that allows users to provide additional information about how <code>@gen</code> functions should be interpreted. Annotations are optional, and not necessary to understand the basics of Gen. There are two types of annotations – <em>argument annotations</em> and <em>function annotations</em>.</p><p><strong>Argument annotations.</strong> In addition to type declarations on arguments like regular Julia functions, <code>@gen</code> functions also support additional annotations on arguments. Each argument can have the following different syntactic forms:</p><ul><li><p><code>y</code>: No type declaration; no annotations.</p></li><li><p><code>y::Float64</code>: Type declaration; but no annotations.</p></li><li><p><code>(grad)(y)</code>: No type declaration provided;, annotated with <code>grad</code>.</p></li><li><p><code>(grad)(y::Float64)</code>: Type declaration provided; and annotated with <code>grad</code>.</p></li></ul><p>Currently, the possible argument annotations are:</p><ul><li><code>grad</code> (see <a href="#differentiable_modeling">Differentiable programming</a>).</li></ul><p><strong>Function annotations.</strong> The <code>@gen</code> function itself can also be optionally associated with zero or more annotations, which are separate from the per-argument annotations. Function-level annotations use the following different syntactic forms:</p><ul><li><p><code>@gen function foo(&lt;args&gt;) &lt;body&gt; end</code>: No function annotations.</p></li><li><p><code>@gen (grad) function foo(&lt;args&gt;) &lt;body&gt; end</code>: The function has the <code>grad</code> annotation.</p></li><li><p><code>@gen (grad,static) function foo(&lt;args&gt;) &lt;body&gt; end</code>: The function has both the <code>grad</code> and <code>static</code> annotations.</p></li></ul><p>Currently the possible function annotations are:</p><ul><li><p><code>grad</code> (see <a href="#differentiable_modeling">Differentiable programming</a>).</p></li><li><p><code>static</code> (see <a href="../sml/#sml">Static Modeling Language</a>).</p></li><li><p><code>nojuliacache</code> (see <a href="../sml/#sml">Static Modeling Language</a>).</p></li></ul><h2 id="Making-random-choices"><a class="docs-heading-anchor" href="#Making-random-choices">Making random choices</a><a id="Making-random-choices-1"></a><a class="docs-heading-anchor-permalink" href="#Making-random-choices" title="Permalink"></a></h2><p>Random choices are made by calling a probability distribution on some arguments:</p><pre><code class="language-julia hljs">val::Bool = bernoulli(0.5)</code></pre><p>See <a href="../distributions/#distributions">Probability Distributions</a> for the set of built-in probability distributions, and for information on implementing new probability distributions.</p><p>In the body of a <code>@gen</code> function, wrapping a call to a random choice with an <code>@trace</code> expression associates the random choice with an <em>address</em>, and evaluates to the value of the random choice. The syntax is:</p><pre><code class="language-julia hljs">@trace(&lt;distribution&gt;(&lt;args&gt;), &lt;addr&gt;)</code></pre><p>Addresses can be any Julia value. Here, we give the Julia symbol address <code>:z</code> to a Bernoulli random choice.</p><pre><code class="language-julia hljs">val::Bool = @trace(bernoulli(0.5), :z)</code></pre><p>Not all random choices need to be given addresses. An address is required if the random choice will be observed, or will be referenced by a custom inference algorithm (e.g. if it will be proposed to by a custom proposal distribution).</p><h3 id="Sample-space-and-support-of-random-choices"><a class="docs-heading-anchor" href="#Sample-space-and-support-of-random-choices">Sample space and support of random choices</a><a id="Sample-space-and-support-of-random-choices-1"></a><a class="docs-heading-anchor-permalink" href="#Sample-space-and-support-of-random-choices" title="Permalink"></a></h3><p>Different probability distributions produce different types of values for their random choices. For example, the <a href="../distributions/#Gen.bernoulli"><code>bernoulli</code></a> distribution results in <code>Bool</code> values (either <code>true</code> or <code>false</code>), the <a href="../distributions/#Gen.normal"><code>normal</code></a> distribution results in <code>Real</code> values that may be positive or negative, and the <a href="../distributions/#Gen.beta"><code>beta</code></a> distribution result in <code>Real</code> values that are always in the unit interval (0, 1).</p><p>Each <code>Distribution</code> is associated with two sets of values:</p><ul><li><p>The <strong>sample space</strong> of the distribution, which does not depend on the arguments.</p></li><li><p>The <strong>support</strong> of the distribution, which may depend on the arguments, and is the set of values that has nonzero probability (or probability density). It may be the entire sample space, or it may be a subset of the sample space.</p></li></ul><p>For example, the sample space of <a href="../distributions/#Gen.bernoulli"><code>bernoulli</code></a> is <code>Bool</code> and its support is either <code>{true}</code>, <code>{false}</code>, or <code>{true, false}</code>. The sample space of <a href="../distributions/#Gen.normal"><code>normal</code></a> is <code>Real</code> and its support is the set of all values on the real line. The sample space of <a href="../distributions/#Gen.beta"><code>beta</code></a> is <code>Real</code> and its support is the set of values in the interval (0, 1).</p><p>Gen&#39;s built in modeling languages require that a address is associated with a fixed sample space. For example, it is not permitted to use a <code>bernoulli</code> distribution to sample at addresss <code>:a</code> in one execution, and a <code>normal</code> distribution to sample at address <code>:a</code> in a different execution, because their sample spaces differ (<code>Bool</code> vs <code>Real</code>):</p><pre><code class="language-julia hljs">@gen function foo()
    if @trace(bernoulli(0.5), :branch)
        @trace(bernoulli(0.5), :x)
    else
        @trace(normal(0, 1), :x)
    end
end</code></pre><p>A generative function can be <strong>disciplined</strong> or not. In a disciplined generative function, the support of random choices at each address must be fixed. That is, for each address <code>a</code> there must exist a set S that is a subset of the sample space such that for all executions of the generative function, if <code>a</code> occurs as the address of a choice in the execution, then the support of that choice is exactly S. Violating this discipline will cause NaNs, errors, or undefined behavior in some inference programs. However, in many cases it is convenient to write an inference program that operates correctly and efficiently on some specialized class of undisciplined models. In these cases, authors who want their inference code to be reusable should consider documenting which kinds of undisciplined models their inference algorithms allow or expect to see.</p><p>If the support of a random choice needs to change, a disciplined generative function can represent this by using a different address for each distinct value of the support. For example, consider the following generative function:</p><pre><code class="language-julia hljs">@gen function foo()
    n = @trace(categorical([0.5, 0.5]), :n) + 1
    @trace(categorical(ones(n) / n), :x)
end</code></pre><p>The support of the random choice with address <code>:x</code> is either the set <span>$\{1, 2\}$</span> or <span>$\{1, 2, 3\}$</span>. Therefore, this random choice does not have constant support, and the generative function <code>foo</code> is not &#39;disciplined&#39;. Specifically, this could result in undefined behavior for the following inference program:</p><pre><code class="language-julia hljs">tr, _ = importance_resampling(foo, (), choicemap((:x, 3)))</code></pre><p>It is recommended to write disciplined generative functions when possible.</p><h2 id="Calling-generative-functions"><a class="docs-heading-anchor" href="#Calling-generative-functions">Calling generative functions</a><a id="Calling-generative-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Calling-generative-functions" title="Permalink"></a></h2><p><code>@gen</code> functions can invoke other generative functions in three ways:</p><p><strong>Untraced call</strong>: If <code>foo</code> is a generative function, we can invoke <code>foo</code> from within the body of a <code>@gen</code> function using regular call syntax. The random choices made within the call are not given addresses in our trace, and are therefore <em>untraced</em> random choices (see <a href="../../core/gfi/#gfi">Generative Function Interface</a> for details on untraced random choices).</p><pre><code class="language-julia hljs">val = foo(0.5)</code></pre><p><strong>Traced call with a nested address namespace</strong>: We can include the traced random choices made by <code>foo</code> in the caller&#39;s trace, under a namespace, using <code>@trace</code>:</p><pre><code class="language-julia hljs">val = @trace(foo(0.5), :x)</code></pre><p>Now, all random choices made by <code>foo</code> are included in our trace, under the namespace <code>:x</code>. For example, if <code>foo</code> makes random choices at addresses <code>:a</code> and <code>:b</code>, these choices will have addresses <code>:x =&gt; :a</code> and <code>:x =&gt; :b</code> in the caller&#39;s trace.</p><p><strong>Traced call with shared address namespace</strong>: We can include the traced random choices made by <code>foo</code> in the caller&#39;s trace using <code>@trace</code>:</p><pre><code class="language-julia hljs">val = @trace(foo(0.5))</code></pre><p>Now, all random choices made by <code>foo</code> are included in our trace. The caller must guarantee that there are no address collisions. NOTE: This type of call can only be used when calling other <code>@gen</code> functions. Other types of generative functions cannot be called in this way.</p><h2 id="Composite-addresses"><a class="docs-heading-anchor" href="#Composite-addresses">Composite addresses</a><a id="Composite-addresses-1"></a><a class="docs-heading-anchor-permalink" href="#Composite-addresses" title="Permalink"></a></h2><p>In Julia, <code>Pair</code> values can be constructed using the <code>=&gt;</code> operator. For example, <code>:a =&gt; :b</code> is equivalent to <code>Pair(:a, :b)</code> and <code>:a =&gt; :b =&gt; :c</code> is equivalent to <code>Pair(:a, Pair(:b, :c))</code>. A <code>Pair</code> value (e.g. <code>:a =&gt; :b =&gt; :c</code>) can be passed as the address field in an <code>@trace</code> expression, provided that there is not also a random choice or generative function called with <code>@trace</code> at any prefix of the address.</p><p>Consider the following examples.</p><p>This example is <strong>invalid</strong> because <code>:a =&gt; :b</code> is a prefix of <code>:a =&gt; :b =&gt; :c</code>:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :a =&gt; :b =&gt; :c)
@trace(normal(0, 1), :a =&gt; :b)</code></pre><p>This example is <strong>invalid</strong> because <code>:a</code> is a prefix of <code>:a =&gt; :b =&gt; :c</code>:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :a =&gt; :b =&gt; :c)
@trace(normal(0, 1), :a)</code></pre><p>This example is <strong>invalid</strong> because <code>:a =&gt; :b</code> is a prefix of <code>:a =&gt; :b =&gt; :c</code>:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :a =&gt; :b =&gt; :c)
@trace(foo(0.5), :a =&gt; :b)</code></pre><p>This example is <strong>invalid</strong> because <code>:a</code> is a prefix of <code>:a =&gt; :b</code>:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :a)
@trace(foo(0.5), :a =&gt; :b)</code></pre><p>This example is <strong>valid</strong> because <code>:a =&gt; :b</code> and <code>:a =&gt; :c</code> are not prefixes of one another:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :a =&gt; :b)
@trace(normal(0, 1), :a =&gt; :c)</code></pre><p>This example is <strong>valid</strong> because <code>:a =&gt; :b</code> and <code>:a =&gt; :c</code> are not prefixes of one another:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :a =&gt; :b)
@trace(foo(0.5), :a =&gt; :c)</code></pre><h2 id="Tilde-syntax"><a class="docs-heading-anchor" href="#Tilde-syntax">Tilde syntax</a><a id="Tilde-syntax-1"></a><a class="docs-heading-anchor-permalink" href="#Tilde-syntax" title="Permalink"></a></h2><p>As a short-hand for <code>@trace</code> expressions, the tilde operator <code>~</code> can also be used to make random choices and traced calls to generative functions. For example, the expression</p><pre><code class="language-julia hljs">{:x} ~ normal(0, 1)</code></pre><p>is equivalent to:</p><pre><code class="language-julia hljs">@trace(normal(0, 1), :x)</code></pre><p>One can also conveniently assign random values to variables using the syntax:</p><pre><code class="language-julia hljs">x ~ normal(0, 1)</code></pre><p>which is equivalent to:</p><pre><code class="language-julia hljs">x = @trace(normal(0, 1), :x)</code></pre><p>Finally, one can make traced calls using a shared address namespace with the syntax:</p><pre><code class="language-julia hljs">{*} ~ foo(0.5)</code></pre><p>which is equivalent to:</p><pre><code class="language-julia hljs">@trace(foo(0.5))</code></pre><p>Note that <code>~</code> is also defined in <code>Base</code> as a unary operator that performs the bitwise-not operation (see <a href="https://docs.julialang.org/en/v1/base/math/#Base.:~"><code>Base.:~</code></a>). This use of <code>~</code> is also supported within <code>@gen</code> functions. However, uses of <code>~</code> as a <em>binary</em> infix operator within an <code>@gen</code> function will <em>always</em> be treated as equivalent to an <code>@trace</code> expression. If your module contains its own two-argument definition <code>YourModule.:~(a, b)</code> of the <code>~</code> function, calls to that function within <code>@gen</code> functions have to be in qualified prefix form, i.e., you have to write <code>YourModule.:~(a, b)</code> instead of <code>a ~ b</code>.</p><h2 id="Return-value"><a class="docs-heading-anchor" href="#Return-value">Return value</a><a id="Return-value-1"></a><a class="docs-heading-anchor-permalink" href="#Return-value" title="Permalink"></a></h2><p>Like regular Julia functions, <code>@gen</code> functions return either the expression used in a <code>return</code> keyword, or by evaluating the last expression in the function body. Note that the return value of a <code>@gen</code> function is different from a trace of <code>@gen</code> function, which contains the return value associated with an execution as well as the assignment to each random choice made during the execution. See <a href="../../core/gfi/#gfi">Generative Function Interface</a> for more information about traces.</p><h2 id="trainable_parameters_modeling"><a class="docs-heading-anchor" href="#trainable_parameters_modeling">Trainable Parameters</a><a id="trainable_parameters_modeling-1"></a><a class="docs-heading-anchor-permalink" href="#trainable_parameters_modeling" title="Permalink"></a></h2><p>A <code>@gen</code> function may begin with an optional block of <em>trainable parameter declarations</em>. The block consists of a sequence of statements, beginning with <code>@param</code>, that declare the name and Julia type for each trainable parameter. The function below has a single trainable parameter <code>theta</code> with type <code>Float64</code>:</p><pre><code class="language-julia hljs">@gen function foo(prob::Float64)
    @param theta::Float64
    z1 = @trace(bernoulli(prob), :a)
    z2 = @trace(bernoulli(theta), :b)
    return z1 || z2
end</code></pre><p>Trainable parameters obey the same scoping rules as Julia local variables defined at the beginning of the function body. The value of a trainable parameter is undefined until it is initialized using <a href="#Gen.init_param!"><code>init_param!</code></a>. In addition to the current value, each trainable parameter has a current <strong>gradient accumulator</strong> value. The gradient accumulator value has the same shape (e.g. array dimension) as the parameter value. It is initialized to all zeros, and is incremented by <a href="../../core/gfi/#Gen.accumulate_param_gradients!"><code>accumulate_param_gradients!</code></a>.</p><p>The following methods are exported for the trainable parameters of <code>@gen</code> functions:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.init_param!" href="#Gen.init_param!"><code>Gen.init_param!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">init_param!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol, value)</code></pre><p>Initialize the the value of a named trainable parameter of a generative function.</p><p>Also generates the gradient accumulator for that parameter to <code>zero(value)</code>.</p><p>Example:</p><pre><code class="language-julia hljs">init_param!(foo, :theta, 0.6)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/builtin_optimization.jl#L48-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.get_param" href="#Gen.get_param"><code>Gen.get_param</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">value = get_param(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol)</code></pre><p>Get the current value of a trainable parameter of the generative function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/builtin_optimization.jl#L12-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.get_param_grad" href="#Gen.get_param_grad"><code>Gen.get_param_grad</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">value = get_param_grad(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol)</code></pre><p>Get the current value of the gradient accumulator for a trainable parameter of the generative function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/builtin_optimization.jl#L21-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.set_param_grad!" href="#Gen.set_param_grad!"><code>Gen.set_param_grad!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_param_grad!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol, grad_value)</code></pre><p>Set the gradient accumlator for a trainable parameter of the generative function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/builtin_optimization.jl#L39-L43">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.set_param!" href="#Gen.set_param!"><code>Gen.set_param!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_param!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol, value)</code></pre><p>Set the value of a trainable parameter of the generative function.</p><p>NOTE: Does not update the gradient accumulator value.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/builtin_optimization.jl#L1-L7">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.zero_param_grad!" href="#Gen.zero_param_grad!"><code>Gen.zero_param_grad!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">zero_param_grad!(gen_fn::Union{DynamicDSLFunction,StaticIRGenerativeFunction}, name::Symbol)</code></pre><p>Reset the gradient accumlator for a trainable parameter of the generative function to all zeros.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/builtin_optimization.jl#L30-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.accumulate_param_gradients_determ!" href="#Gen.accumulate_param_gradients_determ!"><code>Gen.accumulate_param_gradients_determ!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">arg_grads = accumulate_param_gradients_determ!(
    gen_fn::CustomDetermGF, state, args, retgrad, scale_factor)</code></pre><p>Increment gradient accumulators for parameters the gradient with respect to the arguments, optionally scaled, and return the gradient with respect to the arguments (not scaled).</p><p>Given the previous state and a gradient with respect to the return value <span>$∇_y J$</span> (<code>retgrad</code>), return the following gradient (<code>arg_grads</code>) with respect to the arguments <span>$x$</span>:</p><p class="math-container">\[∇_x J\]</p><p>Also increment the gradient accumulators for the trainable parameters <span>$Θ$</span> of the function by:</p><p class="math-container">\[s * ∇_Θ J\]</p><p>where <span>$s$</span> is <code>scale_factor</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/modeling_library/custom_determ.jl#L69-L89">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Gen.gradient_with_state" href="#Gen.gradient_with_state"><code>Gen.gradient_with_state</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">arg_grads = gradient_with_state(gen_fn::CustomDetermGF, state, args, retgrad)</code></pre><p>Return the gradient tuple with respect to the arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/probcomp/Gen.jl/blob/3f44183269baf671472b4497c3c00ee2d223d207/src/modeling_library/custom_determ.jl#L59-L63">source</a></section></article><p>Trainable parameters are designed to be trained using gradient-based methods. This is discussed in the next section.</p><h2 id="differentiable_modeling"><a class="docs-heading-anchor" href="#differentiable_modeling">Differentiable Programming</a><a id="differentiable_modeling-1"></a><a class="docs-heading-anchor-permalink" href="#differentiable_modeling" title="Permalink"></a></h2><p>Given a trace of a <code>@gen</code> function, Gen supports automatic differentiation of the log probability (density) of all of the random choices made in the trace with respect to the following types of inputs:</p><ul><li><p>all or a subset of the arguments to the function.</p></li><li><p>the values of all or a subset of random choices.</p></li><li><p>all or a subset of trainable parameters of the <code>@gen</code> function.</p></li></ul><p>We first discuss the semantics of these gradient computations, and then discuss what how to write and use Julia code in the body of a <code>@gen</code> function so that it can be automatically differentiated by the gradient computation.</p><h3 id="Supported-gradient-computations"><a class="docs-heading-anchor" href="#Supported-gradient-computations">Supported gradient computations</a><a id="Supported-gradient-computations-1"></a><a class="docs-heading-anchor-permalink" href="#Supported-gradient-computations" title="Permalink"></a></h3><p><strong>Gradients with respect to arguments.</strong> A <code>@gen</code> function may have a fixed set of its arguments annotated with <code>grad</code>, which indicates that gradients with respect to that argument should be supported. For example, in the function below, we indicate that we want to support differentiation with respect to the <code>y</code> argument, but that we do not want to support differentiation with respect to the <code>x</code> argument.</p><pre><code class="language-julia hljs">@gen function foo(x, (grad)(y))
    if x &gt; 5
        @trace(normal(y, 1), :z)
    else
        @trace(normal(y, 10), :z)
    end
end</code></pre><p>For the function <code>foo</code> above, when <code>x &gt; 5</code>, the gradient with respect to <code>y</code> is the gradient of the log probability density of a normal distribution with standard deviation 1, with respect to its mean, evaluated at mean <code>y</code>. When <code>x &lt;= 5</code>, we instead differentiate the log density of a normal distribution with standard deviation 10, relative to its mean.</p><p><strong>Gradients with respect to values of random choices.</strong> The author of a <code>@gen</code> function also identifies a set of addresses of random choices with respect to which they wish to support gradients of the log probability (density). Gradients of the log probability (density) with respect to the values of random choices are used in gradient-based numerical optimization of random choices, as well as certain MCMC updates that require gradient information.</p><p><strong>Gradients with respect to trainable parameters.</strong> The gradient of the log probability (density) with respect to the trainable parameters can also be computed using automatic differentiation. Currently, the log probability (density) must be a differentiable function of all trainable parameters.</p><p><strong>Gradients of a function of the return value.</strong> Differentiable programming in Gen composes across function calls. If the return value of the <code>@gen</code> function is conditionally dependent on source elements including (i) any arguments annotated with <code>grad</code> or (ii) any random choices for which gradients are supported, or (ii) any trainable parameters, then the gradient computation requires a gradient of the an external function with respect to the return value in order to the compute the correct gradients. Thus, the function being differentiated always includes a term representing the log probability (density) of all random choices made by the function, but can be extended with a term that depends on the return value of the function. The author of a <code>@gen</code> function can indicate that the return value depends on the source elements (causing the gradient with respect to the return value is required for all gradient computations) by adding the <code>grad</code> annotation to the <code>@gen</code> function itself. For example, in the function below, the return value is conditionally dependent (and actually identical to) on the random value at address <code>:z</code>:</p><pre><code class="language-julia hljs">@gen function foo(x, (grad)(y))
    if x &gt; 5
        return @trace(normal(y, 1), :z)
    else
        return @trace(normal(y, 10), :z)
    end
end</code></pre><p>If the author of <code>foo</code> wished to support the computation of gradients with respect to the value of <code>:z</code>, they would need to add the <code>grad</code> annotation to <code>foo</code> using the following syntax:</p><pre><code class="language-julia hljs">@gen (grad) function foo(x, (grad)(y))
    if x &gt; 5
        return @trace(normal(y, 1), :z)
    else
        return @trace(normal(y, 10), :z)
    end
end</code></pre><h3 id="Writing-differentiable-code"><a class="docs-heading-anchor" href="#Writing-differentiable-code">Writing differentiable code</a><a id="Writing-differentiable-code-1"></a><a class="docs-heading-anchor-permalink" href="#Writing-differentiable-code" title="Permalink"></a></h3><p>In order to compute the gradients described above, the code in the body of the <code>@gen</code> function needs to be differentiable. Code in the body of a <code>@gen</code> function consists of:</p><ul><li><p>Julia code</p></li><li><p>Making random choices</p></li><li><p>Calling generative functions</p></li></ul><p>We now discuss how to ensure that code of each of these forms is differentiable. Note that the procedures for differentiation of code described below are only performed during certain operations on <code>@gen</code> functions (<a href="../../core/gfi/#Gen.choice_gradients"><code>choice_gradients</code></a> and <a href="../../core/gfi/#Gen.accumulate_param_gradients!"><code>accumulate_param_gradients!</code></a>).</p><p><strong>Julia code.</strong> Julia code used within a body of a <code>@gen</code> function is made differentiable using the <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff</a> package, which implements  reverse-mode automatic differentiation. Specifically, values whose gradient is required (either values of arguments, random choices, or trainable parameters) are &#39;tracked&#39; by boxing them into special values and storing the tracked value on a &#39;tape&#39;. For example a <code>Float64</code> value is boxed into a <code>ReverseDiff.TrackedReal</code> value. Methods (including e.g. arithmetic operators) are defined that operate on these tracked values and produce other tracked values as a result. As the computation proceeds all the values are placed onto the tape, with back-references to the parent operation and operands. Arithmetic operators, array and linear algebra functions, and common special numerical functions, as well as broadcasting, are automatically supported. See <a href="https://github.com/JuliaDiff/ReverseDiff.jl">ReverseDiff</a> for more details.</p><p><strong>Making random choices.</strong> When making a random choice, each argument is either a tracked value or not. If the argument is a tracked value, then the probability distribution must support differentiation of the log probability (density) with respect to that argument. Otherwise, an error is thrown. The <a href="../../core/gfi/#Gen.has_argument_grads"><code>has_argument_grads</code></a> function indicates which arguments support differentiation for a given distribution (see <a href="../distributions/#distributions">Probability Distributions</a>). If the gradient is required for the <em>value</em> of a random choice, the distribution must support differentiation of the log probability (density) with respect to the value. This is indicated by the <a href="../distributions/#Gen.has_output_grad"><code>has_output_grad</code></a> function.</p><p><strong>Calling generative functions.</strong> Like distributions, generative functions indicate which of their arguments support differentiation, using the <code>has_argument_grads</code> function. It is an error if a tracked value is passed as an argument of a generative function, when differentiation is not supported by the generative function for that argument. If a generative function <code>gen_fn</code> has <code>accepts_output_grad(gen_fn) = true</code>, then the return value of the generative function call will be tracked and will propagate further through the caller <code>@gen</code> function&#39;s computation.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../core/change_hints/">« Change Hints</a><a class="docs-footer-nextpage" href="../sml/">Static Modeling Language »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 6 September 2025 14:05">Saturday 6 September 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
